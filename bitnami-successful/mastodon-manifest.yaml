---
# Source: mastodon/charts/apache/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-apache
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apache
    app.kubernetes.io/version: 2.4.59
    helm.sh/chart: apache-11.2.4
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: apache
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 8080
        - port: 8443
---
# Source: mastodon/charts/elasticsearch/templates/coordinating/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-elasticsearch-coordinating
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: coordinating-only
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: coordinating-only
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 9200
        - port: 9300
---
# Source: mastodon/charts/elasticsearch/templates/data/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-elasticsearch-data
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: data
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: data
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 9200
        - port: 9300
---
# Source: mastodon/charts/elasticsearch/templates/ingest/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-elasticsearch-ingest
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: ingest
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: ingest
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 9200
        - port: 9300
---
# Source: mastodon/charts/elasticsearch/templates/master/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-elasticsearch-master
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: master
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: master
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 9200
        - port: 9300
---
# Source: mastodon/charts/minio/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-minio
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: minio
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 9001
        - port: 9000
---
# Source: mastodon/charts/minio/templates/provisioning-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-minio-provisioning
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/component: minio-provisioning
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
---
# Source: mastodon/charts/postgresql/templates/primary/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-postgresql
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.6
    app.kubernetes.io/component: primary
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 5432
---
# Source: mastodon/charts/redis/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-redis
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: redis
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 6379
---
# Source: mastodon/templates/init-job/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-mastodon-init
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
    app.kubernetes.io/component: init
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: mastodon
      app.kubernetes.io/component: init
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
---
# Source: mastodon/templates/sidekiq/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-mastodon-sidekiq
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
    app.kubernetes.io/component: sidekiq
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: mastodon
      app.kubernetes.io/component: sidekiq
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
---
# Source: mastodon/templates/streaming/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-mastodon-streaming
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
    app.kubernetes.io/component: streaming
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: mastodon
      app.kubernetes.io/component: streaming
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 8080
---
# Source: mastodon/templates/tootctlMediaManagement/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-mastodon-tootctl-media
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
    app.kubernetes.io/component: tootctlMediaManagement
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: mastodon
      app.kubernetes.io/component: tootctlMediaManagement
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
---
# Source: mastodon/templates/web/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-mastodon-web
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
    app.kubernetes.io/component: web
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: mastodon
      app.kubernetes.io/component: web
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 3000
---
# Source: mastodon/charts/apache/templates/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-apache
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apache
    app.kubernetes.io/version: 2.4.59
    helm.sh/chart: apache-11.2.4
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: apache
---
# Source: mastodon/charts/elasticsearch/templates/coordinating/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-elasticsearch-coordinating
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: coordinating-only
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: coordinating-only
---
# Source: mastodon/charts/elasticsearch/templates/data/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-elasticsearch-data
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: data
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: data
---
# Source: mastodon/charts/elasticsearch/templates/ingest/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-elasticsearch-ingest
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: ingest
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: ingest
---
# Source: mastodon/charts/elasticsearch/templates/master/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-elasticsearch-master
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: master
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: master
---
# Source: mastodon/charts/minio/templates/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-minio
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: minio
---
# Source: mastodon/charts/postgresql/templates/primary/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-postgresql
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.6
    app.kubernetes.io/component: primary
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
---
# Source: mastodon/charts/redis/templates/master/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-redis-master
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
    app.kubernetes.io/component: master
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
---
# Source: mastodon/charts/apache/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-apache
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apache
    app.kubernetes.io/version: 2.4.59
    helm.sh/chart: apache-11.2.4
automountServiceAccountToken: false
---
# Source: mastodon/charts/elasticsearch/templates/coordinating/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-elasticsearch-coordinating
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: coordinating-only
automountServiceAccountToken: false
---
# Source: mastodon/charts/elasticsearch/templates/data/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-elasticsearch-data
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: data
automountServiceAccountToken: false
---
# Source: mastodon/charts/elasticsearch/templates/ingest/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-elasticsearch-ingest
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: ingest
automountServiceAccountToken: false
---
# Source: mastodon/charts/elasticsearch/templates/master/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-elasticsearch-master
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: master
automountServiceAccountToken: false
---
# Source: mastodon/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-minio
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
automountServiceAccountToken: false
secrets:
  - name: my-release-minio
---
# Source: mastodon/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-postgresql
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.6
automountServiceAccountToken: false
---
# Source: mastodon/charts/redis/templates/master/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: my-release-redis-master
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
---
# Source: mastodon/templates/service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-mastodon
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
automountServiceAccountToken: false
---
# Source: mastodon/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-minio
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
type: Opaque
data:
  root-user: "YWRtaW4="
  root-password: "U1BzWXgzd2FPag=="
---
# Source: mastodon/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-postgresql
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.6
type: Opaque
data:
  postgres-password: "UndlV1k2Q0NqYw=="
  password: "RnpnQzM3NXB6dA=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: mastodon/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-redis
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
type: Opaque
data:
  redis-password: "a3R0QWFaNmZTUQ=="
---
# Source: mastodon/templates/default-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-mastodon-default
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
data:
---
# Source: mastodon/templates/smtp-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-mastodon-smtp
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
data:
  login: ""
  password: ""
  server: ""
---
# Source: mastodon/charts/minio/templates/provisioning-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-minio-provisioning
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
    app.kubernetes.io/component: minio-provisioning
data:
---
# Source: mastodon/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-configuration
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: mastodon/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-health
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: mastodon/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-scripts
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--requirepass" "${REDIS_PASSWORD}")
    ARGS+=("--masterauth" "${REDIS_PASSWORD}")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: mastodon/templates/apache-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-apache-mastodon-vhost
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
data:
  mastodon-vhost.conf: |-
    <VirtualHost 127.0.0.1:8080 _default_:8080>
      ServerName 
      ServerAlias *
      <Location "/">
        ProxyPass http://my-release-mastodon-web:80/
        ProxyPassReverse 
        ProxyPreserveHost on
        Order allow,deny
        Allow from all
      </Location>
      <Location "/api/v1/streaming">
        # Streaming uses normal API calls and websockets. We used this configuration
        # based on https://stackoverflow.com/questions/27526281/websockets-and-apache-proxy-how-to-configure-mod-proxy-wstunnel
        RewriteEngine On
        RewriteCond %{HTTP:Upgrade} =websocket [NC]
        RewriteRule /api/(.*)           ws://my-release-mastodon-streaming:80/api/$1 [P,L]
        RewriteCond %{HTTP:Upgrade} !=websocket [NC]
        RewriteRule /api/(.*)           http://my-release-mastodon-streaming:80/api/$1 [P,L]
        ProxyPassReverse 
        Order allow,deny
        Allow from all
      </Location>
      <Location "/s3storage">
        ProxyPass http://my-release-minio:80/s3storage/
        ProxyPassReverse 
        Order allow,deny
        Allow from all
      </Location>
    </VirtualHost>
---
# Source: mastodon/templates/default-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-mastodon-default
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
data:
  DB_HOST: "my-release-postgresql"
  DB_PORT: "5432"
  DB_NAME: "bitnami_mastodon"
  DB_USER: "bn_mastodon"
  ES_ENABLED: "true"
  ES_HOST: "my-release-elasticsearch"
  ES_PORT: "9200"
  WEB_DOMAIN: ""
  LOCAL_DOMAIN: ""
  LOCAL_HTTPS: "true"
  DEFAULT_LOCALE: "en"
  STREAMING_API_BASE_URL: "ws://"
  REDIS_HOST: "my-release-redis-master"
  REDIS_PORT: "6379"
  SMTP_PORT: "587"
  SMTP_FROM_ADDRESS: ""
  SMTP_DOMAIN: ""
  SMTP_REPLY_TO: ""
  SMTP_DELIVERY_METHOD: "smtp"
  SMTP_CA_FILE: "/etc/ssl/certs/ca-certificates.crt"
  SMTP_OPENSSL_VERIFY_MODE: "none"
  SMTP_ENABLE_STARTTLS_AUTO: "true"
  SMTP_TLS: "false"
  SMTP_AUTH_METHOD: "plain"
  RAILS_ENV: "production"
  NODE_ENV: "production"
  S3_ENABLED: "true"
  S3_BUCKET: "s3storage"
  S3_ENDPOINT: "http://my-release-minio"
  S3_HOSTNAME: "my-release-minio"
  S3_REGION: "us-east-1"
  S3_ALIAS_HOST: "/s3storage"
  S3_PROTOCOL: "http"
---
# Source: mastodon/templates/init-job/init-job-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-mastodon-init-scripts
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
data:
  # All these operations require access to PostgreSQL (including Elasticsearch migration) and Redis. In order to avoid
  # potential race conditions we include them in the same script.
  migrate-and-create-admin.sh: |-
    #!/bin/bash

    set -o errexit
    set -o nounset
    set -o pipefail

    # Load libraries
    . /opt/bitnami/scripts/liblog.sh
    . /opt/bitnami/scripts/libos.sh
    . /opt/bitnami/scripts/libvalidations.sh
    . /opt/bitnami/scripts/libmastodon.sh

    # Load Mastodon environment variables
    . /opt/bitnami/scripts/mastodon-env.sh
    info "Migrating database"
    psql_connection_string="postgresql://${MASTODON_DATABASE_USERNAME}:${MASTODON_DATABASE_PASSWORD}@${MASTODON_DATABASE_HOST}:${MASTODON_DATABASE_PORT_NUMBER}/${MASTODON_DATABASE_NAME}"
    mastodon_wait_for_postgresql_connection "$psql_connection_string"
    mastodon_rake_execute db:migrate
    elasticsearch_connection_string="http://${MASTODON_ELASTICSEARCH_HOST}:${MASTODON_ELASTICSEARCH_PORT_NUMBER}"
    mastodon_wait_for_elasticsearch_connection "$elasticsearch_connection_string"
    info "Migrating Elasticsearch"
    mastodon_rake_execute chewy:upgrade
    mastodon_ensure_admin_user_exists
  precompile-assets.sh: |-
    #!/bin/bash

    set -o errexit
    set -o nounset
    set -o pipefail

    # Load libraries
    . /opt/bitnami/scripts/liblog.sh
    . /opt/bitnami/scripts/libos.sh
    . /opt/bitnami/scripts/libvalidations.sh
    . /opt/bitnami/scripts/libmastodon.sh

    # Load Mastodon environment variables
    . /opt/bitnami/scripts/mastodon-env.sh
    mastodon_wait_for_s3_connection "$MASTODON_S3_HOSTNAME" "$MASTODON_S3_PORT_NUMBER"
    info "Precompiling assets"
    mastodon_rake_execute assets:precompile
---
# Source: mastodon/charts/minio/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: my-release-minio
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "8Gi"
---
# Source: mastodon/charts/apache/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-apache
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apache
    app.kubernetes.io/version: 2.4.59
    helm.sh/chart: apache-11.2.4
spec:
  type: LoadBalancer
  externalTrafficPolicy: "Cluster"
  
  loadBalancerSourceRanges: []
  
  sessionAffinity: None
  ports:
    - name: http
      port: 80
      targetPort: http
    - name: https
      port: 443
      targetPort: https
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: apache
---
# Source: mastodon/charts/elasticsearch/templates/coordinating/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-elasticsearch-coordinating-hl
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: coordinating-only
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: coordinating-only
---
# Source: mastodon/charts/elasticsearch/templates/data/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-elasticsearch-data-hl
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: data
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: data
---
# Source: mastodon/charts/elasticsearch/templates/ingest/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-elasticsearch-ingest-hl
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: ingest
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: ingest
---
# Source: mastodon/charts/elasticsearch/templates/master/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-elasticsearch-master-hl
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: master
---
# Source: mastodon/charts/elasticsearch/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-elasticsearch
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: coordinating-only
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
      nodePort: null
    - name: tcp-transport
      port: 9300
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: coordinating-only
---
# Source: mastodon/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-minio
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
spec:
  type: ClusterIP
  ports:
    - name: minio-api
      port: 80
      targetPort: minio-api
      nodePort: null
    - name: minio-console
      port: 9001
      targetPort: minio-console
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: minio
---
# Source: mastodon/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql-hl
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.6
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: mastodon/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.6
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: mastodon/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-redis-headless
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: redis
---
# Source: mastodon/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-redis-master
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: master
---
# Source: mastodon/templates/streaming/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-mastodon-streaming
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
    app.kubernetes.io/component: streaming
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: http
      port: 80
      targetPort: http
      protocol: TCP
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/component: streaming
---
# Source: mastodon/templates/web/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-mastodon-web
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/version: 4.2.9
    helm.sh/chart: mastodon-6.2.6
    app.kubernetes.io/part-of: mastodon
    app.kubernetes.io/component: web
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: mastodon
    app.kubernetes.io/component: web
---
# Source: mastodon/charts/apache/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-apache
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apache
    app.kubernetes.io/version: 2.4.59
    helm.sh/chart: apache-11.2.4
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: apache
  replicas: 1
  revisionHistoryLimit: 10
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: apache
        app.kubernetes.io/version: 2.4.59
        helm.sh/chart: apache-11.2.4
    spec:
      
      automountServiceAccountToken: false
      # yamllint disable rule:indentation
      hostAliases:
        - hostnames:
          - status.localhost
          ip: 127.0.0.1
      # yamllint enable rule:indentation
      priorityClassName: ""
      serviceAccountName: my-release-apache
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: apache
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      initContainers:
        - name: preserve-logs-symlinks
          image: docker.io/bitnami/apache:2.4.59-debian-12-r6
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          command:
            - /bin/bash
          args:
            - -ec
            - |
              #!/bin/bash

              . /opt/bitnami/scripts/libfs.sh
              # We copy the logs folder because it has symlinks to stdout and stderr
              if ! is_dir_empty /opt/bitnami/apache/logs; then
                cp -r /opt/bitnami/apache/logs /emptydir/app-logs-dir
              fi
          volumeMounts:
            - name: empty-dir
              mountPath: /emptydir
      containers:
        - name: apache
          image: docker.io/bitnami/apache:2.4.59-debian-12-r6
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: APACHE_HTTP_PORT_NUMBER
              value: "8080"
            - name: APACHE_HTTPS_PORT_NUMBER
              value: "8443"
          envFrom:
          ports:
            - name: http
              containerPort: 8080
            - name: https
              containerPort: 8443
          livenessProbe:
            tcpSocket:
              port: http
            initialDelaySeconds: 180
            periodSeconds: 20
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            httpGet:
              path: /api/v1/streaming/health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /opt/bitnami/apache/conf
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/apache/logs
              subPath: app-logs-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/apache/var/run
              subPath: app-tmp-dir
            - name: vhosts
              mountPath: /vhosts
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: vhosts
          configMap:
            name: my-release-apache-mastodon-vhost
---
# Source: mastodon/charts/minio/templates/standalone/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-minio
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: minio
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: minio
        app.kubernetes.io/version: 2024.6.13
        helm.sh/chart: minio-14.6.10
      annotations:
        checksum/credentials-secret: 116cc425f3fafda7cbd385ac52abf502949b7db2bab61ce56bee9b54b5a768cf
    spec:
      
      serviceAccountName: my-release-minio
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: minio
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      automountServiceAccountToken: false
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: OnRootMismatch
        supplementalGroups: []
        sysctls: []
      containers:
        - name: minio
          image: docker.io/bitnami/minio:2024.6.13-debian-12-r2
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MINIO_SCHEME
              value: "http"
            - name: MINIO_FORCE_NEW_KEYS
              value: "no"
            - name: MINIO_API_PORT_NUMBER
              value: "9000"
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: my-release-minio
                  key: root-user
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-minio
                  key: root-password
            - name: MINIO_DEFAULT_BUCKETS
              value: s3storage
            - name: MINIO_BROWSER
              value: "on"
            - name: MINIO_PROMETHEUS_AUTH_TYPE
              value: "public"
            - name: MINIO_CONSOLE_PORT_NUMBER
              value: "9001"
            - name: MINIO_DATA_DIR
              value: "/bitnami/minio/data"
          envFrom:
          ports:
            - name: minio-api
              containerPort: 9000
              protocol: TCP
            - name: minio-console
              containerPort: 9001
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /minio/health/live
              port: minio-api
              scheme: "HTTP"
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            tcpSocket:
              port: minio-api
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 5
          resources:
            limits:
              cpu: 375m
              ephemeral-storage: 1024Mi
              memory: 384Mi
            requests:
              cpu: 250m
              ephemeral-storage: 50Mi
              memory: 256Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/minio/tmp
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /.mc
              subPath: app-mc-dir
            - name: data
              mountPath: /bitnami/minio/data
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: data
          persistentVolumeClaim:
            claimName: my-release-minio
---
# Source: mastodon/charts/elasticsearch/templates/coordinating/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-elasticsearch-coordinating
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: coordinating-only
    ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
    app: coordinating-only
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: coordinating-only
  updateStrategy:
    type: RollingUpdate
  serviceName: my-release-elasticsearch-coordinating-hl
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: elasticsearch
        app.kubernetes.io/version: 8.14.1
        helm.sh/chart: elasticsearch-21.2.4
        app.kubernetes.io/component: coordinating-only
        ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
        app: coordinating-only
      annotations:
    spec:
      serviceAccountName: my-release-elasticsearch-coordinating
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/os-shell:12-debian-12-r22
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
            runAsUser: 0
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
        - name: copy-default-plugins
          image: docker.io/bitnami/elasticsearch:8.14.1-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 768Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 512Mi
          command:
            - /bin/bash
          args:
            - -ec
            - |
              #!/bin/bash

              . /opt/bitnami/scripts/libfs.sh
              . /opt/bitnami/scripts/elasticsearch-env.sh

              if ! is_dir_empty "$DB_DEFAULT_PLUGINS_DIR"; then
                  cp -nr "$DB_DEFAULT_PLUGINS_DIR"/* /plugins
              fi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /plugins
              subPath: app-plugins-dir
      containers:
        - name: elasticsearch
          image: docker.io/bitnami/elasticsearch:8.14.1-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: BITNAMI_DEBUG
              value: "false"
            - name: ELASTICSEARCH_CLUSTER_NAME
              value: "elastic"
            - name: ELASTICSEARCH_IS_DEDICATED_NODE
              value: "yes"
            - name: ELASTICSEARCH_NODE_ROLES
              value: ""
            - name: ELASTICSEARCH_TRANSPORT_PORT_NUMBER
              value: "9300"
            - name: ELASTICSEARCH_HTTP_PORT_NUMBER
              value: "9200"
            - name: ELASTICSEARCH_CLUSTER_HOSTS
              value: "my-release-elasticsearch-master-hl.mastodon.svc.cluster.local,my-release-elasticsearch-coordinating-hl.mastodon.svc.cluster.local,my-release-elasticsearch-data-hl.mastodon.svc.cluster.local,my-release-elasticsearch-ingest-hl.mastodon.svc.cluster.local,"
            - name: ELASTICSEARCH_TOTAL_NODES
              value: "2"
            - name: ELASTICSEARCH_CLUSTER_MASTER_HOSTS
              value: my-release-elasticsearch-master-0 
            - name: ELASTICSEARCH_MINIMUM_MASTER_NODES
              value: "1"
            - name: ELASTICSEARCH_ADVERTISED_HOSTNAME
              value: "$(MY_POD_NAME).my-release-elasticsearch-coordinating-hl.mastodon.svc.cluster.local"
            - name: ELASTICSEARCH_HEAP_SIZE
              value: "128m"
          ports:
            - name: rest-api
              containerPort: 9200
            - name: transport
              containerPort: 9300
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: rest-api
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 90
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 768Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 512Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/config
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/tmp
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/logs
              subPath: app-logs-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/plugins
              subPath: app-plugins-dir
            - name: data
              mountPath: /bitnami/elasticsearch/data
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: "data"
          emptyDir: {}
---
# Source: mastodon/charts/elasticsearch/templates/data/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-elasticsearch-data
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: data
    ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
    app: data
spec:
  replicas: 1
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: data
  serviceName: my-release-elasticsearch-data-hl
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: elasticsearch
        app.kubernetes.io/version: 8.14.1
        helm.sh/chart: elasticsearch-21.2.4
        app.kubernetes.io/component: data
        ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
        app: data
      annotations:
    spec:
      serviceAccountName: my-release-elasticsearch-data
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/os-shell:12-debian-12-r22
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
            runAsUser: 0
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
        - name: copy-default-plugins
          image: docker.io/bitnami/elasticsearch:8.14.1-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 1536Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 1024Mi
          command:
            - /bin/bash
          args:
            - -ec
            - |
              #!/bin/bash

              . /opt/bitnami/scripts/libfs.sh
              . /opt/bitnami/scripts/elasticsearch-env.sh

              if ! is_dir_empty "$DB_DEFAULT_PLUGINS_DIR"; then
                  cp -nr "$DB_DEFAULT_PLUGINS_DIR"/* /plugins
              fi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /plugins
              subPath: app-plugins-dir
      containers:
        - name: elasticsearch
          image: docker.io/bitnami/elasticsearch:8.14.1-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: ELASTICSEARCH_IS_DEDICATED_NODE
              value: "yes"
            - name: ELASTICSEARCH_NODE_ROLES
              value: "data"
            - name: ELASTICSEARCH_TRANSPORT_PORT_NUMBER
              value: "9300"
            - name: ELASTICSEARCH_HTTP_PORT_NUMBER
              value: "9200"
            - name: ELASTICSEARCH_CLUSTER_NAME
              value: "elastic"
            - name: ELASTICSEARCH_CLUSTER_HOSTS
              value: "my-release-elasticsearch-master-hl.mastodon.svc.cluster.local,my-release-elasticsearch-coordinating-hl.mastodon.svc.cluster.local,my-release-elasticsearch-data-hl.mastodon.svc.cluster.local,my-release-elasticsearch-ingest-hl.mastodon.svc.cluster.local,"
            - name: ELASTICSEARCH_TOTAL_NODES
              value: "2"
            - name: ELASTICSEARCH_CLUSTER_MASTER_HOSTS
              value: my-release-elasticsearch-master-0 
            - name: ELASTICSEARCH_MINIMUM_MASTER_NODES
              value: "1"
            - name: ELASTICSEARCH_ADVERTISED_HOSTNAME
              value: "$(MY_POD_NAME).my-release-elasticsearch-data-hl.mastodon.svc.cluster.local"
            - name: ELASTICSEARCH_HEAP_SIZE
              value: "1024m"
          ports:
            - name: rest-api
              containerPort: 9200
            - name: transport
              containerPort: 9300
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: rest-api
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 90
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 1536Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 1024Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/config
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/tmp
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/logs
              subPath: app-logs-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/plugins
              subPath: app-plugins-dir
            - name: data
              mountPath: /bitnami/elasticsearch/data
      volumes:
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: "data"
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: mastodon/charts/elasticsearch/templates/ingest/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-elasticsearch-ingest
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: ingest
    ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
    app: ingest
spec:
  replicas: 1
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: ingest
  serviceName: my-release-elasticsearch-ingest-hl
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: elasticsearch
        app.kubernetes.io/version: 8.14.1
        helm.sh/chart: elasticsearch-21.2.4
        app.kubernetes.io/component: ingest
        ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
        app: ingest
      annotations:
    spec:
      serviceAccountName: my-release-elasticsearch-ingest
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/os-shell:12-debian-12-r22
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
            runAsUser: 0
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
        - name: copy-default-plugins
          image: docker.io/bitnami/elasticsearch:8.14.1-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 768Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 512Mi
          command:
            - /bin/bash
          args:
            - -ec
            - |
              #!/bin/bash

              . /opt/bitnami/scripts/libfs.sh
              . /opt/bitnami/scripts/elasticsearch-env.sh

              if ! is_dir_empty "$DB_DEFAULT_PLUGINS_DIR"; then
                  cp -nr "$DB_DEFAULT_PLUGINS_DIR"/* /plugins
              fi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /plugins
              subPath: app-plugins-dir
      containers:
        - name: elasticsearch
          image: docker.io/bitnami/elasticsearch:8.14.1-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: ELASTICSEARCH_IS_DEDICATED_NODE
              value: "yes"
            - name: ELASTICSEARCH_NODE_ROLES
              value: "ingest"
            - name: ELASTICSEARCH_TRANSPORT_PORT_NUMBER
              value: "9300"
            - name: ELASTICSEARCH_HTTP_PORT_NUMBER
              value: "9200"
            - name: ELASTICSEARCH_CLUSTER_NAME
              value: "elastic"
            - name: ELASTICSEARCH_CLUSTER_HOSTS
              value: "my-release-elasticsearch-master-hl.mastodon.svc.cluster.local,my-release-elasticsearch-coordinating-hl.mastodon.svc.cluster.local,my-release-elasticsearch-data-hl.mastodon.svc.cluster.local,my-release-elasticsearch-ingest-hl.mastodon.svc.cluster.local,"
            - name: ELASTICSEARCH_TOTAL_NODES
              value: "2"
            - name: ELASTICSEARCH_CLUSTER_MASTER_HOSTS
              value: my-release-elasticsearch-master-0 
            - name: ELASTICSEARCH_MINIMUM_MASTER_NODES
              value: "1"
            - name: ELASTICSEARCH_ADVERTISED_HOSTNAME
              value: "$(MY_POD_NAME).my-release-elasticsearch-ingest-hl.mastodon.svc.cluster.local"
            - name: ELASTICSEARCH_HEAP_SIZE
              value: "128m"
          ports:
            - name: rest-api
              containerPort: 9200
            - name: transport
              containerPort: 9300
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: rest-api
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 90
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 768Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 512Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/config
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/tmp
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/logs
              subPath: app-logs-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/plugins
              subPath: app-plugins-dir
            - name: data
              mountPath: /bitnami/elasticsearch/data
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: "data"
          emptyDir: {}
---
# Source: mastodon/charts/elasticsearch/templates/master/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-elasticsearch-master
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/version: 8.14.1
    helm.sh/chart: elasticsearch-21.2.4
    app.kubernetes.io/component: master
    ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
    app: master
spec:
  replicas: 1
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/component: master
  serviceName: my-release-elasticsearch-master-hl
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: elasticsearch
        app.kubernetes.io/version: 8.14.1
        helm.sh/chart: elasticsearch-21.2.4
        app.kubernetes.io/component: master
        ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
        app: master
      annotations:
    spec:
      serviceAccountName: my-release-elasticsearch-master
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/os-shell:12-debian-12-r22
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
            runAsUser: 0
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
        - name: copy-default-plugins
          image: docker.io/bitnami/elasticsearch:8.14.1-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 768Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 512Mi
          command:
            - /bin/bash
          args:
            - -ec
            - |
              #!/bin/bash

              . /opt/bitnami/scripts/libfs.sh
              . /opt/bitnami/scripts/elasticsearch-env.sh

              if ! is_dir_empty "$DB_DEFAULT_PLUGINS_DIR"; then
                  cp -nr "$DB_DEFAULT_PLUGINS_DIR"/* /plugins
              fi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /plugins
              subPath: app-plugins-dir
      containers:
        - name: elasticsearch
          image: docker.io/bitnami/elasticsearch:8.14.1-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: ELASTICSEARCH_IS_DEDICATED_NODE
              value: "yes"
            - name: ELASTICSEARCH_NODE_ROLES
              value: "master"
            - name: ELASTICSEARCH_TRANSPORT_PORT_NUMBER
              value: "9300"
            - name: ELASTICSEARCH_HTTP_PORT_NUMBER
              value: "9200"
            - name: ELASTICSEARCH_CLUSTER_NAME
              value: "elastic"
            
            - name: ELASTICSEARCH_CLUSTER_HOSTS
              value: "my-release-elasticsearch-master-hl.mastodon.svc.cluster.local,my-release-elasticsearch-coordinating-hl.mastodon.svc.cluster.local,my-release-elasticsearch-data-hl.mastodon.svc.cluster.local,my-release-elasticsearch-ingest-hl.mastodon.svc.cluster.local,"
            - name: ELASTICSEARCH_TOTAL_NODES
              value: "2"
            - name: ELASTICSEARCH_CLUSTER_MASTER_HOSTS
              value: my-release-elasticsearch-master-0 
            - name: ELASTICSEARCH_MINIMUM_MASTER_NODES
              value: "1"
            - name: ELASTICSEARCH_ADVERTISED_HOSTNAME
              value: "$(MY_POD_NAME).my-release-elasticsearch-master-hl.mastodon.svc.cluster.local"
            - name: ELASTICSEARCH_HEAP_SIZE
              value: "128m"
          ports:
            - name: rest-api
              containerPort: 9200
            - name: transport
              containerPort: 9300
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: rest-api
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 90
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 768Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 512Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/config
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/tmp
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/logs
              subPath: app-logs-dir
            - name: empty-dir
              mountPath: /opt/bitnami/elasticsearch/plugins
              subPath: app-plugins-dir
            - name: data
              mountPath: /bitnami/elasticsearch/data
      volumes:
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: "data"
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: mastodon/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-postgresql
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.6
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: my-release-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: my-release-postgresql
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 16.3.0
        helm.sh/chart: postgresql-15.5.6
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: my-release-postgresql
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:16.3.0-debian-12-r14
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "bn_mastodon"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "bitnami_mastodon"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "bn_mastodon" -d "dbname=bitnami_mastodon" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "bn_mastodon" -d "dbname=bitnami_mastodon" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/conf
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/tmp
              subPath: app-tmp-dir
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: mastodon/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-redis-master
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.5.4
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
  serviceName: my-release-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: redis
        app.kubernetes.io/version: 7.2.5
        helm.sh/chart: redis-19.5.4
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: 86bcc953bb473748a3d3dc60b7c11f34e60c93519234d4c37f42e22ada559d47
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 560c33ff34d845009b51830c332aa05fa211444d1877d3526d3599be7543aaa5
        checksum/secret: bda1e7a4044636edec7df7c10ac4c49b044bfbf70c9240b839a6672e43b621fe
    spec:
      
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: my-release-redis-master
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      enableServiceLinks: true
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.2.5-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: empty-dir
              mountPath: /opt/bitnami/redis/etc/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
      volumes:
        - name: start-scripts
          configMap:
            name: my-release-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: my-release-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: my-release-redis-configuration
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: redis-data
        labels:
          app.kubernetes.io/instance: my-release
          app.kubernetes.io/name: redis
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: mastodon/charts/minio/templates/provisioning-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-release-minio-provisioning
  namespace: "mastodon"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2024.6.13
    helm.sh/chart: minio-14.6.10
    app.kubernetes.io/component: minio-provisioning
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
spec: 
  parallelism: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: 2024.6.13
        helm.sh/chart: minio-14.6.10
        app.kubernetes.io/component: minio-provisioning
    spec:
      
      restartPolicy: OnFailure
      terminationGracePeriodSeconds: 0
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: my-release-minio
      initContainers:
        - name: wait-for-available-minio
          image: docker.io/bitnami/minio:2024.6.13-debian-12-r2
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
            - -c
            - |-
              set -e;
              echo "Waiting for Minio";
              wait-for-port \
                --host=my-release-minio \
                --state=inuse \
                --timeout=120 \
                80;
              echo "Minio is available";
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
      containers:
        - name: minio
          image: docker.io/bitnami/minio:2024.6.13-debian-12-r2
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
            - -c
            - >-
              set -e;
              echo "Start Minio provisioning";

              function attachPolicy() {
                local tmp=$(mc admin $1 info provisioning $2 | sed -n -e 's/^Policy.*: \(.*\)$/\1/p');
                IFS=',' read -r -a CURRENT_POLICIES <<< "$tmp";
                if [[ ! "${CURRENT_POLICIES[*]}" =~ "$3" ]]; then
                  mc admin policy attach provisioning $3 --$1=$2;
                fi;
              };

              function detachDanglingPolicies() {
                local tmp=$(mc admin $1 info provisioning $2 | sed -n -e 's/^Policy.*: \(.*\)$/\1/p');
                IFS=',' read -r -a CURRENT_POLICIES <<< "$tmp";
                IFS=',' read -r -a DESIRED_POLICIES <<< "$3";
                for current in "${CURRENT_POLICIES[@]}"; do
                  if [[ ! "${DESIRED_POLICIES[*]}" =~ "${current}" ]]; then
                    mc admin policy detach provisioning $current --$1=$2;
                  fi;
                done;
              }

              function addUsersFromFile() {
                local username=$(grep -oP '^username=\K.+' $1);
                local password=$(grep -oP '^password=\K.+' $1);
                local disabled=$(grep -oP '^disabled=\K.+' $1);
                local policies_list=$(grep -oP '^policies=\K.+' $1);
                local set_policies=$(grep -oP '^setPolicies=\K.+' $1);

                mc admin user add provisioning "${username}" "${password}";

                IFS=',' read -r -a POLICIES <<< "${policies_list}";
                for policy in "${POLICIES[@]}"; do
                  attachPolicy user "${username}" "${policy}";
                done;
                if [ "${set_policies}" == "true" ]; then
                  detachDanglingPolicies user "${username}" "${policies_list}";
                fi;

                local user_status="enable";
                if [[ "${disabled}" != "" && "${disabled,,}" == "true" ]]; then
                  user_status="disable";
                fi;

                mc admin user "${user_status}" provisioning "${username}";
              };
              mc alias set provisioning $MINIO_SCHEME://my-release-minio:80 $MINIO_ROOT_USER $MINIO_ROOT_PASSWORD;

              mc admin service restart provisioning;
              
              mc anonymous set download provisioning/s3storage;

              echo "End Minio provisioning";
          env:
            - name: MINIO_SCHEME
              value: "http"
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: my-release-minio
                  key: root-user
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-minio
                  key: root-password
          envFrom:
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /.mc
              subPath: app-mc-dir
            - name: empty-dir
              mountPath: /opt/bitnami/minio/tmp
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: minio-provisioning
              mountPath: /etc/ilm
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: minio-provisioning
          configMap:
            name: my-release-minio-provisioning
