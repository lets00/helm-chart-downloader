---
# Source: graph-node/charts/ipfs/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-ipfs
  labels:
    app.kubernetes.io/name: ipfs
    helm.sh/chart: ipfs-2.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
---
# Source: graph-node/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-graph-node
  labels:
    app.kubernetes.io/name: graph-node
    helm.sh/chart: graph-node-3.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
---
# Source: graph-node/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-graph-node
  labels:
    app.kubernetes.io/name: graph-node
    helm.sh/chart: graph-node-3.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
---
# Source: graph-node/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-graph-node-config
  labels:
    app.kubernetes.io/name: graph-node
    helm.sh/chart: graph-node-3.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  config.toml: "IyBTdG9yZSBjb25maWd1cmF0aW9uCltzdG9yZV0KICBbc3RvcmUucHJpbWFyeV0KICBjb25uZWN0aW9uID0gInBvc3RncmVzcWw6Ly86QDovIgogIHBvb2xfc2l6ZSA9IDMwCiAgd2VpZ2h0ID0gMQojIENoYWluIGNvbmZpZ3VyYXRpb24KW2NoYWluc10KICBpbmdlc3RvciA9ICJteS1yZWxlYXNlLWdyYXBoLW5vZGUtMCIKCiMgRGVwbG95bWVudCBydWxlIGNvbmZpZ3VyYXRpb24KW2RlcGxveW1lbnRdCltbZGVwbG95bWVudC5ydWxlXV0KaW5kZXhlcnMgPSBbICJteS1yZWxlYXNlLWdyYXBoLW5vZGUtMCIgXQpzaGFyZCA9ICJwcmltYXJ5Igo="
---
# Source: graph-node/charts/ipfs/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-ipfs
  labels:
    app.kubernetes.io/name: ipfs
    helm.sh/chart: ipfs-2.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
data:
  IPFS_PATH: "/data"
  IPFS_PROFILE: "server"
  IPFS_FD_MAX: "8192"
  LIBP2P_TCP_REUSEPORT: "true"
  IPFS_LOGGING: "error"
  IPFS_LOGGING_FMT: "color"
  IPFS_FUSE_DEBUG: "false"
  YAMUX_DEBUG: ""
---
# Source: graph-node/charts/ipfs/templates/entrypoint.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-ipfs-entrypoint
  labels:
    app.kubernetes.io/name: ipfs
    helm.sh/chart: ipfs-2.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
data:
  start_ipfs: |
    #!/bin/sh
    set -e
    user=ipfs
    repo="$IPFS_PATH"

    if [ `id -u` -eq 0 ]; then
      echo "Changing user to $user"
      # ensure folder is writable
      su-exec "$user" test -w "$repo" || chown -R -- "$user" "$repo"
      # restart script with new privileges
      exec su-exec "$user" "$0" "$@"
    fi

    # 2nd invocation with regular user
    ipfs version

    if [ -e "$repo/config" ]; then
      echo "Found IPFS fs-repo at $repo"
      echo "Try to migrate existing repo..."
      ipfs repo migrate
    else
      case "$IPFS_PROFILE" in
        "") INIT_ARGS="" ;;
        *) INIT_ARGS="--profile=$IPFS_PROFILE" ;;
      esac
      ipfs init $INIT_ARGS
      ipfs config Addresses.API /ip4/0.0.0.0/tcp/5001
      ipfs config Addresses.Gateway /ip4/0.0.0.0/tcp/8080
      ipfs config --json Peering.Peers "[{\"Addr\": [\"/dnsaddr/node-1.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcFf2FH3CEgTNHeMRGhN7HNHU1EXAxoEk6EFuSyXCsvRE\"}, {\"Addr\": [\"/dnsaddr/node-2.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcFmLd5ySfk2WZuJ1mfSWLDjdmHZq7rSAua4GoeSQfs1z\"}, {\"Addr\": [\"/dnsaddr/node-3.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcfFmzSDVbwexQ9Au2pt5YEXHK5xajwgaU6PpkbLWerMa\"}, {\"Addr\": [\"/dnsaddr/node-4.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcfJeB3Js1FG7T8YaZATEiaHqNKVdQfybYYkbT1knUswx\"}, {\"Addr\": [\"/dnsaddr/node-5.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcfVvzK4tMdFmpJjEKDUoqRgP4W9FnmJoziYX5GXJJ8eZ\"}, {\"Addr\": [\"/dnsaddr/node-6.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcfZD3VKrUxyP9BbyUnZDpbqDnT7cQ4WjPP8TRLXaoE7G\"}, {\"Addr\": [\"/dnsaddr/node-7.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcfZP2LuW4jxviTeG8fi28qjnZScACb8PEgHAc17ZEri3\"}, {\"Addr\": [\"/dnsaddr/node-8.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcfgsJsMtx6qJb74akCw1M24X1zFwgGo11h1cuhwQjtJP\"}, {\"Addr\": [\"/dnsaddr/node-9.ingress.cloudflare-ipfs.com\"], \"ID\": \"Qmcfr2FC7pFzJbTSDfYaSy1J8Uuy8ccGLeLyqJCKJvTHMi\"}, {\"Addr\": [\"/dnsaddr/node-10.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcfR3V5YAtHBzxVACWCzXTt26SyEkxdwhGJ6875A8BuWx\"}, {\"Addr\": [\"/dnsaddr/node-11.ingress.cloudflare-ipfs.com\"], \"ID\": \"Qmcfuo1TM9uUiJp6dTbm915Rf1aTqm3a3dnmCdDQLHgvL5\"}, {\"Addr\": [\"/dnsaddr/node-12.ingress.cloudflare-ipfs.com\"], \"ID\": \"QmcfV2sg9zaq7UUHVCGuSvT2M2rnLBAPsiE79vVyK3Cuev\"}, {\"Addr\": [\"/dnsaddr/fra1-1.hostnodes.pinata.cloud\"], \"ID\": \"QmWaik1eJcGHq1ybTWe7sezRfqKNcDRNkeBaLnGwQJz1Cj\"}, {\"Addr\": [\"/dnsaddr/fra1-2.hostnodes.pinata.cloud\"], \"ID\": \"QmNfpLrQQZr5Ns9FAJKpyzgnDL2GgC6xBug1yUZozKFgu4\"}, {\"Addr\": [\"/dnsaddr/fra1-3.hostnodes.pinata.cloud\"], \"ID\": \"QmPo1ygpngghu5it8u4Mr3ym6SEU2Wp2wA66Z91Y1S1g29\"}, {\"Addr\": [\"/dnsaddr/nyc1-1.hostnodes.pinata.cloud\"], \"ID\": \"QmRjLSisUCHVpFa5ELVvX3qVPfdxajxWJEHs9kN3EcxAW6\"}, {\"Addr\": [\"/dnsaddr/nyc1-2.hostnodes.pinata.cloud\"], \"ID\": \"QmPySsdmbczdZYBpbi2oq2WMJ8ErbfxtkG8Mo192UHkfGP\"}, {\"Addr\": [\"/dnsaddr/nyc1-3.hostnodes.pinata.cloud\"], \"ID\": \"QmSarArpxemsPESa6FNkmuu9iSE1QWqPX2R3Aw6f5jq4D5\"}]"


      # Set up the swarm key, if provided

      SWARM_KEY_FILE="$repo/swarm.key"
      SWARM_KEY_PERM=0400

      # Create a swarm key from a given environment variable
      if [ ! -z "$IPFS_SWARM_KEY" ] ; then
        echo "Copying swarm key from variable..."
        echo -e "$IPFS_SWARM_KEY" >"$SWARM_KEY_FILE" || exit 1
        chmod $SWARM_KEY_PERM "$SWARM_KEY_FILE"
      fi

      # Unset the swarm key variable
      unset IPFS_SWARM_KEY

      # Check during initialization if a swarm key was provided and
      # copy it to the ipfs directory with the right permissions
      # WARNING: This will replace the swarm key if it exists
      if [ ! -z "$IPFS_SWARM_KEY_FILE" ] ; then
        echo "Copying swarm key from file..."
        install -m $SWARM_KEY_PERM "$IPFS_SWARM_KEY_FILE" "$SWARM_KEY_FILE" || exit 1
      fi

      # Unset the swarm key file variable
      unset IPFS_SWARM_KEY_FILE

    fi

    exec ipfs "$@"
---
# Source: graph-node/charts/ipfs/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-ipfs
  labels:
    app.kubernetes.io/name: ipfs
    helm.sh/chart: ipfs-2.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 4001
      targetPort: p2p-tcp
      protocol: TCP
      name: p2p-tcp
    - port: 4001
      targetPort: p2p-udp
      protocol: UDP
      name: p2p-udp
    - port: 5001
      targetPort: api
      protocol: TCP
      name: api
    - port: 8080
      targetPort: gateway
      protocol: TCP
      name: gateway
    - port: 8081
      targetPort: websocket
      protocol: TCP
      name: websocket
  selector:
    app.kubernetes.io/name: ipfs
    app.kubernetes.io/instance: my-release
---
# Source: graph-node/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-graph-node
  labels:
    app.kubernetes.io/name: graph-node
    helm.sh/chart: graph-node-3.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: http
      protocol: TCP
      name: http
    - port: 8001
      targetPort: websocket
      protocol: TCP
      name: websocket
    - port: 8020
      targetPort: jsonrpc
      protocol: TCP
      name: jsonrpc
    - port: 8030
      targetPort: index-status
      protocol: TCP
      name: index-status
    - port: 8040
      targetPort: metrics
      protocol: TCP
      name: metrics
  selector:
    app.kubernetes.io/name: graph-node
    app.kubernetes.io/instance: my-release
---
# Source: graph-node/charts/ipfs/templates/statefulset.yaml
kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: my-release-ipfs
  labels:
    app.kubernetes.io/name: ipfs
    helm.sh/chart: ipfs-2.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: ipfs
      app.kubernetes.io/instance: my-release
  serviceName: my-release-ipfs
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ipfs
        app.kubernetes.io/instance: my-release
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: my-release-ipfs
      priorityClassName: ""
      initContainers:
        - name: init-chown
          image: "docker.io/busybox:1.34"
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 0
          command: ["chown", "-R", "1001:1001", "/data"]
          volumeMounts:
            - name: data
              mountPath: /data
      containers:
        - name: my-release-ipfs
          image: "docker.io/ipfs/kubo:v0.24.0"
          imagePullPolicy: IfNotPresent
          args: [
            "daemon",
            "--mount-ipns=/data/ipns",
            "--mount-ipfs=/data/ipfs"
          ]
          envFrom:
            - configMapRef:
                name: my-release-ipfs
          ports:
            - containerPort: 4001
              name: p2p-tcp
              protocol: TCP
            - containerPort: 4001
              name: p2p-udp
              protocol: UDP
            - containerPort: 5001
              name: api
              protocol: TCP
            - containerPort: 8080
              name: gateway
              protocol: TCP
            - containerPort: 8081
              name: websocket
              protocol: TCP
          volumeMounts:
            - name: data
              mountPath: /data
            - name: entrypoint
              subPath: start_ipfs
              mountPath: /usr/local/bin/start_ipfs
          livenessProbe:
            httpGet:
              path: /debug/metrics/prometheus
              port: api
            initialDelaySeconds: 15
            periodSeconds: 3
          readinessProbe:
            httpGet:
              path: /debug/metrics/prometheus
              port: api
            initialDelaySeconds: 15
            periodSeconds: 3
      volumes:
        - name: entrypoint
          configMap:
            name: my-release-ipfs-entrypoint
            defaultMode: 0777
  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app.kubernetes.io/name: ipfs
          helm.sh/chart: ipfs-2.0.4
          app.kubernetes.io/instance: my-release
          app.kubernetes.io/managed-by: Helm
      spec:
        accessModes: [ReadWriteOnce]
        storageClassName: 
        resources:
          requests:
            storage: "25Gi"
---
# Source: graph-node/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-graph-node
  labels:
    app.kubernetes.io/name: graph-node
    helm.sh/chart: graph-node-3.0.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  podManagementPolicy: "Parallel"
  selector:
    matchLabels:
      app.kubernetes.io/name: graph-node
      app.kubernetes.io/instance: my-release
  serviceName: my-release-graph-node
  template:
    metadata:
      annotations:
        checksum/config.toml: 545b316a00be81c7abf59d2fd9e2bafeee98a64f200793f1f61dd651b79ce544
        checksum/graph-secret: f7f29d7f9c3a0c4804d2deded5b3c608e6bfd70a9d09f2f8b923a2bec2b38130
      labels:
        app.kubernetes.io/name: graph-node
        app.kubernetes.io/instance: my-release
    spec:
      serviceAccountName: my-release-graph-node
      securityContext:
        null
      priorityClassName: ""
      containers:
        - name: graph-node
          command:
            - graph-node
            - --config=/config/config.toml
          securityContext:
            null
          image: "docker.io/graphprotocol/graph-node:v0.35.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: GRAPH_NODE_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: IPFS
              value: "my-release-ipfs:5001"
            - name: ETHEREUM_BLOCK_BATCH_SIZE
              value: "50"
            - name: ETHEREUM_POLLING_INTERVAL
              value: "500"
            - name: EXPERIMENTAL_SUBGRAPH_VERSION_SWITCHING_MODE
              value: "synced"
            - name: GRAPH_ALLOW_NON_DETERMINISTIC_IPFS
              value: "true"
            - name: GRAPH_ETHEREUM_MAX_BLOCK_RANGE_SIZE
              value: "1000"
            - name: GRAPH_GRAPHQL_DISABLE_BOOL_FILTERS
              value: "false"
            - name: GRAPH_IPFS_TIMEOUT
              value: "300"
            - name: GRAPH_LOG
              value: "info"
            - name: GRAPH_MAX_IPFS_FILE_BYTES
              value: "1048576"
            - name: STORE_CONNECTION_POOL_SIZE
              value: "25"
          envFrom:
            - secretRef:
                name: my-release-graph-node
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
            - name: websocket
              containerPort: 8001
              protocol: TCP
            - name: jsonrpc
              containerPort: 8020
              protocol: TCP
            - name: index-status
              containerPort: 8030
              protocol: TCP
            - name: metrics
              containerPort: 8040
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            {}
          volumeMounts:
          - name: config
            mountPath: "/config"
            readOnly: true
      volumes:
        - name: config
          secret:
            secretName: my-release-graph-node-config
