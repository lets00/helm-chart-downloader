---
# Source: kafka/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-kafka
  labels:
    helm.sh/chart: kafka-16.1.1
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v3.6.2"
    app.kubernetes.io/managed-by: Helm
---
# Source: kafka/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-kafka-cluster-id
  labels:
    helm.sh/chart: kafka-16.1.1
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v3.6.2"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  clusterId: "TkRsbVpXVTVZVEl0WVRoak5pMDBaag=="
---
# Source: kafka/templates/broker/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-kafka-broker
  labels:
    helm.sh/chart: kafka-16.1.1
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v3.6.2"
    app.kubernetes.io/managed-by: Helm
    component: "broker_controller"
data:
  ## /etc/kafka/base/server.properties
  server.properties: |
    num.partitions=2
---
# Source: kafka/templates/cm-entrypoint.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-kafka-entrypoint
  labels:
    helm.sh/chart: kafka-16.1.1
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v3.6.2"
    app.kubernetes.io/managed-by: Helm
    component: "broker_controller"
data:
  entrypoint.sh: |
    #!/bin/bash
    
    export KAFKA_CONF_FILE="/etc/kafka/server.properties"
    export KAFKA_BASE_CONF_FILE="${KAFKA_BASE_CONF_FILE:=/etc/kafka/base/server.properties}"

    export KAFKA_CFG_LOG_DIR="$KAFKA_HOME/data"
    
    if [[ -z "$KAFKA_HOME" ]]; then
      export KAFKA_HOME="/opt/kafka"
      export KAFKA_CFG_LOG_DIR="$KAFKA_HOME/data"
    fi
    if [[ ! -d "$KAFKA_HOME" ]]; then
      mkdir -p "$KAFKA_HOME"
    fi
    
    check_runtime() {
      java -version
      if [[ $? -ne 0 ]]; then
        echo "[ERROR] Missing java"
        exit "500"
      fi
    }
    
    run_as_other_user_if_needed() {
      if [[ "$(id -u)" == "0" ]]; then
        # If running as root, drop to specified UID and run command
        exec chroot --userspec=1000:0 / "${@}"
      else
        # Either we are running in Openshift with random uid and are a member of the root group
        # or with a custom --user
        exec "${@}"
      fi
    }
    
    get_nodeid_from_suffix() {
      local line="$1"
      local index="${line##*-}"
      if [[ "$index" =~ ^[0-9]+$ ]]; then
        export KAFKA_CFG_NODE_ID="$index"
        if [[ "$KAFKA_NODE_ID_OFFSET" =~ ^[0-9]+$ ]]; then
          if [[ $KAFKA_NODE_ID_OFFSET -gt "0" ]]; then
            export KAFKA_CFG_NODE_ID="$((index + KAFKA_NODE_ID_OFFSET))"
          fi
        fi
      fi
    }
    
    fix_external_advertised_listeners() {
      if [[ -z "$KAFKA_EXTERNAL_SERVICE_TYPE" ]]; then
        return
      fi
      if [[ -z "$KAFKA_EXTERNAL_ADVERTISED_LISTENERS" ]]; then
        return
      fi
      local ext_listeners="$KAFKA_EXTERNAL_ADVERTISED_LISTENERS"
      local i="${POD_NAME##*-}"
      local listener=$(echo "$ext_listeners" | cut -d "," -f $((i+1)) | sed 's/ //g')
      if [[ "$KAFKA_EXTERNAL_SERVICE_TYPE" == "NodePort" ]]; then
        listener=$(echo "$listener" | sed -E "s%://[^:]*:%://${POD_HOST_IP}:%")
      fi
      if [[ "$listener" =~ ://[^:]*:[0-9]+$ ]]; then
        export KAFKA_CFG_ADVERTISED_LISTENERS="${KAFKA_CFG_ADVERTISED_LISTENERS},${listener}"
        echo "KAFKA_CFG_ADVERTISED_LISTENERS: $KAFKA_CFG_ADVERTISED_LISTENERS"
      else
        echo "[WARN] KAFKA_EXTERNAL_ADVERTISED_LISTENER invalid, value: [$listener]"
      fi
    }
    
    init_nodeid() {
      if [[ "$KAFKA_NODE_ID" =~ ^[0-9]+$ ]]; then
        export KAFKA_CFG_NODE_ID="$KAFKA_NODE_ID"
        return
      fi
      if [[ "$KAFKA_NODE_ID" = hostname* ]]; then
        get_nodeid_from_suffix "$HOSTNAME"
      elif [[ "$KAFKA_NODE_ID" = pod* ]]; then
        if [[ -n "$POD_NAME" ]]; then
          get_nodeid_from_suffix "$POD_NAME"
        fi
      fi
      if [[ -z "$KAFKA_CFG_NODE_ID" ]]; then
        export KAFKA_CFG_NODE_ID="1"
      fi
    }
    
    take_file_ownership() {
      if [[ "$(id -u)" == "0" ]]; then
        chown -R 1000:0 "$KAFKA_HOME"
        if [[ -d "$KAFKA_CFG_LOG_DIR" ]]; then
          chown -R 1000:0 "$KAFKA_CFG_LOG_DIR"
        fi
      fi
    }
    
    update_server_conf() {
      local key=$1
      local value=$2
      local pattern="$(echo $key | sed 's/\./\\./')"
      sed -i "/^${pattern} *=/d" "$KAFKA_CONF_FILE"
      echo "${key}=${value}" >> "$KAFKA_CONF_FILE"
    }
    
    set_kafka_cfg_default() {
      if [[ -z "$KAFKA_CFG_NODE_ID" ]]; then
        export KAFKA_CFG_NODE_ID="1"
      fi
      if [[ -z "$KAFKA_CFG_PROCESS_ROLES" ]]; then
        export KAFKA_CFG_PROCESS_ROLES="broker,controller"
      fi
      if [[ -z "$KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP" ]]; then
        export KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP="CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
      fi
      if [[ -z "$KAFKA_CFG_INTER_BROKER_LISTENER_NAME" ]]; then
        export KAFKA_CFG_INTER_BROKER_LISTENER_NAME="PLAINTEXT"
      fi
      if [[ -z "$KAFKA_CFG_CONTROLLER_LISTENER_NAMES" ]]; then
        export KAFKA_CFG_CONTROLLER_LISTENER_NAMES="CONTROLLER"
      fi
      if [[ -z "$KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR" ]]; then
        export KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR="1"
      fi
      if [[ -z "$KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR" ]]; then
        export KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR="1"
      fi
      if [[ -z "$KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR" ]]; then
        export KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR="1"
      fi
      ##
      ## KAFKA_CONTROLLER_LISTENER_PORT default value: 19091
      local ctl_port="${KAFKA_CONTROLLER_LISTENER_PORT-19091}"
      ## KAFKA_BROKER_LISTENER_PORT default value: 9092
      local broker_port="${KAFKA_BROKER_LISTENER_PORT-9092}"
      if [[ -z "$KAFKA_CFG_LISTENERS" ]]; then
        export KAFKA_CFG_LISTENERS="CONTROLLER://:${ctl_port},PLAINTEXT://:${broker_port}"
      fi
      if [[ -z "$KAFKA_CFG_CONTROLLER_QUORUM_VOTERS" ]]; then
        export KAFKA_CFG_CONTROLLER_QUORUM_VOTERS="${KAFKA_CFG_NODE_ID}@127.0.0.1:${ctl_port}"
      fi
    }
    
    init_server_conf() {
      init_nodeid
      set_kafka_cfg_default
      fix_external_advertised_listeners
      if [[ ! -f "$KAFKA_CONF_FILE" ]]; then
        mkdir -p "$(dirname $KAFKA_CONF_FILE)"
        if [[ -f "$KAFKA_BASE_CONF_FILE" ]]; then
          cat "$KAFKA_BASE_CONF_FILE" > $KAFKA_CONF_FILE
        fi
        touch "$KAFKA_CONF_FILE"
      fi
      for var in "${!KAFKA_CFG_@}"; do
        # printf '%s=%s\n' "$var" "${!var}"
        key="$(echo "$var" | sed -e 's/^KAFKA_CFG_//' -e 's/_/./g' | tr 'A-Z' 'a-z')"
        value="${!var}"
        update_server_conf "$key" "$value"
      done
    }
    
    reset_log_dirs() {
      ## protect log.dirs
      sed -i "/^log.dir *=/d" "$KAFKA_CONF_FILE"
      update_server_conf "log.dirs" "$KAFKA_CFG_LOG_DIR"
    }
    
    start_server() {
      check_runtime
      reset_log_dirs
      if [[ -n "$KAFKA_HEAP_OPTS" ]]; then
        export JAVA_TOOL_OPTIONS="${JAVA_TOOL_OPTIONS} ${KAFKA_HEAP_OPTS}"
      fi
      if [[ ! -f "$KAFKA_CFG_LOG_DIR/meta.properties" ]]; then
        echo ">>> Format Log Directories <<<"
        if [[ -z "$KAFKA_CLUSTER_ID" ]]; then
          echo "Generate a Cluster UUID"
          export KAFKA_CLUSTER_ID="$(${KAFKA_HOME}/bin/kafka-storage.sh random-uuid)"
        fi
        cat "$KAFKA_CONF_FILE"
        if [[ "$(id -u)" == "0" ]]; then
          chroot --userspec=1000:0 / ${KAFKA_HOME}/bin/kafka-storage.sh format \
            -t $KAFKA_CLUSTER_ID -c "$KAFKA_CONF_FILE"
        else
          ${KAFKA_HOME}/bin/kafka-storage.sh format \
            -t $KAFKA_CLUSTER_ID -c "$KAFKA_CONF_FILE"
        fi
      fi
      run_as_other_user_if_needed "${KAFKA_HOME}/bin/kafka-server-start.sh" "$KAFKA_CONF_FILE"
    }
    
    init_server_conf
    take_file_ownership
    if [[ "$@" = "start" ]]; then
      start_server
    else
      exec "$@"
    fi
---
# Source: kafka/templates/broker/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-kafka-headless
  labels:
    helm.sh/chart: kafka-16.1.1
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v3.6.2"
    app.kubernetes.io/managed-by: Helm
    component: "broker_controller"
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - port: 9092
      targetPort: broker
      protocol: TCP
      name: broker
    - port: 9090
      targetPort: controller
      protocol: TCP
      name: controller
  selector:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    component: "broker_controller"
---
# Source: kafka/templates/broker/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-kafka-broker
  labels:
    helm.sh/chart: kafka-16.1.1
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v3.6.2"
    app.kubernetes.io/managed-by: Helm
    component: "broker_controller"
spec:
  type: "ClusterIP"
  ports:
    - name: broker
      port: 9092
      targetPort: broker
      protocol: TCP
  selector:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    component: "broker_controller"
---
# Source: kafka/templates/broker/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-kafka-broker
  labels:
    helm.sh/chart: kafka-16.1.1
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v3.6.2"
    app.kubernetes.io/managed-by: Helm
    component: "broker_controller"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
      app.kubernetes.io/instance: my-release
      component: "broker_controller"
  serviceName: my-release-kafka-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kafka
        app.kubernetes.io/instance: my-release
        component: "broker_controller"
    spec:
      serviceAccountName: my-release-kafka
      securityContext:
        null
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 5
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: kafka
                  app.kubernetes.io/instance: my-release
                  component: "broker_controller"
              topologyKey: "kubernetes.io/hostname"
      containers:
      - name: kafka
        image: "kafkace/kafka:v3.6.1"
        imagePullPolicy: "IfNotPresent"
        env:
        - name: POD_HOST_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_HEAP_OPTS
          value: "-Xms1024m -Xmx1024m"
        - name: KAFKA_CFG_PROCESS_ROLES
          value: "broker,controller"
        - name: KAFKA_CFG_LISTENERS
          value: "BROKER://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095,CONTROLLER://0.0.0.0:9090"
        - name: KAFKA_CFG_ADVERTISED_LISTENERS
          value: "BROKER://$(POD_NAME).my-release-kafka-headless.kafka-16.1.1.tgz.svc.cluster.local:9092"
        - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
          value: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT
        - name: KAFKA_CFG_INTER_BROKER_LISTENER_NAME
          value: BROKER
        - name: KAFKA_CFG_CONTROLLER_LISTENER_NAMES
          value: CONTROLLER
        - name: KAFKA_CFG_CONTROLLER_QUORUM_VOTERS
          value: 0@my-release-kafka-broker-0.my-release-kafka-headless.kafka-16.1.1.tgz.svc.cluster.local:9090
        - name: KAFKA_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              name: my-release-kafka-cluster-id
              key: clusterId
        - name: KAFKA_NODE_ID
          value: "podnameSuffix"
        - name: KAFKA_BASE_CONF_FILE
          value: /etc/kafka/base/server.properties
        ports:
        - containerPort: 9092
          name: broker
          protocol: TCP
        - containerPort: 9090
          name: controller
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - bin/kafka-broker-api-versions.sh --bootstrap-server=127.0.0.1:9092
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 20
          timeoutSeconds: 5
        resources:
          limits:
            cpu: 4
            memory: 16Gi
          requests:
            cpu: 200m
            memory: 2Gi
        volumeMounts:
        - mountPath: /opt/kafka/data
          name: data
          subPath: data
        - mountPath: /opt/kafka/logs
          name: data
          subPath: logs
        - mountPath: /etc/kafka/base/server.properties
          name: base-config
          subPath: server.properties
        - mountPath: /entrypoint.sh
          name: entrypoint-sh
          subPath: entrypoint.sh
        lifecycle:
          preStop:
            exec:
              command: ["sh", "-c", "sleep 10; bin/kafka-server-stop.sh"]
      terminationGracePeriodSeconds: 60
      volumes:
      - name: base-config
        configMap:
          items:
          - key: server.properties
            path: server.properties
          name: my-release-kafka-broker
      - name: entrypoint-sh
        configMap:
          items:
          - key: entrypoint.sh
            path: entrypoint.sh
          name: my-release-kafka-entrypoint
          defaultMode: 0744
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: "30Gi"
