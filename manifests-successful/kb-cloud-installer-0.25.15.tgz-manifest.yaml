---
# Source: kb-cloud-installer/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kb-cloud-installer
  labels:
    helm.sh/chart: kb-cloud-installer-0.25.15
    app.kubernetes.io/name: kb-cloud-installer
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: kb-cloud-installer/templates/scripts.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kb-cloud-installer-scripts
  labels:
    helm.sh/chart: kb-cloud-installer-0.25.15
    app.kubernetes.io/name: kb-cloud-installer
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  
  db-init.sh: |-
    #!/bin/bash
    
    function get_meta_db_dsn() {
        local database=$1
        local host
        local port
        local user
        local password
        if [ "$META_DB_TYPE" == "external" ]; then
            host="$EXTERNAL_META_DB_HOST"
            port="$EXTERNAL_META_DB_PORT"
            user="$EXTERNAL_META_DB_USER"
            password="$EXTERNAL_META_DB_PASSWORD"
        else
            local pg_conn_credential="${pg_name}-conn-credential"
            host=$(kubectl get secret "$pg_conn_credential" -n "$NAMESPACE" -o jsonpath='{.data.host}' | base64 -d).$NAMESPACE
            port=$(kubectl get secret "$pg_conn_credential" -n "$NAMESPACE" -o jsonpath='{.data.port}' | base64 -d)
            user=$(kubectl get secret "$pg_conn_credential" -n "$NAMESPACE" -o jsonpath='{.data.username}' | base64 -d)
            password=$(kubectl get secret "$pg_conn_credential" -n "$NAMESPACE" -o jsonpath='{.data.password}' | base64 -d)
        fi
        echo "postgres://$user:$password@$host:$port/$database?sslmode=disable"
    }
    
    function create_databases() {
        if [ "$INIT_META_DB" == false ]; then
            echo "INIT_META_DB is false, skip init meta database"
            return
        fi
    
        local database="postgres"
        if [ "$META_DB_TYPE" == "external" ]; then
            database="$EXTERNAL_META_DB_DATABASE"
        fi
        dsn=$(get_meta_db_dsn "$database")
        echo "meta database $dsn"
    
        # SQLsï¼Œabout kubeblockscloud,frontend,logto and grafana
        sqls=(
            "create database kubeblockscloud;"
            "create user kubeblockscloud with encrypted password '$META_DB_PASSWORD';"
            "grant all privileges on database kubeblockscloud to kubeblockscloud;"
            "create database cloud_frontend;"
            "create user cloud_frontend with encrypted password '$META_DB_PASSWORD';"
            "grant all privileges on database cloud_frontend to cloud_frontend;"
            "create database logto;"
            "create user logto with encrypted password '$META_DB_PASSWORD';"
            "grant all privileges on database logto to logto;"
            "ALTER USER logto CREATEROLE;"
            "create database grafana;"
            "grant all privileges on database grafana to kubeblockscloud;"
        )
    
        if [ "$DEBUG" = "true" ]; then
            echo "sqls to execute:" "${sqls[@]}"
        fi
    
        for sql in "${sqls[@]}"; do
            psql "${dsn}" -a -c "$sql"
        done
    }
    
    function get_cluster_status() {
        local name=$1
        local namespace=$2
        kbcli -n "$namespace" cluster list "$name" --output json | jq -r '.status.phase'
    }
    
    # check if cluster is running
    function wait_clusters_running() {
        local times=0
        while true; do
            if [[ $times -gt 300 ]]; then
                echo "Timeout: Cluster did not reach running state within 300 checks"
                exit 1
            fi
    
            # get cluster status
            pg_status=$(get_cluster_status "$pg_name" "$NAMESPACE")
            if [ "$pg_status" = "Running" ]; then
                echo "Cluster $pg_name is running, performing subsequent operations..."
                # exit loop
                break
            fi
            times=$((times + 1))
            sleep 5
            echo "Checking cluster status (attempt $times)..."
        done
    }
    
    function check_max_connections() {
        local times=0
        local max_connections=$1
        dsn=$(get_meta_db_dsn "postgres")
        echo "check max_connections ..."
        while true; do
            if [[ $times -gt 300 ]]; then
                echo "Timeout: Cluster max_connections did not reach 1000 within 300 checks"
                exit 1
            fi
            result=$(psql "${dsn}" -t -c "SHOW max_connections;" 2>/dev/null)
            result=$(echo $result | xargs)
            if [ "$result" == "$max_connections" ]; then
                echo "max_connections is set to $max_connections."
                break
            else
                echo "max_connections is not set to $max_connections. Current value: $result"
                echo "Waiting for 5 seconds before retrying..."
                sleep 5
            fi
        done
    }
    
    function create_clusters() {
        # create postgresql
        echo "create postgresql cluster ... "
        kbcli -n "$NAMESPACE" cluster create $pg_name --cluster-definition=postgresql --cluster-version=postgresql-14.8.0 --set cpu=1,memory=1Gi,storage=20Gi,replicas=1
    
        echo "wait clusters running ... "
        wait_clusters_running
        echo "Cluster started successfully!"
    
        echo "set meta database max_connections ... "
        kbcli -n "$NAMESPACE" cluster configure $pg_name --components postgresql --set max_connections=1000
    
        # wait max_connections set
        set +e
        check_max_connections 1000
        set -e
    
        # init database
        create_databases
    }
    
    function check_cluster_exist() {
        local cluster_name=$1
        local namespace=$2
        if kbcli -n "$namespace" cluster list "$cluster_name" >/dev/null 2>&1; then
            echo "true"
        else
            echo "false"
        fi
    }
    
    function check_ns_exist() {
        local namespace=$1
        if kubectl get ns "$namespace" >/dev/null 2>&1; then
            echo "true"
        else
            echo "false"
        fi
    }
    
    # create postgresql cluster and init database
    function init_meta_database_in_kubeblocks() {
        # create namespace
        echo "create namespace $NAMESPACE"
        ns_exist=$(check_ns_exist "$NAMESPACE")
        if [ "$ns_exist" = "true" ]; then
            echo "$NAMESPACE exists"
        else
            echo "$NAMESPACE not exists"
            kubectl create ns "$NAMESPACE"
        fi
    
        # check if cluster already created
        pg_exist=$(check_cluster_exist "$pg_name" "$NAMESPACE")
        if [ "$pg_exist" = "true" ]; then
            echo "Cluster $pg_name already exist"
            # get cluster status
            wait_clusters_running
    
            # try to init database, maybe some database already exists that will
            # cause error, so we ignore the error
            set +e
            create_databases || true
            set -e
        else
            create_clusters
        fi
        echo "init meta databases done"
    }
    
  installer.sh: |-
    #!/bin/bash
    
    set -e
    
    source "./scripts/precheck.sh"
    source "./scripts/kubeblocks.sh"
    source "./scripts/db-init.sh"
    source "./scripts/logto.sh"
    
    pg_name="apecloud-pg"
    cloud_release_name="$NAME"
    
    if [ "$DEBUG" = "true" ]; then
        set -x
    fi
    
    function install_cloud() {
        local values_path="/installer/values/values.example.yaml"
    
        local meta_db_host
        local meta_db_port
        local meta_db_host_port
        if [ "$META_DB_TYPE" == "external" ]; then
            meta_db_host="$EXTERNAL_META_DB_HOST"
            meta_db_port="$EXTERNAL_META_DB_PORT"
            meta_db_host_port="${EXTERNAL_META_DB_HOST}:${EXTERNAL_META_DB_PORT}"
        else
            meta_db_host="${pg_name}-postgresql.$NAMESPACE"
            meta_db_port="5432"
            meta_db_host_port="${pg_name}-postgresql.$NAMESPACE:$meta_db_port"
        fi
    
        # set the database URL
        local kubeblockscloud_dsn="postgres://kubeblockscloud:$META_DB_PASSWORD@$meta_db_host_port/kubeblockscloud?sslmode=disable"
        local cloud_frontend_db_addr="$meta_db_host"
        local grafana_dsn="postgres://kubeblockscloud:$META_DB_PASSWORD@$meta_db_host_port/grafana?sslmode=disable"
    
        local grafana_host="${cloud_release_name}-grafana:80"
        local apiserver_endpoint_domain="http://api.$DOMAIN"
        local apiserver_endpoint="http://apiserver:8080"
    
        local idp_issue_url=""
        local auth_domain=""
        # generate the idp issue url
        if [ "$LOGTO_ENABLED" = "true" ]; then
            if [ "$KUBE_PROVIDER" = "k3d" ]; then
                idp_issue_url="http://logto-core.$NAMESPACE.svc.cluster.local:3001/oidc"
            else
                idp_issue_url="http://$LOGTO_HOST_IP:3001/oidc"
            fi
            auth_domain="http://$LOGTO_HOST_IP:3001/"
        fi
    
        image_version="v${CLOUD_VERSION}"
        install_cmd=(
            helm install "$cloud_release_name" "charts/kubeblocks-cloud-v${CLOUD_VERSION}.tgz"
            -f "$values_path" -n "$NAMESPACE" --create-namespace
            --timeout=30m --wait
            # images
            --set images.registry="$IMAGE_REGISTRY"
            --set images.sentry.tag="$image_version"
            --set images.sentryInit.tag="$image_version"
            --set images.relay.tag="$image_version"
            --set images.prompt.tag="$image_version"
            --set images.apiserver.tag="$image_version"
            --set images.openconsole.tag="$image_version"
            --set images.taskManager.tag="$image_version"
            --set images.cr4w.tag="$image_version"
            --set images.busybox.repository="apecloud/busybox"
            # deploy
            --set deploy.postgresql.dsn="$kubeblockscloud_dsn"
            --set deploy.postgresql.password="$META_DB_PASSWORD"
            --set deploy.apiserver.grafanaHost="$grafana_host"
            --set deploy.apiserver.alertConfigMapNamespace="$NAMESPACE"
            --set deploy.apiserver.idpIssuerUrl="$idp_issue_url"
            --set deploy.apiserver.imageRegistry="$IMAGE_REGISTRY"
            --set deploy.apiserver.engineOptionDatasourceType="$ENGINE_OPTION_DATASOURCE_TYPE"
            --set deploy.apiserver.initEngineOptions="true"
            --set deploy.apiserver.featureGates="$FEATURE_GATES"
            --set deploy.taskManager.apiserverEndpoint="$apiserver_endpoint_domain"
            --set deploy.openconsole.db.addr="$cloud_frontend_db_addr"
            --set deploy.openconsole.db.port="$meta_db_port"
            --set deploy.openconsole.db.name="cloud_frontend"
            --set deploy.openconsole.db.username="cloud_frontend"
            --set deploy.openconsole.db.password="$META_DB_PASSWORD"
            --set deploy.openconsole.yarnOpts="init-start"
            --set deploy.openconsole.openapiServerEndpoint="$apiserver_endpoint_domain"
            --set deploy.openconsole.authDomain="$auth_domain"
            --set deploy.prompt.apiserverEndpoint="$apiserver_endpoint"
            # fqdn
            --set fqdn.domain="$DOMAIN"
            # ingress
            --set ingress.className="$INGRESS_CLASS_NAME"
            # grafana
            --set "grafana.grafana\\.ini.database.url=$grafana_dsn"
            --set "grafana.grafana\\.ini.database.user=kubeblockscloud"
            --set "grafana.grafana\\.ini.database.password=$META_DB_PASSWORD"
            --set "grafana.grafana\\.ini.server.root_url=$apiserver_endpoint_domain/dashboard/v1"
            --set grafana.image.repository="$IMAGE_REGISTRY/apecloud/grafana"
            # vmalert
            --set vmalert.init=true
            # servicemirror
            --set servicemirror.image.repository="$IMAGE_REGISTRY/apecloud/servicemirror"
            # argo-workflows
            --set argo-workflows.controller.image.registry="$IMAGE_REGISTRY"
            --set argo-workflows.controller.image.repository=apecloud/workflow-controller
            --set argo-workflows.server.image.registry="$IMAGE_REGISTRY"
            --set argo-workflows.server.image.repository=apecloud/argocli
            --set argo-workflows.executor.image.registry="$IMAGE_REGISTRY"
            --set argo-workflows.executor.image.repository=apecloud/argoexec
        )
        if [ "$DEBUG" = "true" ]; then
            install_cmd+=("--debug")
        fi
        if [ -n "$EXTRA_VALUES" ]; then
            install_cmd+=(--set "$EXTRA_VALUES")
        fi
        echo "${install_cmd[@]}"
        "${install_cmd[@]}"
    
        # after first installation, upgrade the values
        # update grafana key
        grafana_admin_password=$(kubectl get secret "${cloud_release_name}-grafana" -o jsonpath="{.data.admin-password}" -n "$NAMESPACE" | base64 -d)
        upgrade_cmd=(
            helm -n "$NAMESPACE" upgrade "$cloud_release_name" "charts/kubeblocks-cloud-v${CLOUD_VERSION}.tgz"
            --wait --timeout=30m
            --reset-then-reuse-values
            --set deploy.apiserver.grafanaPassword="$grafana_admin_password"
            --set deploy.apiserver.initEngineOptions="false"
            --set deploy.openconsole.yarnOpts="start"
            --set vmalert.init="false"
        )
        if [ "$DEBUG" = "true" ]; then
            upgrade_cmd+=("--debug")
        fi
        echo "${upgrade_cmd[@]}"
        "${upgrade_cmd[@]}"
    
        # restart apiserver, make sure the new grafana password take effect
        echo "restart apiserver ..."
        kubectl -n "$NAMESPACE" rollout restart deployment apiserver
    }
    
    function upgrade() {
        image_version="v${CLOUD_VERSION}"
        upgrade_cmd=(
            helm -n "$NAMESPACE" upgrade "$cloud_release_name" "charts/kubeblocks-cloud-v${CLOUD_VERSION}.tgz"
            --reset-then-reuse-values
            --timeout=30m --wait
            # images
            --set images.sentry.tag="$image_version"
            --set images.sentryInit.tag="$image_version"
            --set images.relay.tag="$image_version"
            --set images.prompt.tag="$image_version"
            --set images.apiserver.tag="$image_version"
            --set images.openconsole.tag="$image_version"
            --set images.taskManager.tag="$image_version"
            --set images.cr4w.tag="$image_version"
        )
        if [ "$DEBUG" = "true" ]; then
            upgrade_cmd+=("--debug")
        fi
        if [ -n "$EXTRA_VALUES" ]; then
            upgrade_cmd+=(--set "$EXTRA_VALUES")
        fi
        echo "${upgrade_cmd[@]}"
        "${upgrade_cmd[@]}"
    }
    
    function delete_cluster() {
        local cluster_name=$1
        local namespace=$2
    
        exist=$(check_cluster_exist "$cluster_name" "$namespace")
        if [ "$exist" = "false" ]; then
            return
        fi
    
        echo "delete cluster $cluster_name ..."
        kbcli -n "$namespace" cluster delete "$cluster_name" --auto-approve
    
        # wait for cluster being deleted
        while [ "$exist" = "true" ]; do
            echo "waiting for cluster deleted ..."
            sleep 2
            exist=$(check_cluster_exist "$cluster_name" "$namespace")
        done
    }
    
    function uninstall() {
        # uninstall cloud
        if helm -n "$NAMESPACE" list -a --filter "$cloud_release_name" | grep -q "$cloud_release_name"; then
            echo "uninstall $cloud_release_name ... "
            helm -n "$NAMESPACE" uninstall "$cloud_release_name"
        fi
    
        # uninstall logto
        uninstall_logto
    
        # delete meta database
        delete_cluster "$pg_name" "$NAMESPACE"
    
        # uninstall KubeBlocks
        uninstall_kubeblocks
    }
    
    case $ACTION in
        install)
            # pre check the kubernetes cluster
            pre_check
    
            # init meta database, we can use KubeBlocks to provision the database or
            # use an external database. If we use KubeBlocks, we need to install
            # KubeBlocks first then create the meta database.
            echo "meta database type: $META_DB_TYPE"
            if [ "$META_DB_TYPE" == "external" ]; then
                create_databases || true
            elif [ "$META_DB_TYPE" == "kubeblocks" ]; then
                # install KubeBlocks and enable some addons
                install_kubeblocks
    
                # init meta database
                init_meta_database_in_kubeblocks
            else
                echo "unknown meta database type: $META_DB_TYPE"
                exit 1
            fi
    
            # install and init logto
            install_and_init_logto
    
            # install cloud
            install_cloud
            ;;
    
        upgrade)
            upgrade
            ;;
    
        uninstall)
            uninstall
            ;;
    
        *)
            echo "Usage: $0 {install|upgrade|uninstall}"
            exit 1
            ;;
    esac
    
  kubeblocks.sh: |-
    #!/bin/bash
    
    function step() {
        echo -e "\e(0a\e(B $1"
    }
    
    uninstall_kubeblocks() {
        if kubectl get crd | grep clusters.apps.kubeblocks.io; then
            echo "getting remained clusters"
            if [ "$(kubectl get clusters.apps.kubeblocks.io -o json -A | jq '.items | length')" != '0' ]; then
                echo "there are remained kubeblocks clusters, you need to manually clean them"
                exit 1
            else
                echo "there are no remained kubeblocks clusters"
            fi
        fi
    
        kbcli -v=2 kubeblocks uninstall \
            --auto-approve=true \
            --remove-namespace=true \
            --remove-pvcs=true \
            --remove-pvs=true
    }
    
    function wait_addon_enabled() {
        addon=$1
        while true; do
            status=$(kbcli addon list "$addon" --output json | jq -r '.status.phase')
            if [ "$status" = "Enabled" ]; then
                echo "addon $addon is enabled"
                break
            fi
            echo "Waiting for $addon to be enabled ..."
            sleep 5
        done
    }
    
    function wait_addon_disabled() {
        addon=$1
        while true; do
            status=$(kbcli addon list "$addon" --output json | jq -r '.status.phase')
            if [ "$status" = "Disabled" ]; then
                echo "addon $addon is disabled"
                sleep 5
                break
            fi
            echo "Waiting for $addon to be disabled ..."
            sleep 5
        done
    }
    
    function enable_addon() {
        addon=$1
        echo "enable addon $addon ..."
    
        # disable addon first, then enable it with new image registry
        kbcli addon disable "$addon" > /dev/null 2>&1 || true
        wait_addon_disabled "$addon"
    
        cmd=(kbcli addon enable "$addon")
        if [ -n "$IMAGE_REGISTRY" ]; then
            case $addon in
                postgresql)
                    cmd+=(--set image.registry="${IMAGE_REGISTRY}" --set metrics.image.registry="${IMAGE_REGISTRY}")
                    if [ "$DEPLOY_MODE" = "offline" ]; then
                        cmd+=(--set "enabledClusterVersions={postgresql-14.8.0}")
                    fi
                    ;;
                redis)
                    cmd+=(--set image.registry="${IMAGE_REGISTRY}" --set metrics.image.registry="${IMAGE_REGISTRY}")
                    cmd+=(--set redisTwemproxyImage.registry="${IMAGE_REGISTRY}")
                    cmd+=(--set busyboxImage.registry="${IMAGE_REGISTRY}")
                    cmd+=(--set busyboxImage.repository=library/busybox)
                    ;;
    
                mysql)
                    cmd+=(--set image.registry="${IMAGE_REGISTRY}" --set metrics.image.registry="${IMAGE_REGISTRY}")
                    ;;
    
                apecloud-mysql)
                    cmd+=(--set image.registry="${IMAGE_REGISTRY}" --set metrics.image.registry="${IMAGE_REGISTRY}")
                    cmd+=(--set backupTool.image.registry="${IMAGE_REGISTRY}" --set wesqlscale.image.registry="${IMAGE_REGISTRY}")
                    ;;
    
                mongodb)
                    cmd+=(--set image.registry="${IMAGE_REGISTRY}" --set metrics.image.registry="${IMAGE_REGISTRY}")
                    if [ "$DEPLOY_MODE" = "offline" ]; then
                        cmd+=(--set "enabledClusterVersions={mongodb-6.0}")
                    fi
                    ;;
            esac
        fi
        echo "${cmd[@]}"
        "${cmd[@]}"
    
        wait_addon_enabled "$addon"
    }
    
    function install_kubeblocks() {
        kb_namespace=kb-system
    
        # check if KubeBlocks is already installed
        if kbcli version | grep -qi KubeBlocks; then
            echo "Kubeblocks already installed, skipping install"
            return
        fi
    
        # Since `kbcli version` doesn't return kb version, kb deployment doesn't exist.
        # But there's still a chance that there are some remained resources from
        # last failed installation, like CRDs.
        echo "cleaning up remained kubeblocks resources ..."
        uninstall_kubeblocks
    
        # create CRDs
        step "create CRDs ..."
        kubectl create -f ./crds/kubeblocks_crds.yaml
    
        # wait crds created
        sleep 5
    
        step "install kubeblocks ${KB_VERSION} ..."
        install_cmd=(
            helm install kubeblocks "charts/kubeblocks-$KB_VERSION.tgz"
            --namespace="$kb_namespace"
            --create-namespace
            --timeout=60m
            --wait
            --atomic
            --set image.registry="$IMAGE_REGISTRY"
        )
        if [ -n "$KB_STORAGE_CLASS" ]; then
            install_cmd+=(--set storageClass.name="$KB_STORAGE_CLASS")
            install_cmd+=(--set storageClass.create=false)
        fi
        if [ "$DEBUG" = "true" ]; then
            install_cmd+=("--debug")
        fi
        echo "${install_cmd[@]}"
        "${install_cmd[@]}"
    
        # enable engine addons and set its image registry
        engines="$ENABLED_ENGINES"
        if [ -z "$engines" ]; then
            engines="postgresql"
        else
            engines=$(echo "$engines" | tr ',' ' ')
            # check if postgresql is in the list, if not, add them
            if ! echo "$engines" | grep -q postgresql; then
                engines="$engines postgresql"
            fi
        fi
    
        step "Enable addons $engines ..."
        for engine in $engines; do
            enable_addon "$engine"
        done
    }
    
  logto.sh: |-
    #!/bin/bash
    
    #
    # install logto
    #
    
    function install_and_init_logto() {
        if [ "$LOGTO_ENABLED" != "true" ]; then
            echo "logto is not enabled, do not install it."
            return
        fi
    
        echo "check if logto exists ... "
        if helm -n "$NAMESPACE" list -a | grep -q logto; then
            echo "logto already installed in namespace $NAMESPACE, skip installation."
            return
        fi
    
        echo "install logto ... "
        local meta_db_host_port
        if [ "$META_DB_TYPE" == "external" ]; then
            meta_db_host_port="${EXTERNAL_META_DB_HOST}:${EXTERNAL_META_DB_PORT}"
        else
            meta_db_host_port="${pg_name}-postgresql.$NAMESPACE:5432"
        fi
        logto_db_url="postgres://logto:$META_DB_PASSWORD@$meta_db_host_port/logto?sslmode=disable"
        logto_install_cmd=(
            helm install logto -n "$NAMESPACE" "charts/logto-${LOGTO_VERSION}.tgz" --create-namespace
            --set dbUrl="$logto_db_url"
            --set image.registry="$IMAGE_REGISTRY"
            --wait
            --timeout=30m
            --atomic
        )
        if [ "$LOGTO_HOST_NETWORK" = "false" ]; then
            logto_install_cmd+=(
                --set hostNetwork=false
                --set coreEndpoint="http://logto-core.$NAMESPACE.svc.cluster.local:3001"
                --set adminEndpoint="http://logto-admin.$NAMESPACE.svc.cluster.local:3002"
            )
        else
            logto_install_cmd+=(
                --set hostNetwork=true
                --set coreEndpoint="http://$LOGTO_HOST_IP:3001"
                --set adminEndpoint="http://$LOGTO_HOST_IP:3002"
            )
        fi
        if [ -n "$LOGTO_NODE_NAME" ]; then
            logto_install_cmd+=(--set "nodeSelector.kubernetes\\.io/hostname=$LOGTO_NODE_NAME")
        fi
        if [ "$DEBUG" = "true" ]; then
            logto_install_cmd+=("--debug")
        fi
        echo "${logto_install_cmd[@]}"
        "${logto_install_cmd[@]}"
    
        # wait until logto deployed, and logto pod running for a while to make sure the db is initialized
        echo "wait logto deployed ... "
        local times=1
        while true; do
            if [[ $times -gt 300 ]]; then
                break
            fi
            if helm list -n "$NAMESPACE" --output json | jq -r '.[] | select(.name=="logto" and .status=="deployed") | .name' | grep -q 'logto'; then
                pod_name=$(kubectl get pods -n "$NAMESPACE" -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.creationTimestamp}{"\n"}{end}' | grep "logto" | awk '{print $1}')
                pod_status=$(kubectl get pod "$pod_name" -n "$NAMESPACE" -o jsonpath='{.status.phase}')
                if [ "$pod_status" = "Running" ]; then
                    echo "Logto deployed"
                    break
                fi
            fi
            if helm list -n logto --output json | jq -r '.[] | select(.name=="logto" and .status=="failed") | .name' | grep -q 'logto'; then
                echo "logto failed"
                break
            fi
            times=$((times + 1))
            sleep 5
            echo "checking logto status..."
        done
    
        # initialize logto meta db
        echo "init logto meta database"
        console_domain="console.$DOMAIN"
        admin_domain="admin.$DOMAIN"
    
        # SQLs, logto meta db initializations
        sqls=(
            "insert into public.applications (tenant_id, id, name, secret, description, type, oidc_client_metadata, custom_client_metadata, created_at) values ('default', 'zgojvqasnefk2h3rtwoho','KubeBlocks Cloud','iiI34JF1y1W4jNvVk1hCwWPhqtOnP8BF','','SPA', '{\"redirectUris\": [\"http://$console_domain/callback\", \"http://$admin_domain/callback\"], \"postLogoutRedirectUris\": [\"http://$console_domain\",\"http://$admin_domain\"]}', '{\"corsAllowedOrigins\": [\"http://$console_domain\",\"http://$admin_domain\"], \"rotateRefreshToken\": true, \"idTokenTtl\": 2592000, \"refreshTokenTtlInDays\": 14, \"alwaysIssueRefreshToken\": false}', now())"
            "insert into public.applications (tenant_id, id, name, secret, description, type, oidc_client_metadata, custom_client_metadata, created_at) values ('default', '7d305yqkjj8qj9glxkfn3','KubeBlocks M2M','D1HTGTgwxoembbQXsWxfJeio3abhdz1Y','','MachineToMachine','{\"redirectUris\": [], \"postLogoutRedirectUris\": []}','{}', now())"
            "insert into public.applications_roles (tenant_id, id, application_id, role_id) values ('default','9z542i7t53395mzoydpq3','7d305yqkjj8qj9glxkfn3', 'admin-role')"
            "update public.sign_in_experiences set sign_in = '{\"methods\": [{\"password\": true, \"identifier\": \"username\", \"verificationCode\": false, \"isPasswordPrimary\": true}, {\"password\": true, \"identifier\": \"email\", \"verificationCode\": true, \"isPasswordPrimary\": true}]}' , sign_up = '{\"verify\": true, \"password\": true, \"identifiers\": [\"username\"]}' where tenant_id = 'default' and id = 'default';"
            "update public.sign_in_experiences set password_policy='{\"rejects\": {\"pwned\": false}}'"
        )
    
        # construct psql dsn
        dsn=$(get_meta_db_dsn "logto")
    
        # wait for tables being created
        while true; do
            if psql "${dsn}" -t -c "SELECT to_regclass('applications');" | grep -q applications; then
                echo "logto tables created"
                break
            else
                echo "waiting for logto tables being created ..."
                sleep 1
            fi
        done
    
        for sql in "${sqls[@]}"; do
            psql "${dsn}" -a -c "$sql"
        done
    }
    
    function uninstall_logto() {
        echo "check if logto exists ... "
        if helm -n "$NAMESPACE" list | grep -q logto; then
            echo "uninstall logto ... "
            helm uninstall logto -n "$NAMESPACE"
            return
        fi
        echo "logto not installed in namespace $NAMESPACE, skip uninstallation."
    }
    
  precheck.sh: |-
    #!/bin/absh
    
    #
    # pre check the environment, such as kubernetes version
    #
    
    function pre_check() {
        # check kubernetes version is greater than or equal to 1.20
        echo "check kubernetes version .. "
        k8s_v_json=$(kubectl version -o json)
        echo "$k8s_v_json"
        major=$(echo "$k8s_v_json" | jq -r '.serverVersion.major')
        minor=$(echo "$k8s_v_json" | jq -r '.serverVersion.minor')
        if [ "$major" -lt 1 ] || ([ "$major" -eq 1 ] && [ "$minor" -lt 20 ]); then
            echo "Kubernetes version is less than 1.20, please upgrade to 1.20 or later"
            exit 1
        fi
    
        helm version
    }
---
# Source: kb-cloud-installer/templates/values.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kb-cloud-values
  labels:
    helm.sh/chart: kb-cloud-installer-0.25.15
    app.kubernetes.io/name: kb-cloud-installer
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  values.example.yaml: |-
    # -- Number of replicas in deployment
    replicaCount: 1
    # List of images to be deployed along with its tag. Specifying image
    # tag overrides default value which is chart appVersion.
    images:
      sentry:
        name: sentry
        # -- KubeBlocks Cloud sentry image
        repository: apecloud/sentry
        tag: 'v0.20.15'
      sentryInit:
        name: sentry-init
        # -- KubeBlocks Cloud sentry initialize image
        repository: apecloud/sentry-init
        tag: 'v0.20.15'
      relay:
        name: relay
        # -- relay image
        repository: apecloud/relay
        tag: 'v0.20.15'
      prompt:
        name: prompt
        # -- prompt image
        repository: apecloud/prompt
        tag: 'v0.20.15'
      apiserver:
        name: apiserver
        repository: apecloud/apiserver
        tag: 'v0.20.15'
      openconsole:
        name: openconsole
        repository: apecloud/openconsole
        tag: 'v0.20.15'
        redisRepo: "apecloud/redis"
        redisTag: "7.0.5"
      cubetranFront:
        name: cubetran-front
        repository: apecloud/cubetran-front
        defaultTag: ""
      website:
        name: website
        repository: apecloud/apecloud-website
        tag: "latest"
      docs:
        name: apecloud-docs
        repository: apecloud/apecloud-docs
        tag: "latest"
      taskManager:
        name: task-manager
        # -- KubeBlocks Cloud task-manager image
        repository: apecloud/task-manager
        tag: 'v0.20.15'
      cr4w:
        name: cr4w
        repository: apecloud/cr4w
        tag: 'v0.20.15'
      # -- If defined, a imagePullPolicy applied to all deployments
      pullPolicy: IfNotPresent
    imageCredentials:
      registry: "https://index.docker.io/v1/"
      username: "apecloudbot"
      password: "Apecloud2024"
      email: "apecloud-bot@apecloud.com"
    # -- If defined, uses a Secret to pull an image from a private Docker
    # registry or repository
    imagePullSecrets:
      - name: docker-pull-secret
    serviceAccount:
      # Specifies whether a service account should be created
      create: true
      # Annotations to add to the service account
      annotations: {}
      # The name of the service account to use.
      # If not set and create is true, a name is auto generated.
      name: ""
    # -- Annotations for the all deployed pods
    podAnnotations: {}
    # Pod Security Context
    podSecurityContext: {}
    # fsGroup: 2000

    # Security Context
    securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

    # List of services and their port numbers. When "port" is not
    # specificed in "services.<name>.ports" list then service exposes on
    # containerPort instead.
    services:
      # -- sentry service config
      sentry:
        name: sentry
        type: ClusterIP
        annotations: {}
        ports:
          - name: http
            containerPort: 11000
          - name: rpc
            containerPort: 10000
          - name: relay-peering
            containerPort: 10001
      # -- prompt service config
      prompt:
        type: ClusterIP
        annotations: {}
        name: prompt
        ports:
          - name: http
            containerPort: 7009
      # -- relay service config
      relay:
        type: LoadBalancer
        annotations: {}
        name: relay
        ports:
          - name: https
            containerPort: 443
      apiserver:
        type: ClusterIP
        annotations: {}
        name: apiserver
        ports:
          - name: http
            containerPort: 8080
            port: 8080
      # -- dashboard service config
      openconsole:
        type: ClusterIP
        annotations: {}
        name: openconsole
        ports:
          - port: 80
            containerPort: 7001
            name: http
      # apecloud website
      website:
        type: ClusterIP
        annotations:
          alb.ingress.kubernetes.io/healthcheck-path: /
        name: website
        ports:
          - port: 80
            containerPort: 80
            name: http
      docs:
        type: ClusterIP
        name: apecloud-docs
        ports:
          - port: 80
            containerPort: 80
            name: http
    ingress:
      # - install ingress resources.
      enabled: true
      connectEnabled: false
      className: "nginx"
      # - Annotation for ingress resources. The ssl-passthrough annotation
      # - is mandatory for connect ingress.
      annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      connectAnnotations: {}
      # -- Ingress TLS for console
      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - chart-example.com
    resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

    # Autoscale deployment resource
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 100
      targetCPUUtilizationPercentage: 80
      # targetMemoryUtilizationPercentage: 80
    nodeSelector: {}
    tolerations: []
    affinity: {}
    fqdn:
      # -- Root domain
      domain: mytest.kubeblocks.com
      website: apecloud.cn
      # -- subdomain used for viewing dashboard
      hostname: "console"
      # -- a wildcard subdomain used for controller cluster to target
      # -- cluster communication
      coreConnectorSubdomain: "*.core"
      # -- a wildcard subdomain used for controller cluster to end user
      # -- communication
      userSubdomain: "*.connect"
      # -- subdomain used for viewing api
      apiserverHostname: "api"
      # -- subdomain used for viewing admin
      adminHostname: "admin"
      # -- fqdn scheme
      scheme: "http"
    sentry:
      # -- Enable apecloud migrations
      automigrate: true
      database:
        address: ""
        username: ""
        password: ""
        name: ""
        dsn: ""
      initialize:
        # -- Partner name
        partner: "KubeBlocks Cloud"
        # -- Partner description
        partnerDesc: "Default Partner"
        # -- Partner host
        partnerHost: "kubeblocks.com"
        # -- Organization name
        org: "Apecloud"
        # -- Organization description
        orgDesc: "Default Organization"
        # -- Admin email address
        adminEmail: "admin@apecloud.local"
        # -- Admin first name
        adminFirstName: "Admin"
        # -- Admin last name
        adminLastName: "User"
    auditLogs:
      # -- database or elasticsearch for storing audit logs
      # -- database(postgres) by default
      storage: "database"
    deploy:
      platform: ""
      apiserver:
        ginMode: "debug"
        serveAdmin: true
        servePublic: true
        serveInternal: true
        idpName: "logto"
        # use dev logto, for deployment in public cloud without domain
        # idpIssuerUrl: "https://auth-dev.apecloud.cn/oidc"
        # idpAudience: "bd8b7umqse708pzxc8d41"
        # idpM2MClientId: "6ath279bgddzkddrfhpoo"
        # idpM2MClientSecret: "iRFwVj3ENDassmLW2h0TjqOeGlR42srV"
        # for deployment in idc
        idpIssuerUrl: "http://:3001/oidc"
        idpAudience: "zgojvqasnefk2h3rtwoho"
        idpM2MClientId: "7d305yqkjj8qj9glxkfn3"
        idpM2MClientSecret: "D1HTGTgwxoembbQXsWxfJeio3abhdz1Y"
        idpInsecureSkipVerify: true
        caCert: ""
        adminAccountAuth0: "YXV0aDA6N2RkMTliNTUtN2E3Yi00OTEzLTg0MGQtMWRhOTZhOWU1NmY1Cg=="
        adminAccountTaskManager: "dGFza01hbmFnZXI6N2RkMTliNTUtN2E3Yi00OTEzLTg0MGQtMWRhOTZhOWU1NmY1"
        metricsQueryUrl: "http://gemini-victoria-metrics-cluster-vmselect.kb-system:8481/select/0/prometheus/api/v1/query_range"
        grafanaHost: "kb-cloud-grafana:80"
        grafanaUser: "admin"
        grafanaPassword: "123456"
        # for deployment in idc
        basePath: ""
        # for deployment in public cloud without domain
        # basePath: "/apiserver"
        sonyflakeMachineID: "1"
        aliyunSMSEndpoint: ""
        aliyunSMSAccessKeyId: ""
        aliyunSMSAccessKeySecret: ""
        cloudAPIServer: ""
        alertSMSTmplCode: ""
        verifySMSTmplCode: ""
        smsSignName: "ApeCloud"
        kubechatEndpoint: "https://chat.kubeblocks.io"
        openaiApiBase: ""
        openaiApiKey: ""
        openaiApiVersion: "2023-05-15"
        azureOpenaiDeploymentName: ""
        llmContextWindow: ""
        llmMaxTokens: 4095
        llmOutputFormatterEnabled: true
        # when apiserver start, will read sql files from this path and init the meta database
        # if this value is empty, will not init the meta database
        # the migration path in the apiserver container is /etc/apiserver/migration
        migrationPath: "/etc/apiserver/migration"
        # only true in ksr
        enableAccessToken: false
      taskManager:
        enabled: false
        # for deployment in public cloud without domain
        # apiserverEndpoint: "/apiserver"
        # for deployment in idc
        apiserverEndpoint: ""
        apiserverToken: "dGFza01hbmFnZXI6N2RkMTliNTUtN2E3Yi00OTEzLTg0MGQtMWRhOTZhOWU1NmY1"
        smtpEndpoint: ""
        smtpFrom: ""
        smtpFromName: ""
        smtpSupport: "support@apecloud.com"
        smtpInvitation: "http://console.mytest.kubeblocks.com/welcome?token="
      terraform:
        awsAccessKeyId: ""
        awsSecretAccessKey: ""
        alicloudAccessKey: ""
        alicloudSecretKey: ""
      openconsole:
        locale: "zh-CN"
        # for deployment in public cloud without domain
        # openapiServerEndpoint: "/apiserver"
        # for deployment in idc
        openapiServerEndpoint: ""
        basePath: ""
        xframe: "true"
        db:
          port: "5432"
          addr: "apecloud-pg-postgresql.kb-cloud.svc.cluster.local"
          username: "cloud_frontend"
          password: ""
          name: "cloud_frontend"
        authType: "logto"
        # for deployment in public cloud without domain
        # authDomain: "https://auth-dev.apecloud.cn/"
        # for deployment in idc
        authDomain: "http://:3001/"
        # for deployment in public cloud without domain
        # authAppId: "bd8b7umqse708pzxc8d41"
        # authAppSecret: "iiI34JF1y1W4jNvVk1hCwWPhqtOnP8BF"
        # for deployment in idc
        authAppId: "zgojvqasnefk2h3rtwoho"
        authAppSecret: "iiI34JF1y1W4jNvVk1hCwWPhqtOnP8BF"
        themeOptions: '["dark"]'
        protocol: "http"
        # if first time deploy, set this value to "init-start" to init the console database
        yarnOpts: "start"
      website:
        enabled: false
      cr4w:
        enabled: true
        dbMaxIdleConns: ""
        dbMaxOpenConns: ""
        dbConnMaxLifetime: ""
      docs:
        enabled: false
      prompt:
        enabled: true
        # for deployment in public cloud without domain
        # apiserverEndpoint: "/apiserver"
        # for deployment in idc
        apiserverEndpoint: ""
        apiserverToken: "dGFza01hbmFnZXI6N2RkMTliNTUtN2E3Yi00OTEzLTg0MGQtMWRhOTZhOWU1NmY1"
        dev: "false"
      relay:
        enabled: false
      sentry:
        enabled: false
        bootstrapKek: "dGFza01hbmFnZXI6N2RkMTliNTUtN2E3Yi00OTEzLTg0MGQtMWRhOTZhOWU1NmY1"
      postgresql:
        # -- Postgresql db is auto deployed and managed by Helm release
        # when true. (It is recommended to manage your own DB instance
        # separately or use DB services like Amazon RDS in production)
        enable: false
        # -- Postgresql DSN for example, "postgres://user:password@host:5432/db". Required
        # when `deploy.postgresql.enable` is unset and individual components are not specified.
        # Overrides individual components (address, username, password, database)
        dsn: "postgres://user:password@host:5432/db"
        # -- Postgresql address for example, "localhost:5432". Required
        # when `deploy.postgresql.enable` is unset and dsn is not specified.
        address: "apecloud-pg-postgresql.kb-cloud.svc.cluster.local:5432"
        # -- Postgresql username. Required when `deploy.postgresql.enable`
        # is unset and dsn is not specified.
        username: "kubeblockscloud"
        # -- Postgresql password. Required when `deploy.postgresql.enable`
        # is unset and dsn is not specified.
        password: "1234567"
        # -- Postgresql database name. Required when
        # `deploy.postgresql.enable` is unset and dsn is not specified.
        database: "kubeblockscloud"
      contour:
        # -- auto install contour ingress controller
        enable: false
        # -- TLS properties of the virtual host
        tls: {}
        # secretName: chart-example-tls
      victoriametrics:
        enabled: false
        apiAuth:
          username: ""
          password: ""
      grafana:
        enabled: true
    postgresql:
      dbAddr: ""
      # -- When `deploy.postgresql.enable` is true postgres instance is
      # created with this credentials.
      auth:
        existingSecret: postgresql
        enablePostgresUser: false
        username: "admindbuser"
        password: "admindbpassword"
        database: "admindb"
    # -- the chart will overwrite some values of contour subchart.
    # @default -- contour subchart overwrite
    contour:
      contour:
        # HTTPProxy CR installation failed when CRDs are not present. To
        # install CRDs before chart installation we manage contour CRDs in
        # 'crds/' folder as a workaround, till we find better solution to
        # solve this.
        # https://github.com/paralus/helm-charts/issues/13
        manageCRDs: false
        # Do not create IngressClass resource. We setup HTTPProxy
        # resources instead.
        ingressClass:
          create: false
      envoy:
        service:
          # -- Annotations for Envoy service.
          annotations: {}
    # -- the chart will overwrite some values of victoriametrics subchart.
    victoria-metrics-cluster:
      nameOverride: vmc
      vminsert:
        podAnnotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "8480"
        replicaCount: 1
      vmselect:
        extraArgs:
          dedup.minScrapeInterval: 1s
        podAnnotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "8481"
        replicaCount: 1
      vmstorage:
        extraArgs:
          retentionPeriod: "168h"
        podAnnotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "8482"
        replicaCount: 1
        persistentVolume:
          enabled: true
          size: 20Gi
          accessModes:
            - ReadWriteOnce
          storageClass: kb-default-sc
          annotations: {}
    # -- the chart will overwrite some values of grafana subchart.
    grafana:
      grafana.ini:
        security:
          allow_embedding: true
        server:
          # for deployment in idc
          root_url: "http://api.mytest.kubeblocks.com/dashboard/v1"
          # for deployment in public cloud without domain
          # change 1.2.3.4 to your ingress lb after first deployment and upgrade
          # root_url: "http://1.2.3.4:8080/apiserver/dashboard/v1"
        auth.anonymous:
          enabled: true
        database:
          type: "postgres"
          url: 'postgres://kubeblockscloud:12345@apecloud-pg-postgresql.kb-cloud:5432/grafana?sslmode=disable'
          user: "kubeblockscloud"
          password: "12345"
      datasources:
        datasources.yaml:
          apiVersion: 1
          datasources:
            - name: VictoriaMetrics
              type: prometheus
              url: http://gemini-victoria-metrics-cluster-vmselect.kb-system:8481/select/0/prometheus/
              access: proxy
              isDefault: true
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - name: 'mysql'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/mysql
            - name: 'clickhouse'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/clickhouse
            - name: 'mongodb'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/mongodb
            - name: 'postgresql'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/postgresql
            - name: 'qdrant'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/qdrant
            - name: 'redis'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/redis
            - name: 'kafka'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/kafka
            - name: 'node'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/node
            - name: 'oraclemysql'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/oraclemysql
            - name: 'pulsar'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/pulsar
            - name: 'kubelet'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/kubelet
            - name: 'oteld'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/oteld
            - name: 'oracle'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/oracle
            - name: 'oceanbase'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/oceanbase
            - name: 'mysqlproxy'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/mysqlproxy
            - name: 'elasticsearch'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/elasticsearch
            - name: 'starrocksfe'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/starrocksfe
            - name: 'starrocksbe'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/starrocksbe
            - name: 'mogdb'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/mogdb
      dashboardsConfigMaps:
        mysql: "kc-dashboard-mysql"
        clickhouse: "kc-dashboard-clickhouse"
        mongodb: "kc-dashboard-mongodb"
        postgresql: "kc-dashboard-postgresql"
        qdrant: "kc-dashboard-qdrant"
        redis: "kc-dashboard-redis"
        kafka: "kc-dashboard-kafka"
        node: "kc-dashboard-node"
        oraclemysql: "kc-dashboard-oraclemysql"
        pulsar: "kc-dashboard-pulsar"
        kubelet: "kc-dashboard-kubelet"
        oteld: "kc-dashboard-oteld"
        oracle: "kc-dashboard-oracle"
        oceanbase: "kc-dashboard-oceanbase"
        mysqlproxy: "kc-dashboard-mysqlproxy"
        elasticsearch: "kc-dashboard-elasticsearch"
        starrocksfe: "kc-dashboard-starrocks-fe"
        starrocksbe: "kc-dashboard-starrocks-be"
        mogdb: "kc-dashboard-mogdb"
    vmalert:
      init: "false"
    servicemirror:
      enabled: true
      mode: server
      serviceType: LoadBalancer
      # cert/key are PEM encoded data,
      # refer to https://github.com/apecloud/servicemirror/blob/from-scratch/deploy/helm/values-server.yaml
      # for an example.
      #
      # Read the readme for more information: https://github.com/apecloud/servicemirror
      tlsCert: |
        -----BEGIN CERTIFICATE-----
        MIIBmTCCAUCgAwIBAgIRAPLddImqxF5FFmtA5O4ITCkwCgYIKoZIzj0EAwIwKzEp
        MCcGA1UEAxMgcm9vdC5zZXJ2aWNlbWlycm9yLmNsdXN0ZXIubG9jYWwwHhcNMjQw
        MzI2MDU1MTQ1WhcNMzQwMzI0MDU1MTQ1WjArMSkwJwYDVQQDEyByb290LnNlcnZp
        Y2VtaXJyb3IuY2x1c3Rlci5sb2NhbDBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IA
        BJrYfOhtffJnkjlDMF59oZ9p/btkQsyW3K1uadbjOPMYSjLn0YCpRqeuuoMJIF6F
        9lFr6JxqIqScv1MaBiUHtIijRTBDMA4GA1UdDwEB/wQEAwIBBjASBgNVHRMBAf8E
        CDAGAQH/AgEBMB0GA1UdDgQWBBTHfcs/Ek59B01Qs+JkZ07W8o/8ADAKBggqhkjO
        PQQDAgNHADBEAiAmHsDiEb/ddXg72Y+7wbxeaPs2D3GpYT1272G4bsggFgIgcWSn
        wM5a0RrB7OlWi9+HsZ8Z5mC/tZRnS1ybR4bfG8U=
        -----END CERTIFICATE-----
      tlsKey: |
        -----BEGIN EC PRIVATE KEY-----
        MHcCAQEEIJJ2iNrwhrZCOTsVuUDq/+SAYIlCDTjGaWS16qM6iFxQoAoGCCqGSM49
        AwEHoUQDQgAEmth86G198meSOUMwXn2hn2n9u2RCzJbcrW5p1uM48xhKMufRgKlG
        p666gwkgXoX2UWvonGoipJy/UxoGJQe0iA==
        -----END EC PRIVATE KEY-----
    argo-workflows:
      enabled: true
      workflow:
        serviceAccount:
          # this account will be bind to the appropriate role
          # use default so that we don't need to specify serviceaccount when creating workflows
          name: default
      controller:
        # namespace which argo is deployed is already included
        workflowNamespaces:
          - default
---
# Source: kb-cloud-installer/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kb-cloud-installer-cluster-role
  labels:
    helm.sh/chart: kb-cloud-installer-0.25.15
    app.kubernetes.io/name: kb-cloud-installer
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
rules:
  - verbs:
      - '*'
    apiGroups:
      - '*'
    resources:
      - '*'
---
# Source: kb-cloud-installer/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kb-cloud-installer-role-binding
  labels:
    helm.sh/chart: kb-cloud-installer-0.25.15
    app.kubernetes.io/name: kb-cloud-installer
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: kb-cloud-installer
    namespace: kb-cloud-installer-0.25.15.tgz
roleRef:
  kind: ClusterRole
  name: kb-cloud-installer-cluster-role
  apiGroup: rbac.authorization.k8s.io
---
# Source: kb-cloud-installer/templates/installer-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: kb-cloud-installer
  labels:
    helm.sh/chart: kb-cloud-installer-0.25.15
    app.kubernetes.io/name: kb-cloud-installer
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  template:
    metadata:
      name: "my-release"
      labels:
        helm.sh/chart: kb-cloud-installer-0.25.15
        app.kubernetes.io/name: kb-cloud-installer
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/version: "0.1.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: kb-cloud-installer
      securityContext:
        {}
      restartPolicy: Never
      containers:
        - name: installer
          securityContext:
            {}
          image: "docker.io/apecloud/kb-cloud-installer:latest"
          imagePullPolicy: IfNotPresent
          env:
            - name: NAME
              value: "kb-cloud"
            - name: NAMESPACE
              value: "kb-cloud"
            - name: DEBUG
              value: "false"
            - name: CLOUD_VERSION
              value: "0.24.34"
            - name: DOMAIN
              value: "mytest.kubeblocks.com"
            - name: META_DB_TYPE
              value: kubeblocks
            - name: INIT_META_DB
              value: "true"
            - name: KB_VERSION
              value: 0.8.4-beta.6
            - name: KB_STORAGE_CLASS
              value: ""
            - name: ACTION
              value: "install"
            - name: IMAGE_REGISTRY
              value: "docker.io"
            - name: META_DB_PASSWORD
              value: "passw0rd123"
            - name: EXTERNAL_META_DB_HOST
              value: ""
            - name: EXTERNAL_META_DB_PORT
              value: "5432"
            - name: EXTERNAL_META_DB_USER
              value: "postgres"
            - name: EXTERNAL_META_DB_PASSWORD
              value: ""
            - name: EXTERNAL_META_DB_DATABASE
              value: "postgres"
            - name: LOGTO_VERSION
              value: "0.1.3"
            - name: LOGTO_ENABLED
              value: "true"
            - name: LOGTO_HOST_NETWORK
              value: "true"
            - name: LOGTO_NODE_NAME
              value: ""
            - name: LOGTO_HOST_IP
              value: ""
            - name: KUBE_PROVIDER
              value: ""
            - name: INGRESS_CLASS_NAME
              value: "nginx"
            - name: EXTRA_VALUES
              value: ""
            - name: ENABLED_ENGINES
              value: "postgresql,redis,apecloud-mysql,mongodb,mysql"
            - name: DEPLOY_MODE
              value: "online"
            - name: ENGINE_OPTION_DATASOURCE_TYPE
              value: "file"
            - name: FEATURE_GATES
              value: "ClusterStorageClass=true"
          command:
            - "bash"
            - "-c"
            - "/installer/scripts/installer.sh"
          resources:
            {}
          volumeMounts:
            - name: scripts
              mountPath: /installer/scripts
            - name: values
              mountPath: /installer/values
      volumes:
        - name: scripts
          configMap:
            name: kb-cloud-installer-scripts
            defaultMode: 0755
        - name: values
          configMap:
            name: kb-cloud-values
            defaultMode: 0755
