---
# Source: ipfs-cluster/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-ipfs-cluster
  labels:
    helm.sh/chart: ipfs-cluster-0.1.13
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
---
# Source: ipfs-cluster/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-ipfs-cluster
type: Opaque
data:
---
# Source: ipfs-cluster/templates/ipfs.init-d.configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ipfs-my-release-ipfs-cluster-init-d
data:
  001-peers.sh: |-
    #!/bin/sh
    set -xe
    ipfs config Peering.Peers "[ { \"ID\": \"QmcFf2FH3CEgTNHeMRGhN7HNHU1EXAxoEk6EFuSyXCsvRE\", \"Addrs\": [ \"/dnsaddr/node-1.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcFmLd5ySfk2WZuJ1mfSWLDjdmHZq7rSAua4GoeSQfs1z\", \"Addrs\": [ \"/dnsaddr/node-2.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcfFmzSDVbwexQ9Au2pt5YEXHK5xajwgaU6PpkbLWerMa\", \"Addrs\": [ \"/dnsaddr/node-3.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcfJeB3Js1FG7T8YaZATEiaHqNKVdQfybYYkbT1knUswx\", \"Addrs\": [ \"/dnsaddr/node-4.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcfVvzK4tMdFmpJjEKDUoqRgP4W9FnmJoziYX5GXJJ8eZ\", \"Addrs\": [ \"/dnsaddr/node-5.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcfZD3VKrUxyP9BbyUnZDpbqDnT7cQ4WjPP8TRLXaoE7G\", \"Addrs\": [ \"/dnsaddr/node-6.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcfZP2LuW4jxviTeG8fi28qjnZScACb8PEgHAc17ZEri3\", \"Addrs\": [ \"/dnsaddr/node-7.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcfgsJsMtx6qJb74akCw1M24X1zFwgGo11h1cuhwQjtJP\", \"Addrs\": [ \"/dnsaddr/node-8.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"Qmcfr2FC7pFzJbTSDfYaSy1J8Uuy8ccGLeLyqJCKJvTHMi\", \"Addrs\": [ \"/dnsaddr/node-9.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcfR3V5YAtHBzxVACWCzXTt26SyEkxdwhGJ6875A8BuWx\", \"Addrs\": [ \"/dnsaddr/node-10.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"Qmcfuo1TM9uUiJp6dTbm915Rf1aTqm3a3dnmCdDQLHgvL5\", \"Addrs\": [ \"/dnsaddr/node-11.ingress.cloudflare-ipfs.com\" ] }, { \"ID\": \"QmcfV2sg9zaq7UUHVCGuSvT2M2rnLBAPsiE79vVyK3Cuev\", \"Addrs\": [ \"/dnsaddr/node-12.ingress.cloudflare-ipfs.com\" ] } ]" --json
---
# Source: ipfs-cluster/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: my-release-ipfs-cluster
  labels:
    helm.sh/chart: ipfs-cluster-0.1.13
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
---
# Source: ipfs-cluster/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-release-ipfs-cluster
  labels:
    helm.sh/chart: ipfs-cluster-0.1.13
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-release-ipfs-cluster
subjects:
  - kind: ServiceAccount
    name: my-release-ipfs-cluster
    namespace: ipfs-cluster-0.1.13.tgz
---
# Source: ipfs-cluster/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-release-ipfs-cluster
  labels:
    helm.sh/chart: ipfs-cluster-0.1.13
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
  - watch
---
# Source: ipfs-cluster/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-release-ipfs-cluster
  labels:
    helm.sh/chart: ipfs-cluster-0.1.13
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-release-ipfs-cluster
subjects:
  - kind: ServiceAccount
    name: my-release-ipfs-cluster
---
# Source: ipfs-cluster/templates/cluster.service.yaml
apiVersion: v1
kind: Service
metadata:
  name: cluster-0-ipfs-cluster
  labels:
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    nodeType: cluster
spec:
  type: ClusterIP
  ports:
  - port: 9096
    name: p2p
    #  clusterIP: None
  selector:
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    nodeType: cluster
---
# Source: ipfs-cluster/templates/cluster.service.yaml
apiVersion: v1
kind: Service
metadata:
  name: cluster-ipfs-cluster-api
  labels:
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    nodeType: cluster
spec:
  type: ClusterIP
  ports:
  - port: 9094
    name: api
  - port: 9095
    name: ipfs-proxy
  selector:
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    nodeType: cluster
---
# Source: ipfs-cluster/templates/ipfs.service.p2p-nodeport.yaml
apiVersion: v1
kind: Service
metadata:
  name: ipfs-my-release-ipfs-cluster-p2p-nodeport
  labels:
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    nodeType: ipfs
spec:
  type: NodePort
  externalTrafficPolicy: Local
  ports:
  - port: 4001
    name: swarm
    targetPort: swarm
    protocol: TCP
    nodePort: 32000
  - port: 4001
    name: swarm-udp
    targetPort: swarm-udp
    protocol: UDP
    nodePort: 32000
  selector:
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    nodeType: ipfs
---
# Source: ipfs-cluster/templates/ipfs.service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ipfs-my-release-ipfs-cluster
  labels:
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    nodeType: ipfs
spec:
  type: ClusterIP
  ports:
  - port: 4001
    name: swarm
  - port: 5001
    name: api
  - port: 8080
    name: gateway
    #  clusterIP: None
  selector:
    app.kubernetes.io/name: ipfs-cluster
    app.kubernetes.io/instance: my-release
    nodeType: ipfs
---
# Source: ipfs-cluster/templates/cluster.statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: cluster-0-ipfs-cluster
spec:
  serviceName: cluster-0-ipfs-cluster
  replicas: 1  # must be `1`.
  selector:
    matchLabels:
      app.kubernetes.io/name: ipfs-cluster
      app.kubernetes.io/instance: my-release
      nodeType: cluster
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ipfs-cluster
        app.kubernetes.io/instance: my-release
        nodeType: cluster
    spec:
      serviceAccountName: my-release-ipfs-cluster
      securityContext:
        {}
      containers:
      - name: cluster
        env:
          - name: CLUSTER_PEERNAME
            value: cluster-0
          - name: CLUSTER_IPFSHTTP_NODEMULTIADDRESS
            value: /dns4/ipfs-my-release-ipfs-cluster-0.ipfs-my-release-ipfs-cluster.ipfs-cluster-0.1.13.tgz.svc.cluster.local/tcp/5001
          - name: CLUSTER_IPFSPROXY_NODEMULTIADDRESS
            value: /dns4/ipfs-my-release-ipfs-cluster-0.ipfs-my-release-ipfs-cluster.ipfs-cluster-0.1.13.tgz.svc.cluster.local/tcp/5001
          - name: CLUSTER_CRDT_TRUSTEDPEERS
            value: '*' # Trust all peers in Cluster
          # Expose APIs
          - name: CLUSTER_RESTAPI_HTTPLISTENMULTIADDRESS
            value: /ip4/0.0.0.0/tcp/9094
          - name: CLUSTER_IPFSPROXY_LISTENMULTIADDRESS
            value: /ip4/0.0.0.0/tcp/9095
          - name: CLUSTER_MONITORPINGINTERVAL
            value: 2s # Speed up peer discovery
          # Metrics
          - name: CLUSTER_METRICS_ENABLESTATS
            value: "true"
          - name: CLUSTER_METRICS_PROMETHEUSENDPOINT
            value: "/ip4/0.0.0.0/tcp/8888"
        image: "ipfs/ipfs-cluster:latest"
        ports:
        - containerPort: 9096
          name: p2p
        - containerPort: 9094
          name: api
        - containerPort: 9095
          name: ipfs-proxy
        - containerPort: 8888
          name: metrics
        volumeMounts:
        - name: data
          mountPath: /data/ipfs-cluster
        resources:
            {}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
---
# Source: ipfs-cluster/templates/ipfs.statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ipfs-my-release-ipfs-cluster
spec:
  serviceName: ipfs-my-release-ipfs-cluster
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ipfs-cluster
      app.kubernetes.io/instance: my-release
      nodeType: ipfs
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ipfs-cluster
        app.kubernetes.io/instance: my-release
        nodeType: ipfs
    spec:
      serviceAccountName: my-release-ipfs-cluster
      securityContext:
        {}
      initContainers:
        - name: init-nodeport
          image: "lachlanevenson/k8s-kubectl:v1.25.4"
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsNonRoot: false
            runAsUser: 0
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          command:
            - sh
            - -c
            - >
              export EXTERNAL_PORT=$(kubectl get services ipfs-my-release-ipfs-cluster-p2p-nodeport -o jsonpath='{.spec.ports[0].nodePort}');
              export EXTERNAL_IP=$(kubectl get nodes "${NODE_NAME}" -o jsonpath='{.status.addresses[?(@.type=="ExternalIP")].address}');
              echo "EXTERNAL_PORT=$EXTERNAL_PORT" >  /env/init-nodeport;
              echo "EXTERNAL_IP=$EXTERNAL_IP"     >> /env/init-nodeport;
              cat /env/init-nodeport;
              echo "#!/bin/sh" > /container-init.d/nodeport.sh;
              echo "set -ex" >> /container-init.d/nodeport.sh;
              echo "ipfs config Addresses.Announce \"[
              \\\"/ip4/$EXTERNAL_IP/tcp/$EXTERNAL_PORT\\\",
              \\\"/ip4/$EXTERNAL_IP/udp/$EXTERNAL_PORT/quic\\\",
              \\\"/ip4/$EXTERNAL_IP/udp/$EXTERNAL_PORT/quic-v1\\\",
              \\\"/ip4/$EXTERNAL_IP/udp/$EXTERNAL_PORT/quic-v1/webtransport\\\"
              ]\" --json" >> /container-init.d/nodeport.sh;
              chmod +x /container-init.d/nodeport.sh;
          volumeMounts:
            - name: env-nodeport
              mountPath: /env
            - name: init-d
              mountPath: /container-init.d
      containers:
        - name: ipfs
          image: ipfs/kubo:latest
          ports:
            - containerPort: 4001
              name: swarm
              protocol: TCP
            - containerPort: 4001
              name: swarm-udp
              protocol: UDP
            - containerPort: 5001
              name: api
            - containerPort: 8080
              name: gateway
            - containerPort: 5353
              name: zeroconf
              protocol: UDP
          volumeMounts:
            - name: data
              mountPath: /data/ipfs
            - name: env-nodeport
              mountPath: /env
            - name: init-d
              mountPath: /container-init.d
            - name: init-d-configmap
              subPath: 001-peers.sh
              mountPath: /container-init.d/001-peers.sh
          resources:
            {}
      volumes:
        - name: env-nodeport
          emptyDir: {}
        - name: init-d
          emptyDir: {}
        - name: init-d-configmap
          configMap:
            name: ipfs-my-release-ipfs-cluster-init-d
            defaultMode: 0777
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 1Gi
