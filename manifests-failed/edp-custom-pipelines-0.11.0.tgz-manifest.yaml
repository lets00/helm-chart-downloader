---
# Source: edp-custom-pipelines/templates/resources/vcluster/namespace-e2e-vcluster.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: e2e-vcluster
  labels:
    helm.sh/chart: edp-custom-pipelines-0.11.0
    app.kubernetes.io/version: "0.11.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: edp-custom-pipelines/templates/resources/report-junit.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: report-junit
data:
  grype-junit.tpl:
    |
      <?xml version="1.0" ?>
      <testsuites name="grype">
      {{- $failures := len $.Matches }}
          <testsuite tests="{{ $failures }}" failures="{{ $failures }}" name="{{ $.Distro.Name }}:{{ $.Distro.Version }}" errors="0" skipped="0">
              <properties>
                  <property name="type" value="{{ $.Distro.Name }}"></property>
              </properties>
              {{- range .Matches }}
              <testcase classname="{{ .Artifact.Name }}-{{ .Artifact.Version }} ({{ .Artifact.Type }})" name="[{{ .Vulnerability.Severity }}] {{ .Vulnerability.ID }}">
                  <failure message="{{ .Artifact.Name }}: {{ .Vulnerability.ID }}" type="description">{{ .Vulnerability.Description }} {{ .Artifact.CPEs }} {{ .Vulnerability.DataSource }}</failure>
              </testcase>
              {{- end }}
          </testsuite>
      </testsuites>
  trivy-junit.tpl:
    |
      <?xml version="1.0" ?>
      <testsuites name="trivy">
      {{- range . -}}
      {{- $failures := len .Vulnerabilities }}
          <testsuite tests="{{ $failures }}" failures="{{ $failures }}" name="{{  .Target }}" errors="0" skipped="0">
          {{- if not (eq .Type "") }}
              <properties>
                  <property name="type" value="{{ .Type }}"></property>
              </properties>
              {{- end -}}
              {{ range .Vulnerabilities }}
              <testcase classname="{{ .PkgName }}-{{ .InstalledVersion }}" name="[{{ .Vulnerability.Severity }}] {{ .VulnerabilityID }}">
                  <failure message="{{ escapeXML .Title }}" type="description">{{ escapeXML .Description }}</failure>
              </testcase>
          {{- end }}
          </testsuite>
      {{- $failures := len .Misconfigurations }}
      {{- if gt $failures 0 }}
          <testsuite tests="{{ $failures }}" failures="{{ $failures }}" name="{{  .Target }}" errors="0" skipped="0">
          {{- if not (eq .Type "") }}
              <properties>
                  <property name="type" value="{{ .Type }}"></property>
              </properties>
              {{- end -}}
              {{ range .Misconfigurations }}
              <testcase classname="{{ .Type }}" name="[{{ .Severity }}] {{ .ID }}">
                  <failure message="{{ escapeXML .Title }}" type="description">{{ escapeXML .Description }}</failure>
              </testcase>
          {{- end }}
          </testsuite>
      {{- end }}
      {{- end }}
      </testsuites>
---
# Source: edp-custom-pipelines/templates/resources/autotests/tekton-role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: security
  name: tekton-autotests-edp-custom-pipelines-0.11.0.tgz
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "watch", "list"]
---
# Source: edp-custom-pipelines/templates/resources/autotests/tekton-rb.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: tekton-autotests-binding-edp-custom-pipelines-0.11.0.tgz
  namespace: security
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: tekton-autotests-edp-custom-pipelines-0.11.0.tgz
subjects:
- kind: ServiceAccount
  name: tekton
  namespace: edp-custom-pipelines-0.11.0.tgz
---
# Source: edp-custom-pipelines/templates/resources/vcluster/rolebinding-edp-vcluster-namespace-admin.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: edp-vcluster-namespace-admin-edp-custom-pipelines-0.11.0.tgz
  namespace: e2e-vcluster
  labels:
    helm.sh/chart: edp-custom-pipelines-0.11.0
    app.kubernetes.io/version: "0.11.0"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: tekton
    namespace: edp-custom-pipelines-0.11.0.tgz
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
---
# Source: edp-custom-pipelines/templates/pipelines/cd/deploy-custom.yaml
apiVersion: tekton.dev/v1
kind: Pipeline
metadata:
  name: deploy-custom
  labels:
    app.edp.epam.com/pipelinetype: deploy
spec:
  description: |
    This Pipeline is used to deploy applications to the target Stage (Environment).
  params:
    - name: CDPIPELINE
      description: |
        EDP kind:CDPipeline name used for deployment. For example: mypipe, myfeature
      type: string
    - name: CDSTAGE
      description: |
        EDP kind:Stage name of the kind:CDPipeline defined in the CDPIPELINE values. For example: dev, test, prod
      type: string
    - name: APPLICATIONS_PAYLOAD
      description: |
        Applications payload in format: {"codebase1": {"imageTag": "version1", "customValues": true}, "codebase2": {"imageTag": "version2", "customValues": true}}. For example: {"demo": {"imageTag": "main-20240103-141431", "customValues": true}, "myapp": {"imageTag": "0.1.0-SNAPSHOT.1", "customValues": true}}
      type: string
  tasks:
    - name: clean-edp
      taskRef:
        kind: Task
        name: clean-edp
      params:
        - name: PIPELINE
          value: $(params.CDPIPELINE)
        - name: STAGE
          value: $(params.CDSTAGE)
        - name: APPLICATIONS_PAYLOAD
          value: $(params.APPLICATIONS_PAYLOAD)

    - name: deploy-app
      taskRef:
        kind: Task
        name: deploy-applicationset-cli
      runAfter:
        - clean-edp
      params:
        - name: PIPELINE
          value: $(params.CDPIPELINE)
        - name: STAGE
          value: $(params.CDSTAGE)
        - name: APPLICATIONS_PAYLOAD
          value: $(params.APPLICATIONS_PAYLOAD)

    - name: argo-cd-integration
      taskRef:
        kind: Task
        name: argo-cd-integration
      runAfter:
        - deploy-app
      params:
        - name: PIPELINE
          value: $(params.CDPIPELINE)
        - name: STAGE
          value: $(params.CDSTAGE)

    - name: promote-images
      taskRef:
        kind: Task
        name: promote-images
      runAfter:
        - argo-cd-integration
      params:
        - name: APPLICATIONS_PAYLOAD
          value: $(params.APPLICATIONS_PAYLOAD)
        - name: CDPIPELINE_STAGE
          value: $(params.CDSTAGE)
        - name: CDPIPELINE_CR
          value: $(params.CDPIPELINE)
---
# Source: edp-custom-pipelines/templates/resources/ack/ecr/review-repository.yaml
apiVersion: ecr.services.k8s.aws/v1alpha1
kind: Repository
metadata:
  name: "review-edp-custom-pipelines-0.11.0.tgz"
spec:
  name: "review/edp-custom-pipelines-0.11.0.tgz"
  imageScanningConfiguration:
    scanOnPush: false
  imageTagMutability: MUTABLE
---
# Source: edp-custom-pipelines/templates/tasks/CrdocsBuild.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: crdocs
  labels:
    app.kubernetes.io/version: "0.3"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/categories: Build Tools
    tekton.dev/tags: build-tool
    tekton.dev/displayName: "golang build"
    tekton.dev/platforms: "linux/amd64,linux/s390x,linux/ppc64le"
spec:
  description: >-
    This Task is Golang task to build Go projects.
  params:
    - name: GOOS
      description: "running program's operating system target"
      default: linux
      type: string
    - name: GOARCH
      description: "running program's architecture target"
      default: amd64
      type: string
    - name: GO111MODULE
      description: "value of module support"
      default: auto
      type: string
    - name: GOCACHE
      description: "Go caching directory path"
      default: "$(workspaces.source.path)"
      type: string
    - name: GOMODCACHE
      description: "Go mod caching directory path"
      default: ""
      type: string
    - name: CGO_ENABLED
      description: "Toggle cgo tool during Go build. Use value '0' to disable cgo (for static builds)."
      default: '0'
      type: string
    - name: GOSUMDB
      description: "Go checksum database url. Use value 'off' to disable checksum validation."
      default: ""
      type: string
    - name: EXTRA_COMMANDS
      type: string
      description: Extra commands
      default: ""
      type: string
    - name: BASE_IMAGE
      description: "Base image"
      default: "golang:1.20-bullseye"
      type: string
    - name: GOPROXY
      description: "Go proxy server"
      default: ""
      type: string
  workspaces:
    - name: source


  steps:
    - name: crdocs
      image: $(params.BASE_IMAGE)
      workingDir: $(workspaces.source.path)

      script: |
        set -ex
        crdPath="deploy-templates/crds"
        echo "${GOPROXY}"
        if [ -d "${crdPath}" ]; then
            make api-docs
            git diff -s --exit-code docs/api.md || (echo "Please make sure that the CRD documentation is up to date. Run 'make api-docs' to address the issue" && exit 1)
        else
            echo "Directory with CRD not found in ${crdPath}. Stage will be skipped"
        fi
      env:
        - name: GOOS
          value: "$(params.GOOS)"
        - name: GOARCH
          value: "$(params.GOARCH)"
        - name: GO111MODULE
          value: "$(params.GO111MODULE)"
        - name: GOCACHE
          value: "$(params.GOCACHE)"
        - name: GOMODCACHE
          value: "$(params.GOMODCACHE)"
        - name: CGO_ENABLED
          value: "$(params.CGO_ENABLED)"
        - name: GOSUMDB
          value: "$(params.GOSUMDB)"
        - name: GOPROXY
          value: "$(params.GOPROXY)"
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/GetVersionEDPcontainer.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: get-version-edp-container
spec:
  description:
  params:
    - name: CODEBASEBRANCH_NAME
      type: string
      description: "Codebasebranch name"
  results:
    - name: VERSION
      description: "Application version"
    - name: VCS_TAG
      description: "VCS tag"
    - name: IS_TAG
      description: "CodebaseImageStream tag"
    - name: BUILD_ID
      description: "Build id"
    - name: BRANCH_VERSION
      description: "Branch version"
    - name: IS_RELEASE_BRANCH
    - name: DEPLOYABLE_MODULE_DIR
  steps:
    - name: get-version
      image: bitnami/kubectl:1.25.2
      env:
        - name: CODEBASEBRANCH_NAME
          value: "$(params.CODEBASEBRANCH_NAME)"
      script: |
        #!/usr/bin/env bash
        set -e

        # replace '/' with '-'
        CODEBASEBRANCH_NAME=${CODEBASEBRANCH_NAME//\//-}
        # get current BUILD ID
        BUILD_ID=$(kubectl get codebasebranches.v2.edp.epam.com ${CODEBASEBRANCH_NAME} -o txt --output=jsonpath={.status.build})
        # and increment it
        BUILD_ID=$((BUILD_ID+1))
        # set new version
        kubectl patch codebasebranches.v2.edp.epam.com ${CODEBASEBRANCH_NAME} --subresource=status --type=merge -p "{\"status\": {\"build\": \"$BUILD_ID\"}}"

        IS_RELEASE_BRANCH=$(kubectl get codebasebranches.v2.edp.epam.com ${CODEBASEBRANCH_NAME} -o txt --output=jsonpath={.spec.release})

        # Get current version
        VERSION=$(kubectl get codebasebranches.v2.edp.epam.com ${CODEBASEBRANCH_NAME} -o txt --output=jsonpath={.spec.version})

        BRANCH_VERSION=${VERSION}
        VERSION="${VERSION}.${BUILD_ID}"
        VCS_TAG="build/${VERSION}"
        IS_TAG=${VERSION}
        DEPLOYABLE_MODULE_DIR="."

        IS_TAG=$(echo ${IS_TAG} |sed 's/[0-9]-SNAPSHOT.//g')

        echo "Application version - ${VERSION}"
        echo "VCS tag - ${VCS_TAG}"
        echo "IS tag - ${IS_TAG}"
        echo "Build id - ${BUILD_ID}"
        echo "Branch version - ${BRANCH_VERSION}"

        printf "%s" "${VERSION}" > "$(results.VERSION.path)"
        printf "%s" "${VCS_TAG}" > "$(results.VCS_TAG.path)"
        printf "%s" "${IS_TAG}" > "$(results.IS_TAG.path)"
        printf "%s" "${BUILD_ID}" > "$(results.BUILD_ID.path)"
        printf "%s" "${BRANCH_VERSION}" > "$(results.BRANCH_VERSION.path)"
        printf "%s" "${IS_RELEASE_BRANCH}" > "$(results.IS_RELEASE_BRANCH.path)"
        printf "%s" "${DEPLOYABLE_MODULE_DIR}" > "$(results.DEPLOYABLE_MODULE_DIR.path)"
---
# Source: edp-custom-pipelines/templates/tasks/HelmPushGhPages.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: helm-push-gh-pages
spec:
  description: |
    This Task allows Uset to push a new version of the Helm Chart
    to the repository with Snapshot versions.
  workspaces:
    - name: source
      description: A workspace that contains the repository.

  params:
    - name: CODEBASE_NAME
      type: string

    - name: SSH_REPO_URL
      type: string
      default: "git@github.com:epam/edp-helm-charts.git"

    - name: GH_CHART_URL
      type: string
      default: "https://epam.github.io/edp-helm-charts"

    - name: GH_BRANCH
      type: string
      default: "gh-pages"

    - name: GH_EMAIL
      type: string
      default: "SupportEPMD-EDP@epam.com"

    - name: GH_USER_NAME
      type: string
      default: "edp-bot"

    - name: HELM_REPO_NAME
      type: string
      default: "epamedp"

    - name: SSH_SECRET_NAME
      type: string
      default: "github-pages-helm-chart-sshkey"

    - name: PROJECT_DIR
      type: string
      description: "The directory containing project files."
      default: "."

    - name: USER_HOME
      description: |
        Absolute path to the user's home directory. Set this explicitly if you are running the image as a non-root user
        or have overridden the gitInitImage param with an image containing custom user configuration.
      type: string
      default: "/tekton/home"

  volumes:
    - name: ssh-keys
      secret:
        secretName: $(params.SSH_SECRET_NAME)

  steps:
    - name: helm-push-gh-pages
      image: epamedp/tekton-helm:0.1.6
      workingDir: $(workspaces.source.path)/$(params.PROJECT_DIR)
      volumeMounts:
        - name: ssh-keys
          mountPath: /workspaces/ssh-keys
      env:
        - name: CODEBASE_NAME
          value: $(params.CODEBASE_NAME)
        - name: GIT_SSH_COMMAND
          value: "ssh -i $(params.USER_HOME)/.ssh/id_rsa -o StrictHostKeyChecking=no "
        - name: GIT_SSH_VARIANT
          value: "ssh"
        - name: SSH_REPO_URL
          value: $(params.SSH_REPO_URL)
        - name: GH_EMAIL
          value: $(params.GH_EMAIL)
        - name: GH_USER_NAME
          value: $(params.GH_USER_NAME)
        - name: HELM_REPO_NAME
          value: $(params.HELM_REPO_NAME)
        - name: GH_CHART_URL
          value: $(params.GH_CHART_URL)
        - name: GH_BRANCH
          value: $(params.GH_BRANCH)
        - name: PARAM_USER_HOME
          value: $(params.USER_HOME)
        - name: WORKING_DIR
          value: $(workspaces.source.path)/$(params.PROJECT_DIR)
      script: |
        set -ex

        ls -la

        cp -R "/workspaces/ssh-keys" "${PARAM_USER_HOME}"/.ssh
        chmod 700 "${PARAM_USER_HOME}"/.ssh
        chmod -R 400 "${PARAM_USER_HOME}"/.ssh/*

        # Setting up the config for the git.
        git config --global user.email ${GH_EMAIL}
        git config --global user.name ${GH_USER_NAME}

        for i in "deploy-templates" "charts/pipelines-library" "charts/custom-pipelines"
        do
            if [ -f "${i}/Chart.yaml" ]; then
                echo "[TEKTON] Chart.yaml exists in ${i} in the repository."
                rm -rf chart-repo

                git clone ${SSH_REPO_URL} chart-repo
                cd chart-repo/snapshot

                helm repo add ${HELM_REPO_NAME} ${GH_CHART_URL}/stable --force-update
                helm dep update ${WORKING_DIR}/${i}/
                helm package ${WORKING_DIR}/${i}/ -d packages
                helm repo index --url ${GH_CHART_URL}/snapshot --merge index.yaml .

                git add packages/*.tgz index.yaml
                git commit -m "Push ${CODEBASE_NAME} helm chart"
                git push -u origin ${GH_BRANCH}

                cd ${WORKING_DIR}
            else
                echo "${i}/Chart.yaml does not exist."
            fi
        done
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/MkdocsBuild.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: mkdocs
  labels:
    helm.sh/chart: edp-custom-pipelines-0.11.0
    app.kubernetes.io/version: "0.11.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "0.1"
  annotations:
    tekton.dev/pipelines.minVersion: "0.17.0"
    tekton.dev/categories: Build Tools
    tekton.dev/tags: build-tool
    tekton.dev/platforms: "linux/amd64,linux/s390x,linux/ppc64le"
spec:
  description: >-
    This task can be used to run python goals and mkdocs on a project.
  workspaces:
    - name: source
    - name: ssh-directory
  params:
    - name: PATH_CONTEXT
      type: string
      default: "."
      description: The path where package.json of the project is defined.
    - name: BASE_IMAGE
      type: string
      default: "squidfunk/mkdocs-material:9.0.6"
      description: The python image you want to use.
    - name: GIT_SSH_COMMAND
      type: string
      default: "ssh -i /tekton/home/.ssh/id_rsa -o StrictHostKeyChecking=no"
      description: Custom SSH command.
    - name: GIT_SSH_VARIANT
      type: string
      default: "ssh"
    - name: USER_HOME
      type: string
      default: "/tekton/home"
  steps:
    - name: mkdocs
      image: $(params.BASE_IMAGE)
      workingDir: $(workspaces.source.path)/$(params.PATH_CONTEXT)
      env:
        - name: GIT_SSH_COMMAND
          value: $(params.GIT_SSH_COMMAND)
        - name: GIT_SSH_VARIANT
          value: $(params.GIT_SSH_VARIANT)
        - name: PARAM_USER_HOME
          value: $(params.USER_HOME)
        - name: WORKSPACE_SSH_DIRECTORY_BOUND
          value: $(workspaces.ssh-directory.bound)
        - name: WORKSPACE_SSH_DIRECTORY_PATH
          value: $(workspaces.ssh-directory.path)
      script: |
        set -eux

        if [ "${WORKSPACE_SSH_DIRECTORY_BOUND}" = "true" ] ; then
          cp -R "${WORKSPACE_SSH_DIRECTORY_PATH}" "${PARAM_USER_HOME}"/.ssh
          chmod 700 "${PARAM_USER_HOME}"/.ssh
          chmod -R 400 "${PARAM_USER_HOME}"/.ssh/*
        fi

        commit_docs=$(git show --diff-filter=ACMR --name-only --pretty=format: -- "docs/*" "mkdocs.yml")
        echo -e "Changed documentation in the commit:\n${commit_docs}"

        if [ -z "${commit_docs}" ]; then
            echo "No changes related to the documentation have been found, skipping..."
        else
            remote_repo=$(git config --get remote.origin.url)

            python -m venv /home/tekton/mkdocs
            source /home/tekton/mkdocs/bin/activate
            pip install -r hack/mkdocs/requirements.txt

            # Inject Google Analytics key on build time
            export GOOGLE_ANALYTICS_KEY=G-7ZV6PJ2LSP

            mkdocs build -d ./site

            git config --global user.email SupportEPMD-EDP@epam.com
            git config --global user.name edp-bot

            git clone --branch=gh-pages --depth=1 "${remote_repo}" gh-pages
            cd gh-pages
            # remove current content in branch gh-pages
            git rm -r .
            # copy new doc.
            cp -r ../site/* .
            # try to address issue with sitemap.xml from GH-Pages
            touch .nojekyll
            echo "google-site-verification: google8d28c574bd766c92.html" > google8d28c574bd766c92.html
            echo "18f79d89057c4b108502f91fb24e674b" > 18f79d89057c4b108502f91fb24e674b.txt
            echo -e "User-agent: *\nAllow: /\nSitemap: https://epam.github.io/edp-install/sitemap.xml" > robots.txt
            echo -e "<?xml version=\"1.0\"?>\n<users>\n\t<user>0A0BD75C41E23DEE0C6F5DB33E1BECBC</user>\n</users>" > BingSiteAuth.xml
            git add .
            git commit -m 'Update documentation'
            git push -u origin gh-pages
        fi
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/SetVersionHelm.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: set-version
spec:
  description: |
    This Task sets a version and appVersion into a Chart file.

  workspaces:
    - name: source

  params:
    - name: IS_TAG
      type: string
      description: "Image Stream Tag"
    - name: PROJECT_DIR
      type: string
      description: "The directory containing project files."
      default: "."
  steps:
    - name: set-version-to-chart
      image: alpine:3.18.6
      workingDir: $(workspaces.source.path)/$(params.PROJECT_DIR)
      env:
        - name: IS_TAG
          value: "$(params.IS_TAG)"
      script: |
        set -ex

        chartPath=$(find . -name "Chart.yaml" ! -path '*/common-library/*')
        IFS=$'\n'
        for i in "${chartPath}"; do
            echo "[TEKTON] Chart path is ${i}"
            sed -i "s/^version:.*$/version: ${IS_TAG}/" $i
            sed -i "s/^appVersion:.*$/appVersion: ${IS_TAG}/" $i
        done || true
---
# Source: edp-custom-pipelines/templates/tasks/cd/argocd-integration.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: argo-cd-integration
spec:
  params:
    - name: PIPELINE
      description: EDP kind:CDPipeline name used for deployment.
      type: string
      default: ""
    - name: STAGE
      description: EDP kind:Stage name of the kind:CDPipeline defined in the CDPIPELINE values.
      type: string
      default: ""
    - name: KUBECONFIG_SECRET_NAME
      type: string
      default: "kubeconfig"
  volumes:
    - name: kubeconfig
      secret:
        secretName: $(params.KUBECONFIG_SECRET_NAME)
        optional: true
  steps:
    - name: argo-cd-integration
      image: bitnami/kubectl:1.25.4
      volumeMounts:
        - name: kubeconfig
          mountPath: /workspace/source/kube
      env:
        - name: PIPELINE
          value: "$(params.PIPELINE)"
        - name: STAGE
          value: "$(params.STAGE)"
      script: |
        #!/bin/bash
        set -ex

        kubeconfig="workspace/source/kube/config"

        TARGET_NAMESPACE=$(kubectl get stages ${PIPELINE}-${STAGE} -o jsonpath='{.spec.namespace}')

        if [ -f "$kubeconfig" ]; then
            echo "Kubeconfig exists: $kubeconfig, use it"
            export KUBECONFIG=$kubeconfig
        else
            echo "Kubeconfig does not exist, working on current cluster"
        fi

        # Wait when gerrit deployment is ready
        kubectl wait -n ${TARGET_NAMESPACE} gerrit.v2.edp.epam.com --all '--for=jsonpath={.status.status}=ready' --timeout 400s

        # Get current known hosts from argocd config map

        kubectl get cm argocd-ssh-known-hosts-cm -n argocd -o jsonpath='{.data.ssh_known_hosts}' > /tmp/ssh_known_hosts

        # Get known hosts from gerrit pod

        gerritPort=$(kubectl get gerrit gerrit -n ${TARGET_NAMESPACE} -o jsonpath='{.spec.sshPort}')
        kubectl exec -it deployment/gerrit -n ${TARGET_NAMESPACE} -- ssh-keyscan -p ${gerritPort} gerrit.${TARGET_NAMESPACE} >> /tmp/ssh_known_hosts

        # Set gerrit url for ARGOCD
        gerritUrl=$(echo -n "ssh://edp-ci@gerrit.${TARGET_NAMESPACE}:${gerritPort}" | base64 -w0)

        # copy secret to argocd ns
        SECRET=$(kubectl get secret gerrit-argocd-sshkey -n ${TARGET_NAMESPACE} -o json)
        SECRET=$(echo ${SECRET} | jq 'del(.data.username,.metadata.annotations,.metadata.creationTimestamp,.metadata.labels,.metadata.resourceVersion,.metadata.uid,.metadata.ownerReferences)')
        SECRET=$(echo ${SECRET} | jq '.metadata.namespace = "argocd"')
        SECRET=$(echo ${SECRET} | jq --arg name "${TARGET_NAMESPACE}" '.metadata.name = $name')
        SECRET=$(echo ${SECRET} | jq --arg url "${gerritUrl}" '.data.url = $url')
        SECRET=$(echo ${SECRET} | jq '.data.sshPrivateKey = .data.id_rsa')
        SECRET=$(echo ${SECRET} | jq 'del(.data.id_rsa,.data."id_rsa.pub")')

        echo ${SECRET} | kubectl apply -f -

        # Create configmap with known hosts
        kubectl create configmap argocd-ssh-known-hosts-cm -n argocd --from-file /tmp/ssh_known_hosts -o yaml --dry-run=client | kubectl apply -f -

        # Add argocd label to secret
        kubectl label --overwrite secret ${TARGET_NAMESPACE} -n argocd "argocd.argoproj.io/secret-type=repo-creds"

        rm -f /tmp/ssh_known_hosts
---
# Source: edp-custom-pipelines/templates/tasks/cd/clean-edp.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: clean-edp
spec:
  params:
    - name: PIPELINE
      description: EDP kind:CDPipeline name used for deployment.
      type: string
      default: ""
    - name: STAGE
      description: EDP kind:Stage name of the kind:CDPipeline defined in the CDPIPELINE values.
      type: string
      default: ""
    - name: APPLICATIONS_PAYLOAD
      description: |
        Applications payload in format: {"codebase1": {"imageTag": "version1", "customValues": true}, "codebase2": {"imageTag": "version2", "customValues": true}}. For example: {"demo": {"imageTag": "main-20240103-141431", "customValues": true}, "myapp": {"imageTag": "0.1.0-SNAPSHOT.1", "customValues": true}}
      type: string
    - name: KUBECONFIG_SECRET_NAME
      type: string
      default: "kubeconfig"
  volumes:
    - name: kubeconfig
      secret:
        secretName: $(params.KUBECONFIG_SECRET_NAME)
        optional: true
  steps:
    - name: clean-edp
      image: epamedp/tekton-autotest:0.1.3
      volumeMounts:
        - name: kubeconfig
          mountPath: /workspace/source/kube
      env:
        - name: PIPELINE
          value: "$(params.PIPELINE)"
        - name: STAGE
          value: "$(params.STAGE)"
        - name: APPLICATIONS_PAYLOAD
          value: "$(params.APPLICATIONS_PAYLOAD)"
      script: |
        #!/usr/bin/env python

        import subprocess
        import json
        import os
        import re

        kubeconfig = "workspace/source/kube/config"

        if os.path.isfile(kubeconfig):
            print(f"Kubeconfig exists: {kubeconfig} , use it")
            os.environ['KUBECONFIG'] = kubeconfig
        else:
            print("Kubeconfig does not exist, working on current cluster")

        pipeline = os.getenv('PIPELINE')
        stage = os.getenv('STAGE')

        stages = subprocess.Popen(['kubectl', 'get', 'stages', pipeline + '-' + stage, '-o', "jsonpath='{.spec.namespace}'"], stdout=subprocess.PIPE)
        output, error = stages.communicate()
        target_namespace=output.decode('utf-8').strip("'")

        print("Pipeline - " + pipeline)
        print("Stage - " + stage)
        print("Deployble namespace " + target_namespace)

        get_crd = subprocess.Popen(['kubectl', 'get', 'crd', '-o', 'json'], stdout=subprocess.PIPE)

        crd = json.load(get_crd.stdout)

        edp_cr = [item['metadata']['name'] for item in crd['items'] if '.v2.edp.epam.com' in item['metadata']['name']]

        keycloak_cr=["keycloakclients.v1.edp.epam.com",
                    "keycloakclientscopes.v1.edp.epam.com",
                    "keycloakrealmgroups.v1.edp.epam.com",
                    "keycloakrealmroles.v1.edp.epam.com",
                    "keycloakrealmrolebatches.v1.edp.epam.com",
                    "keycloakauthflows.v1.edp.epam.com",
                    "keycloakrealmcomponents.v1.edp.epam.com",
                    "keycloakrealmidentityproviders.v1.edp.epam.com",
                    "keycloakrealmusers.v1.edp.epam.com",
                    "keycloakrealms.v1.edp.epam.com",
                    "keycloaks.v1.edp.epam.com"]

        list_validating_webhook_configuration = subprocess.run(
            ['kubectl', 'get', 'ValidatingWebhookConfigurations',
            '--no-headers', '--output=custom-columns=NAME:.metadata.name'],
            capture_output=True, text=True
        ).stdout.split('\n')

        filtered_list = [vc for vc in list_validating_webhook_configuration if f"{target_namespace}" in vc]

        for vc in filtered_list:
            try:
                subprocess.run(['kubectl', 'delete', 'ValidatingWebhookConfigurations', vc, '--timeout=12s'], check=True)
                print(f"EDP Validating Webhook Configuration has been deleted: {vc}")
            except subprocess.CalledProcessError:
                print(f"Unable to find ValidatingWebhookConfigurations {vc}")




        # Delete EDP cr

        for cr in edp_cr:
            resources_command = subprocess.run(
                ['kubectl', 'get', cr, '-o', 'json', '-n', target_namespace],
                capture_output=True, text=True
            )
            resources = json.loads(resources_command.stdout)

            resource_names = [item['metadata']['name'] for item in resources['items']]

            for element in resource_names:
                print(f"Start deleting process, now deleting {element} in {cr}")
                replace_finalizers_command = f"kubectl get {cr} {element} -o json -n {target_namespace} | jq 'del(.metadata.finalizers)' | kubectl replace -f -"
                command = f"kubectl delete {cr} {element} --timeout='12s' --ignore-not-found -n {target_namespace}"
                subprocess.run([replace_finalizers_command], shell=True, capture_output=True, text=True)
                result = subprocess.run([command], shell=True, capture_output=True, text=True)
                print(result.stdout)


        # Delete Keycloak cr

        for cr in keycloak_cr:
            resources_command = subprocess.run(
                ['kubectl', 'get', cr,'-o', 'json', '-n', target_namespace],
                capture_output=True, text=True
            )
            # print(resources_command)
            resources = json.loads(resources_command.stdout)
            resource_names = [item['metadata']['name'] for item in resources['items']]

            for element in resource_names:
                print(f"Start deleting process, now deleting {element} in {cr}")
                replace_finalizers_command = f"kubectl get {cr} {element} -o json -n {target_namespace} | jq 'del(.metadata.finalizers)' | kubectl replace -f -"
                command = f"kubectl delete {cr} {element} --timeout='12s' --ignore-not-found -n {target_namespace}"
                subprocess.run([replace_finalizers_command], shell=True, capture_output=True, text=True)
                result = subprocess.run([command], shell=True, capture_output=True, text=True)
                print(result.stdout)

        # Delete EDP components

        resources_command = subprocess.run(
                ['kubectl', 'get', 'edpcomponents.v1.edp.epam.com','-o', 'json', '-n', target_namespace],
                capture_output=True, text=True
            )

        resources = json.loads(resources_command.stdout)
        resource_names = [item['metadata']['name'] for item in resources['items']]

        for element in resource_names:
            print(f"Start deleting process, now deleting {element} in edpcomponents.v1.edp.epam.com")
            command = f"kubectl delete edpcomponents.v1.edp.epam.com {element} --timeout='12s' --ignore-not-found -n {target_namespace}"
            result = subprocess.run([command], shell=True, capture_output=True, text=True)
            print(result.stdout)

    - name: delete-argo-app
      image: epamedp/tekton-cd-pipeline:0.1.2
      env:
        - name: ARGOCD_URL
          valueFrom:
            secretKeyRef:
              name: ci-argocd
              key: url
        - name: ARGOCD_AUTH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ci-argocd
              key: token
        - name: PIPELINE
          value: "$(params.PIPELINE)"
        - name: STAGE
          value: "$(params.STAGE)"
      script: |
        set -ex

        export ARGOCD_OPTS="--core=false --grpc-web"
        # the address of the Argo CD server without https:// prefix
        export ARGOCD_SERVER=${ARGOCD_URL#*//}

        argocd app delete -l "app.edp.epam.com/stage=$STAGE" -l "app.edp.epam.com/pipeline=$PIPELINE" --core=false --grpc-web -y
---
# Source: edp-custom-pipelines/templates/tasks/e2e.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: e2e
  labels:
    helm.sh/chart: edp-custom-pipelines-0.11.0
    app.kubernetes.io/version: "0.11.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "0.1"
spec:
  description: >-
    This Task creates vcluster and runs kuttl tests on it.
  workspaces:
    - name: source

  params:
    - name: CODEBASE_NAME
      type: string
    - name: E2E_IMAGE_REPOSITORY
      type: string
    - name: E2E_IMAGE_TAG
      type: string
    - name: E2E_HOST_NS
      type: string
      default: "e2e-vcluster"
    - name: TOOLS_IMAGE
      type: string
      default: "epamedp/tekton-helm:0.1.6"

  results:
    - name: release_name

  steps:
    - name: vcluster-start
      image: $(params.TOOLS_IMAGE)
      workingDir: $(workspaces.source.path)
      env:
        - name: CODEBASE_NAME
          value: $(params.CODEBASE_NAME)
        - name: E2E_IMAGE_REPOSITORY
          value: $(params.E2E_IMAGE_REPOSITORY)
        - name: E2E_IMAGE_TAG
          value: $(params.E2E_IMAGE_TAG)
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
      script: |
        set -x

        random_str=$(echo $RANDOM | md5sum | head -c 10)
        release_name=$(echo "${CODEBASE_NAME}-${random_str}" | tr '[:upper:]' '[:lower:]')

        vcluster create ${release_name} \
         -n ${E2E_HOST_NS} \
         --connect=false \
         --update-current=false

        printf "%s" "${release_name}" > "$(results.release_name.path)"

    - name: kuttl-test
      image: $(params.TOOLS_IMAGE)
      workingDir: $(workspaces.source.path)
      onError: continue
      env:
        - name: E2E_IMAGE_REPOSITORY
          value: $(params.E2E_IMAGE_REPOSITORY)
        - name: E2E_IMAGE_TAG
          value: $(params.E2E_IMAGE_TAG)
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
        - name: CONTAINER_REGISTRY_URL
          valueFrom:
            configMapKeyRef:
              name: edp-config
              key: container_registry_host
        - name: CONTAINER_REGISTRY_SPACE
          valueFrom:
            configMapKeyRef:
              name: edp-config
              key: container_registry_space
      script: |
        set -x

        release_name=$(cat $(results.release_name.path))
        vcluster connect "${release_name}" --namespace ${E2E_HOST_NS} -- kubectl kuttl test

    - name: vcluster-remove
      image: $(params.TOOLS_IMAGE)
      workingDir: $(workspaces.source.path)
      env:
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
      script: |
        set -x

        release_name=$(cat $(results.release_name.path))
        vcluster -n ${E2E_HOST_NS} delete ${release_name}

    - name: kuttl-test-verify-exitcode
      image: alpine:3.18.6
      workingDir: $(workspaces.source.path)
      script: |
        exitCode=`cat $(steps.step-kuttl-test.exitCode.path)`
        if [ $exitCode == 0 ]; then
            echo "The exit code contains zero status code: ${exitCode}"
        else
            echo "The exit code contains non-zero status code: ${exitCode}"
            exit 1
        fi
---
# Source: edp-custom-pipelines/templates/tasks/edp-autotests.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: autotests
spec:
  description: |
    This task for autotests.
  workspaces:
    - name: source
      description: A workspace that contains the repository.
  params:
    - name: cluster
      type: string
    - name: threads_num
      type: string
    - name: namespace
      type: string
    - name: tags
      type: string
    - name: ci_tool
      type: string
    - name: git_provider
      type: string
    - name: moon_url
      type: string
    - name: browser_type
      type: string
    - name: browser_name
      type: string
    - name: browser_version
      type: string
    - name: secret_name
      type: string
    - name: secret_namespace
      type: string
    - name: registry_type
      type: string
  steps:
    - name: run-autotests
      image: gradle:8-jdk11
      workingDir: $(workspaces.source.path)
      env:
        - name: CLUSTER
          value: $(params.cluster)
        - name: THREADS_NUM
          value: $(params.threads_num)
        - name: NAMESPACE
          value: $(params.namespace)
        - name: TAGS
          value: $(params.tags)
        - name: CI_TOOL
          value: $(params.ci_tool)
        - name: GIT_PROVIDER
          value: $(params.git_provider)
        - name: MOON_URL
          value: $(params.moon_url)
        - name: BROWSER_TYPE
          value: $(params.browser_type)
        - name: BROWSER_NAME
          value: $(params.browser_name)
        - name: BROWSER_VERSION
          value: $(params.browser_version)
        - name: SECRET_NAME
          value: $(params.secret_name)
        - name: SECRET_NAMESPACE
          value: $(params.secret_namespace)
        - name: REGISTRY_TYPE
          value: $(params.registry_type)
      script: |
        set -ex

        chmod +x ./gradlew

        ./gradlew bootRun \
        -Dcluster="${CLUSTER}" \
        -Dthreads.number="${THREADS_NUM}" \
        -Dnamespace="${NAMESPACE}" \
        -Dtags="${TAGS}" \
        -Dci.tool=${CI_TOOL} \
        -Dgit.provider="${GIT_PROVIDER}" \
        -Dmoon.url="${MOON_URL}" \
        -Dbrowser.type="${BROWSER_TYPE}" \
        -Dbrowser.name="${BROWSER_NAME}" \
        -Dbrowser.version="${BROWSER_VERSION}" \
        -Dsecret.name="${SECRET_NAME}" \
        -Dsecret.namespace="${SECRET_NAMESPACE}" \
        -Dregistry.type="${REGISTRY_TYPE}"
---
# Source: edp-custom-pipelines/templates/tasks/integration-tests-keycloak.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: keycloak-integration-tests
  labels:
    app.kubernetes.io/version: "0.1"
spec:
  workspaces:
    - name: source
  params:
    - name: CODEBASE_NAME
      type: string
    - name: E2E_HOST_NS
      type: string
      default: "e2e-vcluster"
    - name: GOLANG_IMAGE
      type: string
      default: "golang:1.20-bullseye"
    - name: TOOLS_IMAGE
      type: string
      default: "epamedp/tekton-helm:0.1.6"
    - name: GOCACHE
      description: "Go caching directory path"
      default: "$(workspaces.source.path)"
      type: string
    - name: GOMODCACHE
      description: "Go mod caching directory path"
      default: ""
      type: string
    - name: GOPROXY
      description: "Go proxy server"
      default: ""
      type: string
  results:
    - name: release_name
    - name: svc_name

  steps:
    - name: vcluster-start
      image: $(params.TOOLS_IMAGE)
      env:
        - name: CODEBASE_NAME
          value: $(params.CODEBASE_NAME)
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
      script: |
        set -x

        random_str=$(echo $RANDOM | md5sum | head -c 10)
        release_name=$(echo "${CODEBASE_NAME}-integration-tests-${random_str}" | tr '[:upper:]' '[:lower:]')

        vcluster create ${release_name} \
         -n ${E2E_HOST_NS} \
         --connect=false \
         --update-current=false

        printf "%s" "${release_name}" > "$(results.release_name.path)"

    - name: deploy-keycloak
      image: $(params.TOOLS_IMAGE)
      workingDir: $(workspaces.source.path)
      env:
        - name: CODEBASE_NAME
          value: $(params.CODEBASE_NAME)
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
      script: |
        set -x
        release_name=$(cat $(results.release_name.path))

        vcluster connect "${release_name}" --namespace ${E2E_HOST_NS} -- \
          kubectl create ns ${CODEBASE_NAME}

        vcluster connect "${release_name}" --namespace ${E2E_HOST_NS} -- \
          kubectl apply -f tests/e2e/helm-success-path/01-install-keycloak-server.yaml \
          --namespace ${CODEBASE_NAME}

        vcluster connect "${release_name}" --namespace ${E2E_HOST_NS} -- \
          kubectl wait --for condition=Available=True deployment keycloak \
          --timeout=120s --namespace ${CODEBASE_NAME}

        svc_name=$(kubectl get service --namespace ${E2E_HOST_NS} \
          --selector=vcluster.loft.sh/managed-by=${release_name},vcluster.loft.sh/namespace=${CODEBASE_NAME} \
          --no-headers \
          -o custom-columns=":metadata.name")

        printf "%s" "${svc_name}" > "$(results.svc_name.path)"

    - name: go-test
      image: $(params.GOLANG_IMAGE)
      workingDir: $(workspaces.source.path)
      onError: continue
      env:
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
        - name: GOCACHE
          value: "$(params.GOCACHE)"
        - name: GOMODCACHE
          value: "$(params.GOMODCACHE)"
        - name: GOPROXY
          value: "$(params.GOPROXY)"
      script: |
        svc_name=$(cat $(results.svc_name.path))
        TEST_KEYCLOAK_URL="http://${svc_name}.${E2E_HOST_NS}:8081" make test

    - name: vcluster-remove
      image: $(params.TOOLS_IMAGE)
      env:
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
      script: |
        release_name=$(cat $(results.release_name.path))
        vcluster -n ${E2E_HOST_NS} delete ${release_name}

    - name: go-test-verify-exitcode
      image: alpine:3.18.6
      script: |
        exitCode=$(cat $(steps.step-go-test.exitCode.path))
        if [ $exitCode == 0 ]; then
            echo "The exit code contains zero status code: ${exitCode}"
        else
            echo "The exit code contains non-zero status code: ${exitCode}"
            exit 1
        fi
---
# Source: edp-custom-pipelines/templates/tasks/integration-tests-nexus.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: nexus-integration-tests
  labels:
    app.kubernetes.io/version: "0.1"
spec:
  workspaces:
    - name: source
  params:
    - name: CODEBASE_NAME
      type: string
    - name: E2E_HOST_NS
      type: string
      default: "e2e-vcluster"
    - name: GOLANG_IMAGE
      type: string
      default: "golang:1.20-bullseye"
    - name: TOOLS_IMAGE
      type: string
      default: "epamedp/tekton-helm:0.1.6"
    - name: GOCACHE
      description: "Go caching directory path"
      default: "$(workspaces.source.path)"
      type: string
    - name: GOMODCACHE
      description: "Go mod caching directory path"
      default: ""
      type: string
    - name: GOPROXY
      description: "Go proxy server"
      default: ""
      type: string
    - name: nexus-login
      type: string
      description: Login for Nexus
      default: admin
    - name: nexus-password
      type: string
      description: Password for Nexus
      default: admin123
  results:
    - name: release_name
    - name: svc_name

  steps:
    - name: vcluster-start
      image: $(params.TOOLS_IMAGE)
      env:
        - name: CODEBASE_NAME
          value: $(params.CODEBASE_NAME)
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
      script: |
        set -x

        random_str=$(echo $RANDOM | md5sum | head -c 10)
        release_name=$(echo "${CODEBASE_NAME}-integration-tests-${random_str}" | tr '[:upper:]' '[:lower:]')

        vcluster create ${release_name} \
         -n ${E2E_HOST_NS} \
         --connect=false \
         --update-current=false

        printf "%s" "${release_name}" > "$(results.release_name.path)"

    - name: deploy-nexus
      image: $(params.TOOLS_IMAGE)
      workingDir: $(workspaces.source.path)
      env:
        - name: CODEBASE_NAME
          value: $(params.CODEBASE_NAME)
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
      script: |
        set -x
        release_name=$(cat $(results.release_name.path))

        vcluster connect "${release_name}" --namespace ${E2E_HOST_NS} -- \
          kubectl create ns ${CODEBASE_NAME}

        vcluster connect "${release_name}" --namespace ${E2E_HOST_NS} -- \
          kubectl apply -f tests/e2e/helm-success-path/01-install-nexus-server.yaml \
          --namespace ${CODEBASE_NAME}

        vcluster connect "${release_name}" --namespace ${E2E_HOST_NS} -- \
          kubectl wait --for condition=Available=True deployment nexus \
          --timeout=120s --namespace ${CODEBASE_NAME}

        svc_name=$(kubectl get service --namespace ${E2E_HOST_NS} \
          --selector=vcluster.loft.sh/managed-by=${release_name},vcluster.loft.sh/namespace=${CODEBASE_NAME} \
          --no-headers \
          -o custom-columns=":metadata.name")

        printf "%s" "${svc_name}" > "$(results.svc_name.path)"

    - name: go-test
      image: $(params.GOLANG_IMAGE)
      workingDir: $(workspaces.source.path)
      onError: continue
      env:
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
        - name: GOCACHE
          value: "$(params.GOCACHE)"
        - name: GOMODCACHE
          value: "$(params.GOMODCACHE)"
        - name: GOPROXY
          value: "$(params.GOPROXY)"
        - name: TEST_NEXUS_USER
          value: "$(params.nexus-login)"
        - name: TEST_NEXUS_PASSWORD
          value: "$(params.nexus-password)"
      script: |
        svc_name=$(cat $(results.svc_name.path))
        TEST_NEXUS_URL="http://${svc_name}.${E2E_HOST_NS}:8081" make test

    - name: vcluster-remove
      image: $(params.TOOLS_IMAGE)
      env:
        - name: E2E_HOST_NS
          value: $(params.E2E_HOST_NS)
      script: |
        release_name=$(cat $(results.release_name.path))
        vcluster -n ${E2E_HOST_NS} delete ${release_name}

    - name: go-test-verify-exitcode
      image: alpine:3.18.6
      script: |
        exitCode=$(cat $(steps.step-go-test.exitCode.path))
        if [ $exitCode == 0 ]; then
            echo "The exit code contains zero status code: ${exitCode}"
        else
            echo "The exit code contains non-zero status code: ${exitCode}"
            exit 1
        fi
---
# Source: edp-custom-pipelines/templates/tasks/release/Build.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: build-release
  labels:
    app.kubernetes.io/version: "0.3"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/categories: Build Tools
    tekton.dev/tags: build-tool
    tekton.dev/displayName: "golang build"
    tekton.dev/platforms: "linux/amd64,linux/s390x,linux/ppc64le"
spec:
  params:
    - name: GOOS
      description: "running program's operating system target"
      default: linux
      type: string
    - name: GOARCH
      description: "running program's architecture target"
      default: amd64
      type: string
    - name: GO111MODULE
      description: "value of module support"
      default: auto
      type: string
    - name: GOCACHE
      description: "Go caching directory path"
      default: "$(workspaces.source.path)"
      type: string
    - name: GOMODCACHE
      description: "Go mod caching directory path"
      default: ""
      type: string
    - name: CGO_ENABLED
      description: "Toggle cgo tool during Go build. Use value '0' to disable cgo (for static builds)."
      default: '0'
      type: string
    - name: GOSUMDB
      description: "Go checksum database url. Use value 'off' to disable checksum validation."
      default: ""
      type: string
    - name: extra-commands
      type: string
      description: Extra commands
      default: ""
      type: string
    - name: base-image
      description: "Base image"
      default: "golang:1.20-bullseye"
      type: string
    - name: goproxy
      description: "Go proxy server"
      default: ""
      type: string
  workspaces:
    - name: source
  steps:
    - name: build
      image: $(params.base-image)
      workingDir: $(workspaces.source.path)
      env:
        - name: GOOS
          value: "$(params.GOOS)"
        - name: GOARCH
          value: "$(params.GOARCH)"
        - name: GO111MODULE
          value: "$(params.GO111MODULE)"
        - name: GOCACHE
          value: "$(params.GOCACHE)"
        - name: GOMODCACHE
          value: "$(params.GOMODCACHE)"
        - name: CGO_ENABLED
          value: "$(params.CGO_ENABLED)"
        - name: GOSUMDB
          value: "$(params.GOSUMDB)"
        - name: GOPROXY
          value: "$(params.goproxy)"
      script: |
        set -ex
        $(params.extra-commands)
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/release/GitPush.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: git-release-push
  labels:
    app.kubernetes.io/version: "0.3"
spec:
  description: >-
    This Task is Golang task to build Go projects.
  workspaces:
    - name: ssh-directory
      optional: true
      description: |
        A .ssh directory with private key, known_hosts, config, etc. Copied to
        the user's home before git commands are executed. Used to authenticate
        with the git remote when performing the clone. Binding a Secret to this
        Workspace is strongly recommended over other volume types.
    - name: source
  params:
    - name: branch
      description: "For example: release/2.10"
      type: string
    - name: base_image
      description: "The execute image you want to use."
      default: "gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/git-init:v0.29.0"
      type: string
    - name: userHome
      description: |
        Absolute path to the user's home directory. Set this explicitly if you are running the image as a non-root user or have overridden
        the gitInitImage param with an image containing custom user configuration.
      type: string
      default: "/tekton/home"
  steps:
    - name: git-release-push
      image: $(params.base_image)
      workingDir: $(workspaces.source.path)
      env:
        - name: BRANCH
          value: "$(params.branch)"
        - name: PARAM_USER_HOME
          value: $(params.userHome)
        - name: WORKSPACE_SSH_DIRECTORY_BOUND
          value: $(workspaces.ssh-directory.bound)
        - name: WORKSPACE_SSH_DIRECTORY_PATH
          value: $(workspaces.ssh-directory.path)
      script: |
        #!/usr/bin/env sh
        set -ex

        if [ "${WORKSPACE_SSH_DIRECTORY_BOUND}" = "true" ] ; then
          cp -R "${WORKSPACE_SSH_DIRECTORY_PATH}" "${PARAM_USER_HOME}"/.ssh
          chmod 700 "${PARAM_USER_HOME}"/.ssh
          chmod -R 400 "${PARAM_USER_HOME}"/.ssh/*
          eval $(ssh-agent -s)
          ssh-add "${PARAM_USER_HOME}"/.ssh/id_rsa
        fi

        export GIT_SSH_COMMAND="ssh -o StrictHostKeyChecking=no"

        git push origin HEAD:${BRANCH} --tags
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/release/HelmPushGhRelease.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: helm-push-gh-release
spec:
  description: |
    This Task allows Uset to push a new version of the Helm Chart
    to the repository with Snapshot versions.
  workspaces:
    - name: source
      description: A workspace that contains the repository.

  params:
    - name: CODEBASE_NAME
      type: string

    - name: SSH_REPO_URL
      type: string
      default: "git@github.com:Rolika4/edp-helm-charts.git"

    - name: GH_CHART_URL
      type: string
      default: "https://epam.github.io/edp-helm-charts"

    - name: GH_BRANCH
      type: string
      default: "gh-pages"

    - name: GH_EMAIL
      type: string
      default: "SupportEPMD-EDP@epam.com"

    - name: GH_USER_NAME
      type: string
      default: "edp-bot"

    - name: HELM_REPO_NAME
      type: string
      default: "epamedp"

    - name: SSH_SECRET_NAME
      type: string
      default: "github-pages-helm-chart-sshkey"

    - name: PROJECT_DIR
      type: string
      description: "The directory containing project files."
      default: "."

    - name: USER_HOME
      description: |
        Absolute path to the user's home directory. Set this explicitly if you are running the image as a non-root user
        or have overridden the gitInitImage param with an image containing custom user configuration.
      type: string
      default: "/tekton/home"

    - name: chart-path
      type: string
      description: "Path to helm chart"
      default: "."

  volumes:
    - name: ssh-keys
      secret:
        secretName: $(params.SSH_SECRET_NAME)

  steps:
    - name: helm-push-gh-pages
      image: epamedp/tekton-helm:0.1.6
      workingDir: $(workspaces.source.path)/$(params.PROJECT_DIR)
      volumeMounts:
        - name: ssh-keys
          mountPath: /workspaces/ssh-keys
      env:
        - name: CODEBASE_NAME
          value: $(params.CODEBASE_NAME)
        - name: GIT_SSH_COMMAND
          value: "ssh -i $(params.USER_HOME)/.ssh/id_rsa -o StrictHostKeyChecking=no "
        - name: GIT_SSH_VARIANT
          value: "ssh"
        - name: SSH_REPO_URL
          value: $(params.SSH_REPO_URL)
        - name: GH_EMAIL
          value: $(params.GH_EMAIL)
        - name: GH_USER_NAME
          value: $(params.GH_USER_NAME)
        - name: HELM_REPO_NAME
          value: $(params.HELM_REPO_NAME)
        - name: GH_CHART_URL
          value: $(params.GH_CHART_URL)
        - name: GH_BRANCH
          value: $(params.GH_BRANCH)
        - name: PARAM_USER_HOME
          value: $(params.USER_HOME)
        - name: WORKING_DIR
          value: $(workspaces.source.path)/$(params.PROJECT_DIR)
        - name: CHART_PATH
          value: $(params.chart-path)
      script: |
        set -ex

        ls -la

        cp -R "/workspaces/ssh-keys" "${PARAM_USER_HOME}"/.ssh
        chmod 700 "${PARAM_USER_HOME}"/.ssh
        chmod -R 400 "${PARAM_USER_HOME}"/.ssh/*
        export GIT_SSH_COMMAND="ssh -o StrictHostKeyChecking=no"
        export GIT_SSH_VARIANT=ssh

        # Setting up the config for the git.
        git config --global user.email ${GH_EMAIL}
        git config --global user.name ${GH_USER_NAME}

        if [ -f "./${CHART_PATH}/Chart.yaml" ]; then
            echo "[TEKTON] Chart.yaml exists in ${CHART_PATH} in the repository."
            rm -rf chart-repo

            eval $(ssh-agent -s)
            ssh-add "${PARAM_USER_HOME}"/.ssh/id_rsa

            git clone ${SSH_REPO_URL} chart-repo
            cd chart-repo/stable

            helm repo add ${HELM_REPO_NAME} ${GH_CHART_URL}/stable --force-update
            helm dep update ${WORKING_DIR}/${CHART_PATH}/
            helm package ${WORKING_DIR}/${CHART_PATH}/ -d packages
            helm repo index --url ${GH_CHART_URL}/stable --merge index.yaml .

            git add packages/*.tgz index.yaml
            git commit -m "Push ${CODEBASE_NAME} helm chart"
            git push -u origin ${GH_BRANCH}

            cd ${WORKING_DIR}
        else
            echo "${CHART_PATH}/Chart.yaml does not exist."
        fi
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/release/UpdateReleaseVersion.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: update-release-version
  labels:
    app.kubernetes.io/version: "0.3"
spec:
  description: >-
    This Task is Golang task to build Go projects.
  workspaces:
    - name: source
  params:
    - name: version
      description: "For example: release/2.10"
      type: string
    - name: base_image
      description: "The execute image you want to use."
      default: "epamedp/tekton-python-make:0.1.4"
      type: string
    - name: node_image
      description: "The execute image you want to use."
      default: "docker.io/library/node:18.17.0-alpine3.18"
      type: string
    - name: chart-path
      description: "Path to chart directory"
      default: "deploy-templates"
      type: string
    - name: codebase-name
      description: "Application name"
      type: string
  steps:
    - name: update-helm-version
      image: $(params.base_image)
      workingDir: $(workspaces.source.path)
      env:
        - name: VERSION
          value: "$(params.version)"
        - name: CHART_PATH
          value: "$(params.chart-path)"
        - name: CODEBASE_NAME
          value: "$(params.codebase-name)"
      script: |
        #!/usr/bin/env sh
        set -e

        # release flow for components with charts
        IFS=$'\n'
        chartPath="./${CHART_PATH}/Chart.yaml"
        echo "Chart path ${chartPath}"

        echo "[TEKTON][DEBUG] Update Version and AppVersion in Chart.yaml"
        sed -i "s/^version:.*\$/version: ${VERSION}/" "${chartPath}"
        sed -i "s/^appVersion:.*\$/appVersion: ${VERSION}/" "${chartPath}"
        sed -i "s/${CODEBASE_NAME}:.*\$/${CODEBASE_NAME}:${VERSION}/" "${chartPath}"

        # Update version in README.md
        echo "[TEKTON][DEBUG] Generate Readme.md"
        make helm-docs

    - name: update-npm-version
      image: $(params.node_image)
      workingDir: $(workspaces.source.path)
      env:
        - name: VERSION
          value: "$(params.version)"
      script: |
        #!/usr/bin/env sh
        set -e

        # update version in package.json
        if [ -f package.json ]; then
          echo "[TEKTON][DEBUG] Update Package.json"
          npm version ${VERSION} --no-git-tag-version
        else
          echo "[TEKTON][DEBUG] Package.json not found."
        fi

    - name: git-tag-commit
      image: $(params.base_image)
      workingDir: $(workspaces.source.path)
      env:
        - name: VERSION
          value: "$(params.version)"
      script: |
        #!/usr/bin/env sh
        set -ex

        # release flow for components with changelog
        if [ -f CHANGELOG.md ]; then
            echo "[TEKTON][DEBUG] Generate Changelog.md"
            NEXT_RELEASE_TAG=${VERSION} make changelog
        fi

        export GIT_SSH_COMMAND="ssh -o StrictHostKeyChecking=no"
        export GIT_SSH_VARIANT=ssh
        git config --global user.email SupportEPMD-EDP@epam.com
        git config --global user.name edp-bot

        # commit if changes are detected
        git diff -s --exit-code . || (git add . && git commit -m "Bump version to ${VERSION}")
        git tag -a "v${VERSION}" -m "Release ${VERSION}"
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/release/ValidateReleaseBranch.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: validate-release-branch
  labels:
    app.kubernetes.io/version: "0.3"
spec:
  description: >-
    This Task is Golang task to build Go projects.
  params:
    - name: branch
      description: "For example: release/2.10"
      type: string
    - name: base_image
      description: "The execute image you want to use."
      default: "golang:1.20-bullseye"
      type: string
  steps:
    - name: validate-release-branch
      image: $(params.base_image)
      env:
        - name: BRANCH
          value: "$(params.branch)"
      script: |
        set -ex

        RELEASE_BRANCH_PATTERN='^(master)$|^(release/)([0-9]{1,2}[.][0-9]{1,2})$'
        BRANCH=${BRANCH}

        if ! echo "${BRANCH}" | egrep -q "${RELEASE_BRANCH_PATTERN}"; then
            echo "!! Malformed branch name: '${BRANCH}', must match '${RELEASE_BRANCH_PATTERN}'" >&2
            exit 1
        fi
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/release/ValidateTargetVersion.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: validate-target-version
  labels:
    app.kubernetes.io/version: "0.3"
spec:
  description: >-
    This Task is Golang task to build Go projects.
  workspaces:
    - name: ssh-directory
      optional: true
      description: |
        A .ssh directory with private key, known_hosts, config, etc. Copied to
        the user's home before git commands are executed. Used to authenticate
        with the git remote when performing the clone. Binding a Secret to this
        Workspace is strongly recommended over other volume types.
  params:
    - name: version
      description: "For example: release/2.10"
      type: string
    - name: git-source-url
      type: string
    - name: base_image
      description: "The execute image you want to use."
      default: "gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/git-init:v0.29.0"
      type: string
    - name: userHome
      description: |
        Absolute path to the user's home directory. Set this explicitly if you are running the image as a non-root user or have overridden
        the gitInitImage param with an image containing custom user configuration.
      type: string
      default: "/tekton/home"
  steps:
    - name: validate-target-version
      image: $(params.base_image)
      env:
        - name: VERSION
          value: "$(params.version)"
        - name: GIT_SOURCE_URL
          value: $(params.git-source-url)
        - name: PARAM_USER_HOME
          value: $(params.userHome)
        - name: WORKSPACE_SSH_DIRECTORY_BOUND
          value: $(workspaces.ssh-directory.bound)
        - name: WORKSPACE_SSH_DIRECTORY_PATH
          value: $(workspaces.ssh-directory.path)
      script: |
        #!/usr/bin/env sh
        set -e

        EDP_VERSION_PATTERN="^([0-9]{1,2}[.][0-9]{1,2}[.]([0-9]{1,2}))$"

        if ! echo "${VERSION}" | egrep -q "${EDP_VERSION_PATTERN}"; then
            echo "![TEKTON][DEBUG] !! Malformed EDP version value: '${VERSION}', must match '${EDP_VERSION_PATTERN}'" >&2
            exit 1
        fi

        cp -R "${WORKSPACE_SSH_DIRECTORY_PATH}" "${PARAM_USER_HOME}"/.ssh
        chmod 700 "${PARAM_USER_HOME}"/.ssh
        chmod -R 400 "${PARAM_USER_HOME}"/.ssh/*
        eval $(ssh-agent -s)
        ssh-add "${PARAM_USER_HOME}"/.ssh/id_rsa

        export GIT_SSH_COMMAND="ssh -o StrictHostKeyChecking=no"

        if git ls-remote ${GIT_SOURCE_URL} refs/tags/v${VERSION} | grep -q -E "${VERSION}"; then
            echo "[TEKTON][DEBUG] !! Target version tag '${VERSION}' already exists in remote '${GIT_SOURCE_URL}'" >&2
            exit 1
        fi

        echo "[TEKTON][DEBUG] Done"
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
---
# Source: edp-custom-pipelines/templates/tasks/release/kaniko-release.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: kaniko-release
  annotations:
    # we use tekton-chain to sign the image and provenance so we need to upload the rekor transparency log
    chains.tekton.dev/transparency-upload: 'true'
    tekton.dev/pipelines.minVersion: "0.17.0"
    tekton.dev/categories: Image Build
    tekton.dev/tags: image-build
    tekton.dev/displayName: "Build and upload container image using Kaniko"
    tekton.dev/platforms: "linux/amd64"
spec:
  description: >-
    This Task builds a simple Dockerfile with kaniko and pushes to a registry.
    This Task stores the image name and digest as results, allowing Tekton Chains to pick up
    that an image was built & sign it.
  params:
    - name: codebase-name
      description: Name of codebase
    - name: image-tag
      description: Image tag
    - name: image-tar
      description: Name (reference) of the image tar.
      default: "image_tar"
    - name: dockerfile
      description: Dockerfile name.
      default: "Dockerfile"
    - name: context
      description: The build context used by Kaniko.
      default: ./
    - name: builder-image
      description: The image on which builds will run
      default: gcr.io/kaniko-project/executor:v1.12.1-debug
  workspaces:
    - name: source
      description: Holds the context and Dockerfile
  volumes:
    - name: dockerconfig
      secret:
        secretName: kaniko-docker-config
        items:
          - key: .dockerconfigjson
            path: config.json
        optional: true
  results:
    - name: IMAGE_DIGEST
      description: Digest of the image just built.
    - name: IMAGE_URL
      description: URL of the image just built.
  steps:
    - name: build-and-push
      workingDir: $(workspaces.source.path)
      image: "$(params.builder-image)"
      env:
        - name: CODEBASE_NAME
          value: "$(params.codebase-name)"
        - name: IMAGE_TAG
          value: "$(params.image-tag)"
        - name: IMAGE_TAR
          value: "$(params.image-tar)"
        - name: DOCKERFILE
          value: "$(params.dockerfile)"
        - name: CONTEXT
          value: "$(params.context)"
        - name: CONTAINER_REGISTRY_URL
          valueFrom:
            configMapKeyRef:
              name: edp-config
              key: container_registry_host
        - name: CONTAINER_REGISTRY_SPACE
          valueFrom:
            configMapKeyRef:
              name: edp-config
              key: container_registry_space
        - name: PLATFORM
          valueFrom:
            configMapKeyRef:
              name: edp-config
              key: platform
      script: |
        base_command="/kaniko/executor \
          --dockerfile=/workspace/source/${DOCKERFILE} \
          --context=/workspace/source/${CONTEXT} \
          --destination=${CONTAINER_REGISTRY_URL}/${CONTAINER_REGISTRY_SPACE}/${CODEBASE_NAME}:${IMAGE_TAG} \
          --digest-file=/tekton/results/IMAGE_DIGEST \
          --tar-path=${IMAGE_TAR}.tar "

        command=$base_command

        $command
      securityContext:
        runAsUser: 0
      volumeMounts:
        - name: dockerconfig
          mountPath: /kaniko/.docker
      
      computeResources:
        limits:
          cpu: "2"
          memory: 3Gi
        requests:
          cpu: "0.5"
          memory: 2Gi
    - image: alpine:3.18.6
      name: write-url
      env:
        - name: CODEBASE_NAME
          value: "$(params.codebase-name)"
        - name: IMAGE_TAG
          value: "$(params.image-tag)"
        - name: CONTAINER_REGISTRY_URL
          valueFrom:
            configMapKeyRef:
              key: container_registry_host
              name: edp-config
        - name: CONTAINER_REGISTRY_SPACE
          valueFrom:
            configMapKeyRef:
              key: container_registry_space
              name: edp-config
      script: |
        set -e
        echo -n "${CONTAINER_REGISTRY_URL}/${CONTAINER_REGISTRY_SPACE}/${CODEBASE_NAME}:${IMAGE_TAG}" | tee "$(results.IMAGE_URL.path)"
---
# Source: edp-custom-pipelines/templates/tasks/sam.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: sam
spec:
  params:
    - default: public.ecr.aws/sam/build-python3.9:1.104.0-20231206215146
      description: The base image for the task.
      name: BASE_IMAGE
      type: string
    - name: EXTRA_COMMANDS
      type: string
      description: Extra commands
      default: ""
  steps:
    - computeResources: {}
      image: $(params.BASE_IMAGE)
      name: sam-build
      script: |
        set -ex

        $(params.EXTRA_COMMANDS)
      workingDir: $(workspaces.source.path)
  workspaces:
    - description: A workspace that contains fetched git repo.
      name: source
---
# Source: edp-custom-pipelines/templates/tasks/waitFor.yaml
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: wait-for
spec:
  params:
    - name: task_name
      description: "The name of the task we are looking for"
      default: "helm-push-gh-pages"
    - name: wait_time
      description: "Delay between search attempts"
      default: 20
    - name: counter
      description: "Number of repeats"
      default: 0
    - name: max_counter
      description: "Maximum number of repeats"
      default: 1000
  steps:
    - name: wait-for
      image: epamedp/tekton-helm:0.1.6
      env:
        - name: TASK
          value: $(params.task_name)
        - name: WAIT_TIME
          value: $(params.wait_time)
        - name: COUNTER
          value: $(params.counter)
        - name: MAX_COUNTER
          value: $(params.max_counter)
      command:
        - /bin/sh
      args:
        - -c
        - |
          set -ex

          while true; do
            taskrun_list=$(kubectl get taskrun -o=jsonpath='{range .items[?(@.status.conditions[].reason=="Pending")]}{.metadata.name}{"\n"}{end}' 2>/dev/null \
            && kubectl get taskrun -o=jsonpath='{range .items[?(@.status.conditions[].reason=="Running")]}{.metadata.name}{"\n"}{end}' 2>/dev/null | grep ${TASK} || true)
            echo "echo ${taskrun_list}"
            if echo ${taskrun_list} | grep ${TASK} ; then
              echo "TaskRun running and contains task ${TASK}"
              sleep ${WAIT_TIME}
              COUNTER=$((COUNTER+1))
              if [ "${COUNTER}" = "${MAX_COUNTER}" ]; then
                echo "Maximum number of retries reached, exiting script"
                exit 1
              fi
            else
              echo "${TASK} is not running, go to the next task"
              break
            fi
          done
