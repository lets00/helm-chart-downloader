---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/controller-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-nginx-ingress-controller
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: controller
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: nginx-ingress-controller
      app.kubernetes.io/component: controller
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 8080
        - port: 8443
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/default-backend-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-nginx-ingress-controller-default-backend
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: default-backend
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: nginx-ingress-controller
      app.kubernetes.io/component: default-backend
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 8080
---
# Source: clustercontrol/charts/monitoring/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: monitoring-0.9.16
    app.kubernetes.io/managed-by: Helm
  name: my-release-monitoring
  namespace: clustercontrol-2024.05.1.tgz
---
# Source: clustercontrol/charts/mysql-innodbcluster/templates/service_account_cluster.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-sa
  namespace: clustercontrol-2024.05.1.tgz
---
# Source: clustercontrol/charts/mysql-operator/templates/service_account_operator.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mysql-operator-sa
  namespace: clustercontrol-2024.05.1.tgz
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-nginx-ingress-controller
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
automountServiceAccountToken: false
---
# Source: clustercontrol/charts/mysql-innodbcluster/templates/cluster_secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-cluster-secret
  namespace: clustercontrol-2024.05.1.tgz
stringData:
  rootUser: "cmon"
  rootHost: "%"
  rootPassword: "cmon"
---
# Source: clustercontrol/templates/secrets.yaml
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: cmon-credentials
stringData:
  cmon-user: ccrpc
  cmon-password: xdvdLsCmRHXveihI
---
# Source: clustercontrol/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: s9s-conf
stringData:
  s9s.conf: |
    [global]
    controller=https://cmon-master:9501/
    cmon_user=ccrpc
    cmon_password=xdvdLsCmRHXveihI
---
# Source: clustercontrol/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: cmon-cnf
stringData:
  cmon.cnf: |
    hostname=0.0.0.0
    mysql_hostname=my-release
    mysql_port=3306
    mysql_password='cmon'
    cmon_user=cmon
    cmon_db=cmon
    rpc_user=ccrpc
    rpc_key=xdvdLsCmRHXveihI
    ccsetup_key=zrgyrbjwlRMxVsNz
    controller_id=00000000-0000-0000-0000-000000000000
    prometheus_hostname=my-release-monitoring-server
---
# Source: clustercontrol/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: ssh-keys
stringData:
  example: |
    -----BEGIN OPENSSH PRIVATE KEY-----
    b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAABlwAAAAdzc2gtcn
    NhAAAAAwEAAQAAAYEAlI7G/DeFnjiUbMkTUexkrDomhQ+CqoE+r0WlfvlpUEE07LMm3OAW
    G1G8ydR4c7ylh43/z36d+dF+UAWpogbMeJMgBXnXzOHxS81SO1m10XxnUwfeEl0A3QE5cM
    0qQkN8094G2V0bfVM5NnY5tn9InDzIPUlzMEzSfPV2MvO7TIOIZ/m1q5gH8nhjyzBgToCm
    LaBgAUMdC8AX1l1hNQZIsbFsAj8s1vVIv1yfiqEAtqByaPq/1EREVmTY8e2aeZhkvGmcUs
    aW+HEmzitQ7HPbwxT4vonLyEQVrR3LwV3/H0H7vBsgy0bAKv/fG1TLy+rBPcqKovzxw27e
    xLBPPCstwOS2n/VDVnpzw5pI9D5uskfKccoFZSG1UWnfTUlqhlMfVuo3pPJGqli5WtQu2N
    0UFq3tdWPaVGm3D0gAQdxRcWE0fjFfrdC1S8jJq+1whwtoB9KN7j795FPMBMMaMZlEgykp
    VXtu1ihvWIHmUgG8KkrbzZlrARF+AZVEbBsnh8OvAAAFgCfXe60n13utAAAAB3NzaC1yc2
    EAAAGBAJSOxvw3hZ44lGzJE1HsZKw6JoUPgqqBPq9FpX75aVBBNOyzJtzgFhtRvMnUeHO8
    pYeN/89+nfnRflAFqaIGzHiTIAV518zh8UvNUjtZtdF8Z1MH3hJdAN0BOXDNKkJDfNPeBt
    ldG31TOTZ2ObZ/SJw8yD1JczBM0nz1djLzu0yDiGf5tauYB/J4Y8swYE6Api2gYAFDHQvA
    F9ZdYTUGSLGxbAI/LNb1SL9cn4qhALagcmj6v9RERFZk2PHtmnmYZLxpnFLGlvhxJs4rUO
    xz28MU+L6Jy8hEFa0dy8Fd/x9B+7wbIMtGwCr/3xtUy8vqwT3KiqL88cNu3sSwTzwrLcDk
    tp/1Q1Z6c8OaSPQ+brJHynHKBWUhtVFp301JaoZTH1bqN6TyRqpYuVrULtjdFBat7XVj2l
    Rptw9IAEHcUXFhNH4xX63QtUvIyavtcIcLaAfSje4+/eRTzATDGjGZRIMpKVV7btYob1iB
    5lIBvCpK282ZawERfgGVRGwbJ4fDrwAAAAMBAAEAAAGAHwD7Q1kdEEvToi6G0zKoQg9yyZ
    NWnFoT6IV7CBhqY77wGjQ7eJ5lzrbM1Tx8FP96dmNqz3Wn56LSn0XHRNLxanqeFLZ8lLxU
    3RKRRmSvHvS9JaV/McrqKrWeNM4Es0adbyQnvsaBPbMYPicHXXCMCVtgGPZSzXJC/aRG0l
    RuswXCepyxTwoQIokAnr/OYaPUyrHtR2Yn0jN5Zhof9u6ETl1uYrunkocncxSUEV0Ppo2u
    wv0N+vFyZ6ttYXRKqHTmw6IoT5RamV28bVFGVPW3NsCLdLedZyy7VsTQ9wsXL2Hqfu8XcC
    xew8D/7SPkfvsuDa7SL9m57L2UTaDgEI8OSd5LXNDD5tqSXdYz559/4D8FYdn4AFMuYHQ6
    648ZTvgHjijPcnLjKFguSGwE5PsJ0vHor6XnPoBFM1rYg/iJWBm3LbZ5HUkGtTUtpM5RLy
    yDRi0PfjwaT4XxnS2fwEt8wCPexzPR/H15UbgW3vEujaha3TYEcuoPnFK8Pb4kbnYRAAAA
    wA6YA1nn6moiFib/VjWVS0D1cDOr39FwVL8iLfwTvUpgUZnDuZeQoWg+caTTCijzmMWeHk
    WVDlQT2kXNxImBkhHVFlAoqNrHGGNCZd/rdA8hZl/JtliVbDK8KO04z2TPgjwyJlugZVLq
    fk27xnrDJvaPbOVPhXcnsErhLwsseRgx85DpQVA0gWFLL7FB2QXzqo6P4WRaHr8KQS6W4T
    Xpaqk+z4ijWfJrQFSOpYv9xogYaiyN8BHvszh4Nu62VFBzAAAAAMEAtyPzlB6NC0nkK/xW
    NaP68a3/lgWTK+Tja2Y8Wv5SiR5vVeq253Abr/M0TiEkgNrIOVSWcABlT4vUYy6/YCWVgy
    uFFi8xDlleVfUcjnTrIU9H+Ry6AFHhE0J8Y52SF+XHTgcdycDMBrHEJmw3y32pgfnvpKCL
    +O0rR5HYJ1eBfXWCnpw9MNNPvQccCGNm4UH4bkExt2FX2pvb7GiBgjjxh5OhDOoqKGqg68
    pub/jUEFCWMLfienmjge3VmG20rnh/AAAAwQDPqLqFdsNlp9lcB2ZU7AGjfCNeiDSgyVlK
    bUS9rXKmHwVvQ+Gur6Wl7MUwkrH5Opvuf7U0TsRGwEXsumuRlSWG3g1UDcy8q5pnbg6c62
    Q4ZSPU+P0Ahf8hRY9xtIOKKya2VFrTtao7X8jYA5Sexqcjvg8GSp8o7pWJ44wodj6kTq7h
    SG+r+dTObJNQV+xnFOdA1/UDaU29H9LDdYWfmlOup8+X6Aum5E0YyrxSEq+xG9SzuiZnYf
    LN/xLOR6dWnNEAAAAJY2FudG9AbWJwAQI=
    -----END OPENSSH PRIVATE KEY-----
  example.pub: |
    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCUjsb8N4WeOJRsyRNR7GSsOiaFD4KqgT6vRaV++WlQQTTssybc4BYbUbzJ1HhzvKWHjf/Pfp350X5QBamiBsx4kyAFedfM4fFLzVI7WbXRfGdTB94SXQDdATlwzSpCQ3zT3gbZXRt9Uzk2djm2f0icPMg9SXMwTNJ89XYy87tMg4hn+bWrmAfyeGPLMGBOgKYtoGABQx0LwBfWXWE1BkixsWwCPyzW9Ui/XJ+KoQC2oHJo+r/URERWZNjx7Zp5mGS8aZxSxpb4cSbOK1Dsc9vDFPi+icvIRBWtHcvBXf8fQfu8GyDLRsAq/98bVMvL6sE9yoqi/PHDbt7EsE88Ky3A5Laf9UNWenPDmkj0Pm6yR8pxygVlIbVRad9NSWqGUx9W6jek8kaqWLla1C7Y3RQWre11Y9pUabcPSABB3FFxYTR+MV+t0LVLyMmr7XCHC2gH0o3uPv3kU8wEwxoxmUSDKSlVe27WKG9YgeZSAbwqStvNmWsBEX4BlURsGyeHw68= canto@mbp

# below config map is here so it can share a randomly generated password
# unfortunately helm supports this only if random string is used in one template
---
# Source: clustercontrol/charts/monitoring/templates/scrape-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-monitoring-server-scrapeconfig
  namespace: clustercontrol-2024.05.1.tgz
  labels:
    app: server
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/instance: my-release
    helm.sh/chart: monitoring-0.9.16
    app.kubernetes.io/managed-by: Helm
data:
  scrape.yml: |
    
    global:
      external_labels:
        monitor: clustercontrol
        use_cmon_sd: true
      scrape_interval: 1m
      scrape_timeout: 10s
    
    scrape_configs:
    - job_name: victoriametrics
      static_configs:
      - targets:
        - localhost:8428
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-apiservers
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: default;kubernetes;https
        source_labels:
        - __meta_kubernetes_namespace
        - __meta_kubernetes_service_name
        - __meta_kubernetes_endpoint_port_name
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      honor_timestamps: false
      job_name: kubernetes-nodes-cadvisor
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - job_name: kubernetes-service-endpoints
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: drop
        regex: true
        source_labels:
        - __meta_kubernetes_pod_container_init
      - action: keep_if_equal
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_port
        - __meta_kubernetes_pod_container_port_number
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: kubernetes_node
    - job_name: kubernetes-service-endpoints-slow
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: drop
        regex: true
        source_labels:
        - __meta_kubernetes_pod_container_init
      - action: keep_if_equal
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_port
        - __meta_kubernetes_pod_container_port_number
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: kubernetes_node
      scrape_interval: 5m
      scrape_timeout: 30s
    - job_name: kubernetes-services
      kubernetes_sd_configs:
      - role: service
      metrics_path: /probe
      params:
        module:
        - http_2xx
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
      - source_labels:
        - __address__
        target_label: __param_target
      - replacement: blackbox
        target_label: __address__
      - source_labels:
        - __param_target
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: drop
        regex: true
        source_labels:
        - __meta_kubernetes_pod_container_init
      - action: keep_if_equal
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        - __meta_kubernetes_pod_container_port_number
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: kubernetes_pod_name
    - http_sd_configs:
      - url: http://cmon-master:8080
      job_name: cmon-sd
      relabel_configs:
      - regex: (.*):(\d+)
        replacement: ${1}
        source_labels:
        - __address__
        target_label: ip
      - replacement: true
        target_label: use_cmon_sd
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/controller-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-nginx-ingress-controller
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: controller
data:
  allow-snippet-annotations: "false"
  allow-backend-server-header: "true"
  allow-snippet-annotations: "true"
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/default-backend-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-nginx-ingress-controller-default-backend
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.25.4
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: default-backend
data:
  defaultBackend.conf: |-
    location /healthz {
      return 200;
    }
    
    location / {
      return 404;
    }
---
# Source: clustercontrol/templates/secrets.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-js
data:
  config.js: |
    window.FEAS_ENV = {
      CMON_API_URL: 'https://localhost/cmon/v2',
      VERSION: '2.0.0-8821',
      INITIAL_PASSWORD: 'zrgyrbjwlRMxVsNz',
      USER_REGISTRATION: 1,
    };
---
# Source: clustercontrol/charts/monitoring/templates/server-pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: my-release-monitoring-server
  namespace: clustercontrol-2024.05.1.tgz
  labels:
    app: server
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/instance: my-release
    helm.sh/chart: monitoring-0.9.16
    app.kubernetes.io/managed-by: Helm
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: "16Gi"
---
# Source: clustercontrol/templates/deployment.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cmon-master-volume
spec:
  
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
# Source: clustercontrol/templates/deployment.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cmon-var-lib-cmon
spec:
  
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
# Source: clustercontrol/charts/monitoring/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-monitoring-clusterrole
  labels:
    helm.sh/chart: monitoring-0.9.16
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
    - discovery.k8s.io
    resources:
    - endpointslices
    verbs: ["get", "list", "watch"]
  - apiGroups: [ "" ]
    resources:
      - nodes
      - nodes/proxy
      - nodes/metrics
      - services
      - endpoints
      - pods
    verbs: [ "get", "list", "watch" ]
  - apiGroups:
      - extensions
      - networking.k8s.io
    resources:
      - ingresses
    verbs: [ "get", "list", "watch" ]
  - nonResourceURLs: [ "/metrics" ]
    verbs: [ "get" ]
---
# Source: clustercontrol/charts/mysql-operator/templates/cluster_role_operator.yaml
# The main role for the operator
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: mysql-operator
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch", "patch"]
  - apiGroups: [""]
    resources: ["pods/status"]
    verbs: ["get", "patch", "update", "watch"]
    # Kopf needs patch on secrets or the sidecar will throw
    # The operator needs this verb to be able to pass it to the sidecar
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "create", "list", "watch", "patch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "create", "list", "watch", "patch"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "create", "list"]
  - apiGroups: [""]
    resources: ["serviceaccounts"]
    verbs: ["get", "create"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "patch", "update"]
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources: ["rolebindings"]
    verbs: ["get", "create"]
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["get", "create"]
  - apiGroups: ["batch"]
    resources: ["jobs"]
    verbs: ["create"]
  - apiGroups: ["batch"]
    resources: ["cronjobs"]
    verbs: ["create", "update", "delete"]
  - apiGroups: ["apps"]
    resources: ["deployments", "statefulsets"]
    verbs: ["get", "create", "patch", "watch", "delete"]
  - apiGroups: ["mysql.oracle.com"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["zalando.org"]
    resources: ["*"]
    verbs: ["get", "patch", "list", "watch"]
  # Kopf: runtime observation of namespaces & CRDs (addition/deletion).
  - apiGroups: [apiextensions.k8s.io]
    resources: [customresourcedefinitions]
    verbs: [list, watch]
  - apiGroups: [""]
    resources: [namespaces]
    verbs: [list, watch]
---
# Source: clustercontrol/charts/mysql-operator/templates/cluster_role_sidecar.yaml
# role for the server sidecar
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: mysql-sidecar
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch", "patch"]
  - apiGroups: [""]
    resources: ["pods/status"]
    verbs: ["get", "patch", "update", "watch"]
  # Kopf needs patch on secrets or the sidecar will throw
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "create", "list", "watch", "patch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "create", "list", "watch", "patch"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "create", "list"]
  - apiGroups: [""]
    resources: ["serviceaccounts"]
    verbs: ["get", "create"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "patch", "update"]
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["get", "patch"]
  - apiGroups: ["mysql.oracle.com"]
    resources: ["innodbclusters"]
    verbs: ["get", "watch", "list"]
  - apiGroups: ["mysql.oracle.com"]
    resources: ["mysqlbackups"]
    verbs: ["create", "get", "list", "patch", "update", "watch", "delete"]
  - apiGroups: ["mysql.oracle.com"]
    resources: ["mysqlbackups/status"]
    verbs: ["get", "patch", "update", "watch"]
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: my-release-nginx-ingress-controller
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - endpoints
      - nodes
      - pods
      - secrets
      - namespaces
    verbs:
      - list
      - watch
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
      - list
      - update
      - watch
  - apiGroups:
      
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      
      - networking.k8s.io
    resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - discovery.k8s.io
    resources:
      - endpointslices
    verbs:
      - list
      - watch
      - get
---
# Source: clustercontrol/charts/monitoring/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-monitoring-clusterrolebinding
  labels:
    helm.sh/chart: monitoring-0.9.16
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: my-release-monitoring
    namespace: clustercontrol-2024.05.1.tgz
roleRef:
  kind: ClusterRole
  name: my-release-monitoring-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: clustercontrol/charts/mysql-operator/templates/cluster_role_binding_operator.yaml
# Give access to the operator
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: mysql-operator-rolebinding
subjects:
  - kind: ServiceAccount
    name: mysql-operator-sa
    namespace: clustercontrol-2024.05.1.tgz
  # TODO The following entry is for dev purposes only and must be deleted
  #- kind: Group
  #  name: system:serviceaccounts
  #  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: mysql-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-release-nginx-ingress-controller
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-release-nginx-ingress-controller
subjects:
  - kind: ServiceAccount
    name: my-release-nginx-ingress-controller
    namespace: "clustercontrol-2024.05.1.tgz"
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-release-nginx-ingress-controller
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
rules:
  - apiGroups:
      - ""
    resources:
      - namespaces
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - configmaps
      - pods
      - secrets
      - endpoints
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
      - list
      - update
      - watch
  - apiGroups:
      
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      
      - networking.k8s.io
    resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - configmaps
    resourceNames:
      - ingress-controller-leader
    verbs:
      - get
      - update
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - create
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      - discovery.k8s.io
    resources:
      - endpointslices
    verbs:
      - list
      - watch
      - get
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - create
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    resourceNames:
      - ingress-controller-leader
    verbs:
      - get
      - update
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-release-nginx-ingress-controller
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-release-nginx-ingress-controller
subjects:
  - kind: ServiceAccount
    name: my-release-nginx-ingress-controller
    namespace: "clustercontrol-2024.05.1.tgz"
---
# Source: clustercontrol/charts/monitoring/templates/server-service.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: clustercontrol-2024.05.1.tgz
  labels:
    app: server
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/instance: my-release
    helm.sh/chart: monitoring-0.9.16
    app.kubernetes.io/managed-by: Helm
  name: my-release-monitoring-server
spec:
  ports:
    - name: http
      port: 9090
      protocol: TCP
      targetPort: http
  selector:
    app: server
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/instance: my-release
  type: "ClusterIP"
---
# Source: clustercontrol/charts/mysql-operator/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql-operator
  namespace: clustercontrol-2024.05.1.tgz
  labels:
    name: mysql-operator
spec:
  type: ClusterIP
  ports:
  - port: 9443
    protocol: TCP
  selector:
    name: mysql-operator
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/controller-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-nginx-ingress-controller
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: controller
spec:
  type: LoadBalancer
  sessionAffinity: None
  externalTrafficPolicy: ""
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/component: controller
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/default-backend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-nginx-ingress-controller-default-backend
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.25.4
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: default-backend
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/component: default-backend
---
# Source: clustercontrol/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: cmon-master
spec:
  ports:
  - port: 9501
    protocol: TCP
    targetPort: 9501
    name: 9501-port
  - port: 8080
    protocol: TCP
    targetPort: 8080
    name: 8080-port
  - port: 9954
    protocol: TCP
    targetPort: 9954
    name: 9954-port
  - port: 80
    protocol: TCP
    targetPort: 80
    name: 80-port
  - port: 9511
    protocol: TCP
    targetPort: 9511
    name: 9511-port
  selector:
    app: cmon-master
    run: cmon-master
  type: ClusterIP
---
# Source: clustercontrol/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: severalnines
spec:
  externalName: severalnines.com
  type: ExternalName
  ports:
  - port: 443
    name: port-443
  - port: 80
    name: port-80
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/controller-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: my-release-nginx-ingress-controller
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: controller
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: nginx-ingress-controller
      app.kubernetes.io/component: controller
  revisionHistoryLimit: 10
  minReadySeconds: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: nginx-ingress-controller
        app.kubernetes.io/version: 1.10.0
        helm.sh/chart: nginx-ingress-controller-11.1.0
        app.kubernetes.io/component: controller
    spec:
      
      dnsPolicy: ClusterFirst
      automountServiceAccountToken: true
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: nginx-ingress-controller
                    app.kubernetes.io/component: controller
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      serviceAccountName: my-release-nginx-ingress-controller
      terminationGracePeriodSeconds: 60
      initContainers:
        - name: prepare-nginx-folder
          image: docker.io/bitnami/nginx-ingress-controller:1.10.0-debian-12-r6
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -ec
            - |
              #!/bin/bash
              cp -r /etc/nginx/* /nginx
              cp -r /etc/ingress-controller/* /ingress-controller
          volumeMounts:
            - name: empty-dir
              mountPath: /nginx
              subPath: app-nginx-dir
            - name: empty-dir
              mountPath: /ingress-controller
              subPath: app-controller-dir
      containers:
        - name: controller
          image: docker.io/bitnami/nginx-ingress-controller:1.10.0-debian-12-r6
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          args:
            - --default-backend-service=$(POD_NAMESPACE)/my-release-nginx-ingress-controller-default-backend
            - --publish-service=clustercontrol-2024.05.1.tgz/my-release-nginx-ingress-controller
            - --http-port=8080
            - --https-port=8443
            - --healthz-port=10254
            - --election-id=ingress-controller-leader
            - --controller-class=k8s.io/ingress-nginx
            - --configmap=$(POD_NAMESPACE)/my-release-nginx-ingress-controller
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          envFrom:
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: https
              containerPort: 8443
              protocol: TCP
            - name: metrics
              containerPort: 10254
              protocol: TCP
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /etc/nginx
              subPath: app-nginx-dir
            - name: empty-dir
              mountPath: /etc/ingress-controller
              subPath: app-controller-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /tmp/nginx
              subPath: app-tmp-dir
            - name: empty-dir
              mountPath: /etc/ingress-controller/telemetry
              subPath: app-telemetry-dir
      volumes:
        - name: empty-dir
          emptyDir: {}
---
# Source: clustercontrol/charts/monitoring/templates/server-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: server
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/instance: my-release
    helm.sh/chart: monitoring-0.9.16
    app.kubernetes.io/managed-by: Helm
  name: my-release-monitoring-server
  namespace: clustercontrol-2024.05.1.tgz
spec:
  selector:
    matchLabels:
      app: server
      app.kubernetes.io/name: monitoring
      app.kubernetes.io/instance: my-release
  replicas: 1
  strategy:
    # Must be "Recreate" when we have a persistent volume
    type: Recreate
  template:
    metadata:
      annotations:
        prometheus.io/port: "8428"
        prometheus.io/scrape: "true"
      labels:
        app: server
        app.kubernetes.io/name: monitoring
        app.kubernetes.io/instance: my-release
        helm.sh/chart: monitoring-0.9.16
        app.kubernetes.io/managed-by: Helm
    spec:
      automountServiceAccountToken: true
      containers:
        - name: monitoring-server
          securityContext:
            {}
          image: "victoriametrics/victoria-metrics:v1.99.0"
          imagePullPolicy: "IfNotPresent"
          args:
            - "--retentionPeriod=1"
            - "--storageDataPath=/storage"
            - -promscrape.config=/scrapeconfig/scrape.yml
            - --envflag.enable=true
            - --envflag.prefix=VM_
            - --loggerFormat=json
            - --maxLabelsPerTimeseries=99
            - --promscrape.maxScrapeSize=5.6777216e+07
          ports:
            - name: http
              containerPort: 8428
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /health
              port: 8428
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 5
            periodSeconds: 15
            timeoutSeconds: 5
          resources:
            {}
          volumeMounts:
            - name: server-volume
              mountPath: /storage
              subPath: 
            - name: scrapeconfig
              mountPath: /scrapeconfig
            
      serviceAccountName: my-release-monitoring
      terminationGracePeriodSeconds: 60
      volumes:
      - name: scrapeconfig
        configMap:
          name: my-release-monitoring-server-scrapeconfig
      - name: server-volume
        persistentVolumeClaim:
          claimName: my-release-monitoring-server
---
# Source: clustercontrol/charts/mysql-operator/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql-operator
  namespace: clustercontrol-2024.05.1.tgz
  labels:
    version: "8.0.37-2.0.14"
    app.kubernetes.io/name: mysql-operator
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "8.0.37-2.0.14"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: helm
    app.kubernetes.io/created-by: helm
spec:
  replicas: 1
  selector:
    matchLabels:
      name: mysql-operator
  template:
    metadata:
      labels:
        name: mysql-operator
    spec:
      containers:
        - name: mysql-operator
          image: container-registry.oracle.com/mysql/community-operator:8.0.37-2.0.14
          imagePullPolicy: IfNotPresent
          args: ["mysqlsh", "--log-level=@INFO", "--pym", "mysqloperator", "operator"]
          env:
          - name: MYSQLSH_USER_CONFIG_HOME
            value: /mysqlsh
          - name: MYSQLSH_CREDENTIAL_STORE_SAVE_PASSWORDS
            value: never
          
          - name: MYSQL_OPERATOR_IMAGE_PULL_POLICY
            value: IfNotPresent
          
          readinessProbe:
            exec:
              command:
              - cat
              - /tmp/mysql-operator-ready
            initialDelaySeconds: 1
            periodSeconds: 3
          volumeMounts:
            - name: mysqlsh-home
              mountPath: /mysqlsh
            - name: tmpdir
              mountPath: /tmp
          securityContext:
            runAsUser: 2
            allowPrivilegeEscalation: false
            privileged: false
            readOnlyRootFilesystem: true
      volumes:
        - name: mysqlsh-home
          emptyDir: {}
        - name: tmpdir
          emptyDir: {}
      serviceAccountName: mysql-operator-sa
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/default-backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-nginx-ingress-controller-default-backend
  namespace: "clustercontrol-2024.05.1.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.25.4
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: default-backend
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: nginx-ingress-controller
      app.kubernetes.io/component: default-backend
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: nginx-ingress-controller
        app.kubernetes.io/version: 1.25.4
        helm.sh/chart: nginx-ingress-controller-11.1.0
        app.kubernetes.io/component: default-backend
    spec:
      
      automountServiceAccountToken: true
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: nginx-ingress-controller
                    app.kubernetes.io/component: default-backend
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: my-release-nginx-ingress-controller
      terminationGracePeriodSeconds: 60
      containers:
        - name: default-backend
          image: docker.io/bitnami/nginx:1.25.4-debian-12-r7
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          args:
          env:
          envFrom:
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /healthz
              port: http
              scheme: HTTP
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 0
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /healthz
              port: http
              scheme: HTTP
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/nginx/tmp
              subPath: app-tmp-dir
            - name: nginx-config-volume
              mountPath: /opt/bitnami/nginx/conf/bitnami/defaultBackend.conf
              subPath: defaultBackend.conf
              readOnly: true
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: nginx-config-volume
          configMap:
            name: my-release-nginx-ingress-controller-default-backend
            items:
              - key: defaultBackend.conf
                path: defaultBackend.conf
---
# Source: clustercontrol/templates/deployment.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: cmon-master
  labels:
    app: cmon-master
    run: cmon-master
spec:
  selector:
    matchLabels:
      app: cmon-master
      run: cmon-master
  replicas: 1
  serviceName: cmon-master
  template:
    metadata:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9954"
      labels:
        app: cmon-master
        run: cmon-master
    spec:
      initContainers:
      - name: init-cmon
        image: severalnines/cmon:2.0.0-8821
        command: [ 'sh', '-c', 'cp /tmp/cmon.cnf /etc/cmon.cnf; /usr/bin/init-cmon.sh']
        volumeMounts:
        - mountPath: /tmp/cmon.cnf
          subPath: cmon.cnf
          name: cmon-cnf-cfg
        - mountPath: /root/.s9s/s9s.conf
          subPath: s9s.conf
          name: s9s-cnf-cfg
      - name: check-cmon-configs
        image: severalnines/cmon:2.0.0-8821
        command: [ 'sh', '-c', '/usr/bin/python3 /usr/bin/update-cmon-configs.py']
        volumeMounts:
        - mountPath: /etc/cmon.cnf
          subPath: cmon.cnf
          name: cmon-cnf-cfg
        - mountPath: /etc/cmon.d/
          name: cmon-master-pv
      containers:
      - name: cmon-master
        image: severalnines/cmon:2.0.0-8821
        command: [ '/usr/sbin/cmon' ]
        args:
        - -s
        - --no-log-db
        - -b 0.0.0.0
        - --mysql-connect-retries=5
        - -d
        
        securityContext:
          privileged: True
        ports:
        - containerPort: 9501
          protocol: TCP
          name: cmon9501
        - containerPort: 9500
          protocol: TCP
          name: cmon9500
        volumeMounts:
        - mountPath: /etc/cmon.d/
          name: cmon-master-pv
        - mountPath: /etc/cmon.cnf
          subPath: cmon.cnf
          name: cmon-cnf-cfg
        - mountPath: /root/.s9s/s9s.conf
          subPath: s9s.conf
          name: s9s-cnf-cfg
        - mountPath: /root/.ssh-keys
          name: ssh-keys
        
        - mountPath: /var/lib/cmon
          name: cmon-pv-var-lib-cmon
        
        livenessProbe:
          httpGet:
            path: /v2/controller?operation=ping
            port: 9501
            scheme: HTTPS
          initialDelaySeconds: 60
          timeoutSeconds: 10
          periodSeconds: 30
      - name: cmon-cloud
        image: severalnines/cmon:2.0.0-8821
        command: ['sh', '-c', '/usr/sbin/cmon-cloud']
        securityContext:
          privileged: True
        ports:
        - containerPort: 9518
          protocol: TCP
          name: cmon9518
      - name: cmon-sd
        image: severalnines/cmon-sd:build-38
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
          protocol: TCP
          name: cmon-sd8080
        env:
          - name: CMON_USERNAME
            valueFrom:
              secretKeyRef:
                name: cmon-credentials
                key: cmon-user
                optional: false
          - name: CMON_PASSWORD
            valueFrom:
              secretKeyRef:
                name: cmon-credentials
                key: cmon-password
                optional: false
      - name: cmon-exporter
        image: severalnines/cmon_exporter-linux-amd64:main
        ports:
        - containerPort: 9954
          protocol: TCP
          name: cmon-exp9954
        env:
          - name: CMON_USERNAME
            valueFrom:
              secretKeyRef:
                name: cmon-credentials
                key: cmon-user
                optional: false
          - name: CMON_PASSWORD
            valueFrom:
              secretKeyRef:
                name: cmon-credentials
                key: cmon-password
                optional: false
      - name: ccv2
        image: severalnines/cc-frontend:2.2.3
        ports:
        - containerPort: 80
          protocol: TCP
          name: 80-port
        volumeMounts:
        - mountPath: /usr/share/nginx/html/config.js
          subPath: config.js
          name: config-js-cfg
      - name: cmon-ssh
        image: severalnines/cmon:2.0.0-8821
        command: ['sh', '-c', '/usr/sbin/cmon-ssh']
        ports:
        - containerPort: 9511
          protocol: TCP
          name: cmon-ssh9511
        volumeMounts:
        - mountPath: /etc/cmon.d/
          name: cmon-master-pv
        
      volumes:
      - name: cmon-master-pv
        persistentVolumeClaim:
          claimName: cmon-master-volume
      - name: cmon-pv-var-lib-cmon
        persistentVolumeClaim:
          claimName: cmon-var-lib-cmon
      - name: cmon-cnf-cfg
        secret:
          secretName: cmon-cnf
      - name: cmon-license
        secret:
          secretName: cmon-license
          optional: true
      - name: s9s-cnf-cfg
        secret:
          secretName: s9s-conf
      - name: ssh-keys
        secret:
          secretName: ssh-keys
      - name: config-js-cfg
        configMap:
          name: config-js
---
# Source: clustercontrol/charts/nginx-ingress-controller/templates/ingressclass.yaml
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  name: nginx
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nginx-ingress-controller
    app.kubernetes.io/version: 1.10.0
    helm.sh/chart: nginx-ingress-controller-11.1.0
    app.kubernetes.io/component: controller
spec:
  controller: k8s.io/ingress-nginx
---
# Source: clustercontrol/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: clustercontrol-ccv2-ingress
  annotations:
    kubernetes.io/tls-acme: "true"
    
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - localhost
      secretName: cmon-cert
  rules:
    - host: localhost
      http:
        paths:
          - backend:
              service:
                name: cmon-master
                port:
                  number: 80 #ccv2
            path: /(.*)
            pathType: ImplementationSpecific
---
# Source: clustercontrol/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: clustercontrol-ccv2-ingress-lic
  annotations:
    kubernetes.io/tls-acme: "true"
    
    nginx.ingress.kubernetes.io/rewrite-target: /service/lic.php
    nginx.ingress.kubernetes.io/upstream-vhost: severalnines.com
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    nginx.ingress.kubernetes.io/server-snippet: |
      proxy_ssl_name severalnines.com;
      proxy_ssl_server_name on;

spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - localhost
      secretName: cmon-cert
  rules:
    - host: localhost
      http:
        paths:
          - backend:
              service:
                name: severalnines
                port:
                  number: 443
            path: /cc-license
            pathType: ImplementationSpecific
---
# Source: clustercontrol/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: clustercontrol-cmon-ingress
  annotations:
    kubernetes.io/tls-acme: "true"
    
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    nginx.ingress.kubernetes.io/configuration-snippet: |
      proxy_pass_header Server;
      add_header Server $upstream_http_server;
      more_set_headers "Set-Cookie: $sent_http_set_cookie; Path=/";

spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - localhost
      secretName: cmon-cert
  rules:
    - host: localhost
      http:
        paths:
          - backend:
              service:
                name: cmon-master #cmon
                port:
                  number: 9501
            path: /cmon/(.*)
            pathType: ImplementationSpecific
---
# Source: clustercontrol/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: clustercontrol-cmon-ssh-ingress
  annotations:
    kubernetes.io/tls-acme: "true"
    
    nginx.ingress.kubernetes.io/force-ssl-redirect: 'true'
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - localhost
      secretName: localhost
  rules:
    - host: localhost
      http:
        paths:
          - path: /cmon-ssh/(.*)
            pathType: ImplementationSpecific
            backend:
              service:
                name: cmon-master
                port:
                  number: 9511
---
# Source: clustercontrol/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: clustercontrol-websocket-cmon-ssh-ingress
  annotations:
    kubernetes.io/tls-acme: "true"
    
    nginx.ingress.kubernetes.io/rewrite-target: /cmon/ws/$1
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: 'true'
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - localhost
      secretName: localhost
  rules:
    - host: localhost
      http:
        paths:
          - path: /cmon-ssh/cmon/ws/(.*)
            pathType: Prefix
            backend:
              service:
                name: cmon-master
                port:
                  number: 9511
---
# Source: clustercontrol/charts/mysql-operator/templates/cluster_kopf_keepering.yaml
apiVersion: zalando.org/v1
kind: ClusterKopfPeering
metadata:
  name: mysql-operator
---
# Source: clustercontrol/charts/mysql-innodbcluster/templates/deployment_cluster.yaml
apiVersion: mysql.oracle.com/v2
kind: InnoDBCluster
metadata:
  name: my-release
  namespace: clustercontrol-2024.05.1.tgz
spec:
  instances: 1
  tlsUseSelfSigned: true
  router:
    instances: 1


  secretName: my-release-cluster-secret
  imagePullPolicy : IfNotPresent
  baseServerId: 1000
  version: 8.0.37
  serviceAccountName: my-release-sa
  datadirVolumeClaimTemplate:
    resources:
      requests:
        storage: "2Gi"
---
# Source: clustercontrol/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-clustercontrol-test-connection"
  labels:
    helm.sh/chart: clustercontrol-2024.05.1
    app.kubernetes.io/name: clustercontrol
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['my-release-clustercontrol:3000']
  restartPolicy: Never
