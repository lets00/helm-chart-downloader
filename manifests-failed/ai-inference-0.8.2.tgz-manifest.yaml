---
# Source: ai-inference/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: evi-ai-inference
  namespace: hce-ai
  labels:
    account: ai-inference
---
# Source: ai-inference/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: evi-minio-secret
  namespace: hce-ai
  labels: 
    app: ai-inference
type: Opaque
data:
  rootUser: 
  rootPassword:
---
# Source: ai-inference/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: hce-ai
  name: ai-inference
data:

  AiInference.config: |
    [Service]
    logDir=.
    logMaxFileSize=16777216
    logMaxFileCount=8
    logSeverity=0
    [HTTP]
    address=0.0.0.0
    port=50051
    [Pipeline]
    maxConcurrentWorkload=8
---
# Source: ai-inference/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: hce-ai
  name: hbase-storage
data:

  hbase_storage_configmap.json: |
    {
        "version": 1,
        "hbaseAddr": "my-hbase-hbase-master.dev",
        "hbasePort": 9090,
        "storageRestAddr": "storage-rest.storage-rest:9900"
    }
---
# Source: ai-inference/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: hce-ai
  name: media-storage
data:

  media_storage_configmap.json: |
    {
        "version": 1,
        "name": "row data source",
        "video_image": {
            "address": "minio-service.minio",
            "port": "9000",
            "rootUser": "/opt/hce-configs/credentials/minio/rootUser",
            "rootPassword": "/opt/hce-configs/credentials/minio/rootPassword"
        },
        "video_image_attributes": {
            "flask_server_address": "storage-rest.storage-rest",
            "flask_server_port": "9900",
            "prefix": "v1",
            "media": "/media"
        },
        "mediatype": [
            "image",
            "video"
        ],
        "datasource": [
            "person",
            "vehicle"
        ]
    }
---
# Source: ai-inference/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: evi-ai-inference
  namespace: hce-ai
  labels: 
    app: ai-inference
spec:
  ports:
  - port: 50051
    targetPort: 50051
    protocol: TCP
  type: ClusterIP
  selector:
    app: ai-inference
    version: v1
---
# Source: ai-inference/templates/deployment.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: evi-ai-inference
  namespace: hce-ai
  annotations:
    container.apparmor.security.beta.kubernetes.io/ai-inference: runtime/default
spec:
  selector:
    matchLabels:
      app: ai-inference
      version: v1
  replicas: 1
  template:
    metadata:
      labels:
        app: ai-inference
        sidecar.istio.io/inject: "true"
        version: v1
    spec:
      nodeSelector:
        feature.node.kubernetes.io/cpu-cpuid.AVX512VNNI: 'true'
        feature.node.kubernetes.io/cpu-cpuid.AVX2: 'true'
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: evi-ai-inference
      # tolerations:
      # - key: "node"
      #   operator: "Equal"
      #   value: "hddl"
      #   effect: "NoSchedule"
      containers:
      - name: evi-ai-inference
        image: "ai-inference-cpu:master-96802044e3c560ce54cdfb2c9d69e25819ef112a"
        command: ["/opt/run_service.sh"]
        imagePullPolicy: IfNotPresent
        securityContext:
          # readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
        resources:
          limits:
            cpu: "52"
            memory: 100Gi
          requests:
            cpu: 500m
            memory: 200Mi
        livenessProbe:
          httpGet:
            path: /healthz
            port:  50051
          initialDelaySeconds: 120
          periodSeconds: 60
        startupProbe:
          httpGet:
            path: /healthz
            port:  50051
          failureThreshold: 5
          periodSeconds: 60
        volumeMounts:
        - mountPath: /dev/dri/card0
          name: dri
        securityContext:
          privileged: true
        ports:
        - containerPort: 50051
        volumeMounts:
        - mountPath: /opt/hce-core/middleware/ai/ai_inference/source/low_latency_server/AiInference.config
          subPath: AiInference.config
          name: config-volume
        - mountPath: /opt/hce-configs/media_storage_configmap.json
          subPath: media_storage_configmap.json
          name: config-volume-ms
        - mountPath: /opt/hce-configs/hbase_storage_configmap.json
          subPath: hbase_storage_configmap.json
          name: config-volume-hs
        - name: media-storage-secret
          mountPath: /opt/hce-configs/credentials/minio
          readOnly: true
      volumes:
      - name: config-volume
        configMap:
          name: ai-inference
      - name: dri
        hostPath:
          path: /dev/dri/card0
      - name: config-volume-ms
        configMap:
          name: media-storage
      - name: config-volume-hs
        configMap:
          name: hbase-storage
      - name: media-storage-secret
        secret:
          secretName: evi-minio-secret
          optional: true
          items:
          - key: rootUser
            path: rootUser
          - key: rootPassword
            path: rootPassword
---
# Source: ai-inference/templates/configmap.yaml
# INTEL CONFIDENTIAL
#
# Copyright (C) 2022 Intel Corporation.
#
# This software and the related documents are Intel copyrighted materials, and your use of
# them is governed by the express license under which they were provided to you (License).
# Unless the License provides otherwise, you may not use, modify, copy, publish, distribute,
# disclose or transmit this software or the related documents without Intel's prior written permission.
#
# This software and the related documents are provided as is, with no express or implied warranties,
# other than those that are expressly stated in the License.
---
# Source: ai-inference/templates/deployment.yaml
# INTEL CONFIDENTIAL
#
# Copyright (C) 2022 Intel Corporation.
#
# This software and the related documents are Intel copyrighted materials, and your use of
# them is governed by the express license under which they were provided to you (License).
# Unless the License provides otherwise, you may not use, modify, copy, publish, distribute,
# disclose or transmit this software or the related documents without Intel's prior written permission.
#
# This software and the related documents are provided as is, with no express or implied warranties,
# other than those that are expressly stated in the License.
---
# Source: ai-inference/templates/secret.yaml
# INTEL CONFIDENTIAL
#
# Copyright (C) 2022 Intel Corporation.
#
# This software and the related documents are Intel copyrighted materials, and your use of
# them is governed by the express license under which they were provided to you (License).
# Unless the License provides otherwise, you may not use, modify, copy, publish, distribute,
# disclose or transmit this software or the related documents without Intel's prior written permission.
#
# This software and the related documents are provided as is, with no express or implied warranties,
# other than those that are expressly stated in the License.
---
# Source: ai-inference/templates/service.yaml
# INTEL CONFIDENTIAL
#
# Copyright (C) 2022 Intel Corporation.
#
# This software and the related documents are Intel copyrighted materials, and your use of
# them is governed by the express license under which they were provided to you (License).
# Unless the License provides otherwise, you may not use, modify, copy, publish, distribute,
# disclose or transmit this software or the related documents without Intel's prior written permission.
#
# This software and the related documents are provided as is, with no express or implied warranties,
# other than those that are expressly stated in the License.
---
# Source: ai-inference/templates/serviceaccount.yaml
# INTEL CONFIDENTIAL
#
# Copyright (C) 2022 Intel Corporation.
#
# This software and the related documents are Intel copyrighted materials, and your use of
# them is governed by the express license under which they were provided to you (License).
# Unless the License provides otherwise, you may not use, modify, copy, publish, distribute,
# disclose or transmit this software or the related documents without Intel's prior written permission.
#
# This software and the related documents are provided as is, with no express or implied warranties,
# other than those that are expressly stated in the License.
