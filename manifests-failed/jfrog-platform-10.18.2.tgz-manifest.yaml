---
# Source: jfrog-platform/charts/xray/templates/xray-resourcequota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  labels:
    app: xray
    chart: xray-103.96.1
    release: "my-release"
    heritage: "Helm"
  name: my-release-xray
spec:
  hard:
    count/jobs.batch: 100
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-artifactory-nginx
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    component: nginx
    heritage: Helm
    release: my-release
spec:
  selector:
    matchLabels:
      component: nginx
      app: artifactory
      release: my-release
  minAvailable: 0
---
# Source: jfrog-platform/charts/rabbitmq/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-rabbitmq
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
secrets:
  - name: my-release-rabbitmq
---
# Source: jfrog-platform/charts/artifactory/templates/artifactory-unified-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-artifactory-unified-secret
  labels:
    app: "artifactory"
    chart: "artifactory-107.84.14"
    component: "artifactory"
    heritage: "Helm"
    release: "my-release"
type: Opaque
stringData:
  access.config.patch.yml: |
    security:
      tls: false
  binarystore.xml: |-
    <!-- File system filestore -->
    <config version="v1">
        <chain> <!--template="file-system"-->
                <provider id="file-system" type="file-system"/>
        </chain>
    </config>
  system.yaml: |

    access:
      database:
        maxOpenConnections: 80
      tomcat:
        connector:
          extraConfig: acceptCount="100"
          maxThreads: 50
          sendReasonPhrase: false
    artifactory:
      database:
        maxOpenConnections: 80
      tomcat:
        connector:
          extraConfig: acceptCount="400"
          maxThreads: 200
          sendReasonPhrase: false
        maintenanceConnector:
          port: 8091
    federation:
      enabled: false
    frontend:
      session:
        timeMinutes: "30"
    jfconnect:
      enabled: true
    mc:
      database:
        maxOpenConnections: 10
      enabled: true
      idgenerator:
        maxOpenConnections: 2
      tomcat:
        connector:
          extraConfig: acceptCount="100"
          maxThreads: 50
          sendReasonPhrase: false
    metadata:
      database:
        maxOpenConnections: 80
    router:
      serviceRegistry:
        insecure: false
    shared:
      database:
        allowNonPostgresql: false
        driver: org.postgresql.Driver
        type: postgresql
      extraJavaOpts: |
        -Dartifactory.graceful.shutdown.max.request.duration.millis=30000 -Dartifactory.access.client.max.connections=50
      logging:
        consoleLog:
          enabled: false

data:
  db-url: "amRiYzpwb3N0Z3Jlc3FsOi8vbXktcmVsZWFzZS1wb3N0Z3Jlc3FsOjU0MzIvYXJ0aWZhY3Rvcnk/c3NsbW9kZT1kaXNhYmxl"
  db-user: "YXJ0aWZhY3Rvcnk="
  db-password: "YXJ0aWZhY3Rvcnk="
  master-key: "YmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYg=="
  join-key: "RUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUU="
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-certificate-secret.yaml
apiVersion: v1
kind: Secret
type: kubernetes.io/tls
metadata:
  name: my-release-artifactory-nginx-certificate
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    heritage: Helm
    release: my-release
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURtekNDQW9PZ0F3SUJBZ0lRWXoyMC9mQWRqZSt5ZkY5dVR5enhaREFOQmdrcWhraUc5dzBCQVFzRkFEQVoKTVJjd0ZRWURWUVFERXc1aGNuUnBabUZqZEc5eWVTMWpZVEFlRncweU5EQTJNakF4TkRVM01USmFGdzB5TlRBMgpNakF4TkRVM01USmFNQ0V4SHpBZEJnTlZCQU1URm0xNUxYSmxiR1ZoYzJVdFlYSjBhV1poWTNSdmNua3dnZ0VpCk1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLQW9JQkFRRE96OHpIYURVdG93ZU1jaW5XR2dqVEZBelIKSkIyWE1aYXZNTE5tV0N1TFN2VkI0NkFtTk05NFB2ZjFud0phblVJVHRPNE50dXJTcjU3RHJheE5vSDYvbHhxNwoya3RiRDVWaDdhQU5RMElqTEo2UTkvQUZuaHdDaDh4UXE3Q0FnOGpIWXpmSUlTMllxc2Z1ZlhSTkNHZUlzNE9LClpxS0pSVlpUQUw0dFIzT29TbDJTN1hNQkJHclRLWWVJUDBHWTVlaUlQWDRDOTN1K000SHVFOU9TTkxCOUZrMHgKU3RLOWFsRTUwcVVxdXdKOHFaakxEYWFieC9OdU1NM21WYk9TUVdKaFlQckFXcU5XaVFIeTYwSm5VaFpScWtEcwpGVVFaQXV1MlVtVkMvRys2eitmbnVzbzNCWVBBeUkySHpRZUFQdHVaYVhvSkpRaTlRcFllR3oxbVVFeTdBZ01CCkFBR2pnZFl3Z2RNd0RnWURWUjBQQVFIL0JBUURBZ1dnTUIwR0ExVWRKUVFXTUJRR0NDc0dBUVVGQndNQkJnZ3IKQmdFRkJRY0RBakFNQmdOVkhSTUJBZjhFQWpBQU1COEdBMVVkSXdRWU1CYUFGSHEzWFprTEtkV0hOUjBEUGZHNwpweittcVlyaU1ITUdBMVVkRVFSc01HcUNNVzE1TFhKbGJHVmhjMlV0WVhKMGFXWmhZM1J2Y25rdWFtWnliMmN0CmNHeGhkR1p2Y20wdE1UQXVNVGd1TWk1MFozcUNOVzE1TFhKbGJHVmhjMlV0WVhKMGFXWmhZM1J2Y25rdWFtWnkKYjJjdGNHeGhkR1p2Y20wdE1UQXVNVGd1TWk1MFozb3VjM1pqTUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFDMgpPOGREYjVnQ1I3VWlPTnlNcTdEbC8yTDRFQUw1OWgwNmVidGh1NUdBc3BzU09SaHNFbUM1OVhFK05uY29wdC9KCjVJWGl5ZkxKNXpXOGNGMXoxQ1lhb0UzU3dETU5rYk85VVNCT1BiMWlIZVdwcE92a3VUTm1aSUZDZHlkNFpGSSsKejhmVHBkUVljN3YyaE5jc2VCdnVZbStWLzV3TnhkSkgzUXBrWUgzbnBXVFY3OTEvL21lYWVSbFEzaDlPMjBEOApyTFRicXBwdjZFL1VjUkI4dkdxbDZsdHgwZ3A0dXp1cjhiSk9xWGJWdk9obzBBZm4yL3g4NlJGMlF5RjI0bWEvClVkYVl6RmZWRmg2TnhQVEViK2VPTDJOc0dJaG9LeVRJQ2p3V01XcGp4THZRdzhVYittM3BZaU9uL29VdjFKK1EKaVRLT1N6dklvM2xMckY2VWdjcS8KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
  tls.key: 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
---
# Source: jfrog-platform/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
  namespace: jfrog-platform-10.18.2.tgz
type: Opaque
data:
  postgresql-password: "cG9zdGdyZXM="
---
# Source: jfrog-platform/charts/rabbitmq/templates/config-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-rabbitmq-config
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  rabbitmq.conf: |-
    IyMgVXNlcm5hbWUgYW5kIHBhc3N3b3JkCiMjCmRlZmF1bHRfdXNlciA9IGFkbWluCiMjIENsdXN0ZXJpbmcKIyMKY2x1c3Rlcl9mb3JtYXRpb24ucGVlcl9kaXNjb3ZlcnlfYmFja2VuZCAgPSByYWJiaXRfcGVlcl9kaXNjb3ZlcnlfazhzCmNsdXN0ZXJfZm9ybWF0aW9uLms4cy5ob3N0ID0ga3ViZXJuZXRlcy5kZWZhdWx0CmNsdXN0ZXJfZm9ybWF0aW9uLm5vZGVfY2xlYW51cC5pbnRlcnZhbCA9IDEwCmNsdXN0ZXJfZm9ybWF0aW9uLm5vZGVfY2xlYW51cC5vbmx5X2xvZ193YXJuaW5nID0gdHJ1ZQpjbHVzdGVyX3BhcnRpdGlvbl9oYW5kbGluZyA9IGF1dG9oZWFsCmxvYWRfZGVmaW5pdGlvbnMgPSAvYXBwL2xvYWRfZGVmaW5pdGlvbi5qc29uCiMgcXVldWUgbWFzdGVyIGxvY2F0b3IKcXVldWVfbWFzdGVyX2xvY2F0b3IgPSBtaW4tbWFzdGVycwojIGVuYWJsZSBsb29wYmFjayB1c2VyCmxvb3BiYWNrX3VzZXJzLmFkbWluID0gZmFsc2UKI2RlZmF1bHRfdmhvc3QgPSBqZnJvZy1wbGF0Zm9ybS0xMC4xOC4yLnRnei12aG9zdAojZGlza19mcmVlX2xpbWl0LmFic29sdXRlID0gNTBNQg==
---
# Source: jfrog-platform/charts/rabbitmq/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-rabbitmq
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  rabbitmq-password: "cGFzc3dvcmQ="
  
  rabbitmq-erlang-cookie: "c2VjcmV0Y29va2ll"
---
# Source: jfrog-platform/charts/rabbitmq/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-load-definition
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  load_definition.json: |
    {
      "vhosts": [
        {
          "name": "xray"
        }
      ],
      "users": [
        {
          "name": "admin",
          "password": "password",
          "tags": "administrator"
        }
      ],
      "permissions": [
      {
        "user": "admin",
        "vhost": "xray",
        "configure": ".*",
        "write": ".*",
        "read": ".*"
      }
      ],
      "policies": [
        {
          "name": "ha-all",
          "apply-to": "all",
          "pattern": ".*",
          "vhost": "xray",
          "definition": {
            "ha-mode": "all",
            "ha-sync-mode": "automatic"
          }
        }
      ]
    }
---
# Source: jfrog-platform/charts/xray/templates/xray-unified-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: xray-unified-secret
  labels:
    app: "xray"
    chart: "xray-103.96.1"
    component: "xray"
    heritage: "Helm"
    release: "my-release"
type: Opaque

stringData:
  system.yaml: |

    
    configVersion: 1
    router:
      serviceRegistry:
        insecure: false
    shared:
      logging:
        consoleLog:
          enabled: false
      jfrogUrl: "http://my-release-artifactory:8082"
      database:
        type: postgresql
        driver: org.postgresql.Driver
      rabbitMq:
        erlangCookie:
          value: "secretcookie"
        url: "amqp://my-release-rabbitmq:5672/"
        username: "admin"
        password: "password"
    contextualAnalysis:
      registry: releases-docker.jfrog.io
      image: jfrog/xray-jas-contextual-analysis
    exposures:
      container:
        registry: releases-docker.jfrog.io
        image: jfrog/xray-jas-exposures

data:
  master-key: "YmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYg=="
  join-key: "RUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUU="
  execution-service-aes-key: "c2ZtTjdtZmNzTUN2Z1IyY2M3dkN5Y0pjWFRNUlhNS0g="
  db-url: "cG9zdGdyZXM6Ly9teS1yZWxlYXNlLXBvc3RncmVzcWw6NTQzMi94cmF5P3NzbG1vZGU9ZGlzYWJsZQ=="
  db-user: "eHJheQ=="
  db-password: "eHJheQ=="
---
# Source: jfrog-platform/charts/artifactory/templates/artifactory-installer-info.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-release-artifactory-installer-info
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    heritage: Helm
    release: my-release
data:
  installer-info.json: |
    {"productId":"Helm_JFrogPlatform/10.18.0-7.84.14","features":[{"featureId":"Platform/kubernetes-v1.30.0"},{"featureId":"Database/postgresql"},{"featureId":"Nginx_Enabled/true"},{"featureId":"ArtifactoryPersistence_Type/file-system"},{"featureId":"SplitServicesToContainers_Enabled/true"},{"featureId":"Filebeat_Enabled/false"},{"featureId":"ReplicaCount/1"}]}
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-artifactory-conf.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-artifactory-nginx-artifactory-conf
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    heritage: Helm
    release: my-release
data:
  artifactory.conf: |
    
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;
    ssl_certificate  /var/opt/jfrog/nginx/ssl/tls.crt;
    ssl_certificate_key  /var/opt/jfrog/nginx/ssl/tls.key;
    ssl_session_cache shared:SSL:1m;
    ssl_prefer_server_ciphers   on;
    ## server configuration
    server {listen 8443 ssl;listen 8080;
      server_name ~(?<repo>.+)\.my-release-artifactory my-release-artifactory;
    
      if ($http_x_forwarded_proto = '') {
        set $http_x_forwarded_proto  $scheme;
      }
      set $host_port 443;
      if ( $scheme = "http" ) {
        set $host_port 80;
      }
      ## Application specific logs
      ## access_log /var/log/nginx/artifactory-access.log timing;
      ## error_log /var/log/nginx/artifactory-error.log;
      rewrite ^/artifactory/?$ / redirect;
      if ( $repo != "" ) {
        rewrite ^/(v1|v2)/(.*) /artifactory/api/docker/$repo/$1/$2 break;
      }
      chunked_transfer_encoding on;
      client_max_body_size 0;
    
      location / {
        proxy_read_timeout  900;
        proxy_pass_header   Server;
        proxy_cookie_path   ~*^/.* /;
        proxy_pass          http://my-release-artifactory:8082/;
        proxy_set_header    X-JFrog-Override-Base-Url $http_x_forwarded_proto://$host:$host_port;
        proxy_set_header    X-Forwarded-Port  $server_port;
        proxy_set_header    X-Forwarded-Proto $http_x_forwarded_proto;
        proxy_set_header    Host              $http_host;
        proxy_set_header    X-Forwarded-For   $proxy_add_x_forwarded_for;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        location /artifactory/ {
          if ( $request_uri ~ ^/artifactory/(.*)$ ) {
            proxy_pass       http://my-release-artifactory:8081/artifactory/$1;
          }
          proxy_pass         http://my-release-artifactory:8081/artifactory/;
        }
        location /pipelines/ {
          proxy_http_version 1.1;
          proxy_set_header Upgrade $http_upgrade;
          proxy_set_header Connection "upgrade";
          proxy_set_header Host $http_host;
          proxy_pass  http://my-release-artifactory:8082;
        }
      }
    }
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-conf.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-artifactory-nginx-conf
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    heritage: Helm
    release: my-release
data:
  nginx.conf: |
    # Main Nginx configuration file
    worker_processes  4;error_log  /var/opt/jfrog/nginx/logs/error.log warn;
    pid        /var/run/nginx.pid;
    
    events {
      worker_connections  1024;
    }
    
    http {
      include       /etc/nginx/mime.types;
      default_type  application/octet-stream;
    
      variables_hash_max_size 1024;
      variables_hash_bucket_size 64;
      server_names_hash_max_size 4096;
      server_names_hash_bucket_size 128;
      types_hash_max_size 2048;
      types_hash_bucket_size 64;
      proxy_read_timeout 2400s;
      client_header_timeout 2400s;
      client_body_timeout 2400s;
      proxy_connect_timeout 75s;
      proxy_send_timeout 2400s;
      proxy_buffer_size 128k;
      proxy_buffers 40 128k;
      proxy_busy_buffers_size 128k;
      proxy_temp_file_write_size 250m;
      proxy_http_version 1.1;
      client_body_buffer_size 128k;
    
      log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
      '$status $body_bytes_sent "$http_referer" '
      '"$http_user_agent" "$http_x_forwarded_for"';
    
      log_format timing 'ip = $remote_addr '
      'user = \"$remote_user\" '
      'local_time = \"$time_local\" '
      'host = $host '
      'request = \"$request\" '
      'status = $status '
      'bytes = $body_bytes_sent '
      'upstream = \"$upstream_addr\" '
      'upstream_time = $upstream_response_time '
      'request_time = $request_time '
      'referer = \"$http_referer\" '
      'UA = \"$http_user_agent\"';access_log /var/opt/jfrog/nginx/logs/access.log timing;
    
      sendfile        on;
      #tcp_nopush     on;
    
      keepalive_timeout  65;
    
      #gzip  on;
    
      include /etc/nginx/conf.d/*.conf;
    
    }
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-scripts-conf.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-artifactory-nginx-scripts
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    heritage: Helm
    release: my-release
data:
  configreloader.sh: |
    #!/bin/sh
    ####
    # A helper script to use inotifyd to reload nginx config
    # upon configmap/ssl secrets changes.
    #
    # Synopsis: setup the nginx command via the values file
    # as follows:
    #
    ####
    # nginx:
    #   customVolumes: |
    #     - name: scripts
    #       configMap:
    #         name: {{ template "artifactory.fullname" . }}-nginx-scripts
    #         defaultMode: 0550
    #   customVolumeMounts: |
    #     - name: scripts
    #       mountPath: /var/opt/jfrog/nginx/scripts/
    #   customCommand:
    #     - /bin/sh
    #     - -c
    #     - |
    #       # watch for configmap changes
    #       /sbin/inotifyd /var/opt/jfrog/nginx/scripts/configreloader.sh {{ .Values.nginx.persistence.mountPath -}}/conf.d:n &
    #       {{ if .Values.nginx.https.enabled -}}
    #       # watch for tls secret changes
    #       /sbin/inotifyd /var/opt/jfrog/nginx/scripts/configreloader.sh {{ .Values.nginx.persistence.mountPath -}}/ssl:n &
    #       {{ end -}}
    #       nginx -g 'daemon off;'
    if [[ "$3" =~ data_tmp ]] && [ "$1" = "n" ]
    then
      # a symlink has changed in one of the watched folders
      # lets verify the config
      nginx -t -q
      if [ $? -eq 0 ]
      then
        # config is valid, lets reload nginx config
        nginx -q -s reload
      fi
    fi
---
# Source: jfrog-platform/charts/postgresql/templates/extended-config-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-postgresql-extended-configuration
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
  namespace: jfrog-platform-10.18.2.tgz
data:

  override.conf: |
    max_connections = 1000
    max_wal_size = '1000MB'
---
# Source: jfrog-platform/templates/platform-ga-upgrade.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-jfrog-platform-configmap
  labels:
    app: jfrog-platform
    chart: jfrog-platform-10.18.2
    heritage: Helm
    release: my-release
data:
---
# Source: jfrog-platform/templates/postgres-setup-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-setup-script
  labels:
    app: postgres-init
data:
  setupPostgres.sh: |
    #!/bin/bash
    # This can be used to create user, database, schema and grant the required permissions.
    # This script can handle multiple execution and not with "already exists" error. An entity will get created only if it does not exist.
    # NOTE : 1. This expects current linux user to be admin user in postgreSQL (this is the case with 'postgres' user)
    #        2. Execute this by logging as postgres or any other user with similar privilege
    #        3. This files needs be executed from a location which postgres (or the admin user which will be used) has access to. (/opt can be used)
    #
    #        su postgres -c "POSTGRES_PATH=/path/to/postgres/bin PGPASSWORD=postgres bash ./createPostgresUsers.sh"
    POSTGRES_LABEL="Postgres"
    
    # Logging function
    log() {
        echo -e "$1"
    }
    
    # Error function
    errorExit() {
        echo; echo -e "\033[31mERROR:\033[0m $1"; echo
        exit 1
    }
    
    # Create user if it does not exist
    createUser(){
        local user=$1
        local pass=$2
        [ ! -z ${user} ] || errorExit "user is empty"
        [ ! -z ${pass} ] || errorExit "password is empty"
        ${PSQL} $POSTGRES_OPTIONS -tAc "SELECT 1 FROM pg_roles WHERE rolname='${user}'" | grep -q 1 1>/dev/null
        local rc=$?
        # Create user if doesn't exists
        if [[ ${rc} -ne 0 ]]; then
            echo "Creating user ${user}..."
            ${PSQL} $POSTGRES_OPTIONS -c "CREATE USER ${user} WITH PASSWORD '${pass}';" 1>/dev/null || errorExit "Failed creating user ${user} on PostgreSQL"
            echo "Done"
        fi
    }
    
    # Create database if it does not exist
    createDB(){
        local db=$1
        local user=$2
        [ ! -z ${db}   ] || errorExit "db is empty"
        [ ! -z ${user} ] || errorExit "user is empty"
        if ! ${PSQL} $POSTGRES_OPTIONS -lqt | cut -d \| -f 1 | grep -qw ${db} 1>/dev/null; then
            ${PSQL} $POSTGRES_OPTIONS -c "CREATE DATABASE ${db} WITH OWNER=${user} ENCODING='UTF8';" 1>/dev/null || errorExit "Failed creating db ${db} on PostgreSQL"
        fi
    }
    
    # Check if postgres db is ready
    postgresIsNotReady() {
        attempt_number=${attempt_number:-0}
        ${PSQL} $POSTGRES_OPTIONS --version > /dev/null 2>&1
        outcome1=$?
        # Execute a simple db function to verify if postgres is up and running
        ${PSQL} $POSTGRES_OPTIONS -l > /dev/null 2>&1
        outcome2=$?
        if [[ $outcome1 -eq 0 ]] && [[ $outcome2 -eq 0  ]]; then
            return 0
        else
            if [ $attempt_number -gt 10 ]; then
                errorExit "Unable to proceed. $POSTGRES_LABEL is not reachable. This can occur if the service is not running \
    or the port is not accepting requests at $DB_PORT (host : $DB_HOST). Gave up after $attempt_number attempts"
            fi
            let "attempt_number=attempt_number+1"
            return 1
        fi
    }
    
    # Wait for availability of postgres
    init(){
        if [[ -z $POSTGRES_PATH ]]; then
            hash ${PSQL} 2>/dev/null || { echo >&2 "\"${PSQL}\" is not installed or not available in path"; exit 1; }
        fi
        log "Waiting for $POSTGRES_LABEL to get ready using the commands: \"${PSQL} $POSTGRES_OPTIONS --version\" & \"${PSQL} $POSTGRES_OPTIONS -l\""
        attempt_number=0
        while ! postgresIsNotReady
        do
            sleep 5
            echo -n '.'
        done
        log "$POSTGRES_LABEL is ready. Executing commands"
    }
    
    # Create users and DB
    setupDB(){
        local user=$1
        local pass=$2
        local db=$3
        # Create user
        createUser "${user}" "${pass}"    
        createDB "${db}" "${user}"
        ${PSQL} $POSTGRES_OPTIONS -c "GRANT ALL PRIVILEGES ON DATABASE ${db} TO ${user}" 1>/dev/null;
    }
    
    # Load default and custom postgres details from below files
    [ -f setenvDefaults.sh ] && source setenvDefaults.sh || true
    [ -f setenv.sh         ] && source setenv.sh         || true
    
    # DB_NAME=$1
    # DB_USERNAME=$2
    # DB_PASSWORD=$3
    # CHART_NAME=$4
    
    : ${DB_NAME:=$1}
    : ${DB_USERNAME:=$2}
    : ${DB_PASSWORD:=$3}
    : ${CHART_NAME:=4}
    
    ### Following are the postgres details being setup for each service.
    ##  Common details
    : ${DB_PORT:=5432}
    : ${DB_SSL_MODE:="disable"}
    : ${DB_TABLESPACE:="pg_default"}
    : ${DB_HOST:="localhost"}
    
    ## Set Postgres options
    [[ -z "${POSTGRES_PATH}" ]] && PSQL=psql || PSQL=${POSTGRES_PATH}/psql
    POSTGRES_OPTIONS="sslmode=${DB_SSL_MODE} --host=${DB_HOST} -p ${DB_PORT} -U ${PGUSERNAME} -w"
    
    init
    
    log "Setting up DB $DB_NAME and user $DB_USERNAME on Postgres for $CHART_NAME chart."
    setupDB "${DB_USERNAME}" "${DB_PASSWORD}" "${DB_NAME}" || true
    
    log "$POSTGRES_LABEL setup is now complete."
    
    exit 0
---
# Source: jfrog-platform/charts/rabbitmq/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-rabbitmq-endpoint-reader
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create"]
---
# Source: jfrog-platform/charts/rabbitmq/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-rabbitmq-endpoint-reader
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: my-release-rabbitmq
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-release-rabbitmq-endpoint-reader
---
# Source: jfrog-platform/charts/artifactory/templates/artifactory-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-artifactory
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    component: artifactory
    heritage: Helm
    release: my-release
spec:
  type: ClusterIP
  ports:
  - port: 8082
    targetPort: 8082
    protocol: TCP
    name: http-router
  - port: 8025
    targetPort: 8025
    protocol: TCP
    name: http-rtfs
  - port: 8081
    targetPort: 8081
    protocol: TCP
    name: http-artifactory
  selector:
    app: artifactory
    component: "artifactory"
    release: my-release
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-artifactory-nginx
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    component: nginx
    heritage: Helm
    release: my-release
spec:
  type: LoadBalancer
  
  externalTrafficPolicy: Cluster
  ports:
  # DEPRECATION NOTE: The following is to maintain support for values pre 1.3.0 and
  # will be cleaned up in a later version
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  - port: 443
    targetPort: 8443
    protocol: TCP
    name: https
  selector:
    app: artifactory
    component: nginx
    release: my-release
---
# Source: jfrog-platform/charts/postgresql/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql-headless
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  namespace: jfrog-platform-10.18.2.tgz
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-release
---
# Source: jfrog-platform/charts/postgresql/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
  annotations:
  namespace: jfrog-platform-10.18.2.tgz
spec:
  type: ClusterIP
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-release
    role: primary
---
# Source: jfrog-platform/charts/rabbitmq/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-rabbitmq-headless
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  clusterIP: None
  ports:
    - name: epmd
      port: 4369
      targetPort: epmd
    - name: amqp
      port: 5672
      targetPort: amqp
    - name: dist
      port: 25672
      targetPort: dist
    - name: http-stats
      port: 15672
      targetPort: stats
  selector: 
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: my-release
  publishNotReadyAddresses: true
---
# Source: jfrog-platform/charts/rabbitmq/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-rabbitmq
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: amqp
      port: 5672
      targetPort: amqp
      nodePort: null
    - name: epmd
      port: 4369
      targetPort: epmd
      nodePort: null
    - name: dist
      port: 25672
      targetPort: dist
      nodePort: null
    - name: http-stats
      port: 15672
      targetPort: stats
      nodePort: null
  selector: 
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: my-release
---
# Source: jfrog-platform/charts/xray/templates/xray-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-xray
  labels:
    app: xray
    chart: xray-103.96.1
    component: xray
    heritage: Helm
    release: my-release
spec:
  type: ClusterIP
  ports:
  - port: 80
    protocol: TCP
    name: http
    targetPort: 8000
  - port: 8082
    protocol: TCP
    name: http-router
    targetPort: 8082
  selector:
    app: xray
    component: xray
    release: my-release
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-artifactory-nginx
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    heritage: Helm
    release: my-release
    component: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: artifactory
      release: my-release
      component: nginx
  template:
    metadata:
      annotations:
        checksum/nginx-conf: 499fadff69ee8d989971f277364430815a86cc19b043baf8cec4121f43d08294
        checksum/nginx-artifactory-conf: b8207a3a12c87f40de5dfbc66543396499c963c7c1feb286335b153eef095441
      labels:
        app: artifactory
        chart: artifactory-107.84.14
        component: nginx
        heritage: Helm
        release: my-release
    spec:
      securityContext:
        fsGroup: 107
        runAsGroup: 107
        runAsUser: 104
      serviceAccountName: default
      terminationGracePeriodSeconds: 30
      initContainers:
      - name: "setup"
        image: releases-docker.jfrog.io/ubi9/ubi-minimal:9.4.949
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
        - '/bin/sh'
        - '-c'
        - >
          rm -rfv /var/opt/jfrog/nginx/lost+found;
          mkdir -p /var/opt/jfrog/nginx/logs;
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 50Mi
        volumeMounts:
        - mountPath: "/var/opt/jfrog/nginx"
          name: nginx-volume
      containers:
      - name: nginx
        image: releases-docker.jfrog.io/jfrog/nginx-artifactory-pro:7.84.14
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        ports:

        # DEPRECATION NOTE: The following is to maintain support for values pre 1.3.1 and
        # will be cleaned up in a later version
        - containerPort: 8080
          name: http
        - containerPort: 8443
          name: https
        volumeMounts:
        - name: nginx-conf
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf
        - name: nginx-artifactory-conf
          mountPath: "/var/opt/jfrog/nginx/conf.d/"
        - name: nginx-volume
          mountPath: "/var/opt/jfrog/nginx"  
        - name: ssl-certificates
          mountPath: "/var/opt/jfrog/nginx/ssl"  
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8080/router/api/v1/system/readiness
          initialDelaySeconds: 3
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        readinessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8080/router/api/v1/system/readiness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8080/
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
      volumes:
      - name: nginx-conf
        configMap:
          name: my-release-artifactory-nginx-conf
      - name: nginx-artifactory-conf
        configMap:
          name: my-release-artifactory-nginx-artifactory-conf
      - name: nginx-volume
        emptyDir: {}
      - name: ssl-certificates
        secret:
          secretName: my-release-artifactory-nginx-certificate
---
# Source: jfrog-platform/charts/artifactory/templates/artifactory-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-artifactory
  labels:
    app: artifactory
    chart: artifactory-107.84.14
    component: artifactory
    heritage: Helm
    release: my-release
spec:
  serviceName: artifactory
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: artifactory
      role: artifactory
      release: my-release
  template:
    metadata:
      labels:
        app: artifactory
        chart: artifactory-107.84.14
        heritage: Helm
        role: artifactory
        component: artifactory
        release: my-release
      annotations:
        checksum/artifactory-unified-secret: db571f5021f1d76e790fdb3b692113c7d0da7374ee0407d5a5fee132645b2745
    spec:
      serviceAccountName: default
      terminationGracePeriodSeconds: 40
      securityContext:
        fsGroup: 1030
        runAsGroup: 1030
        runAsNonRoot: true
        runAsUser: 1030
      initContainers:
      
      - name: postgres-setup-init
        image: "releases-docker.jfrog.io/postgres:15.6-alpine"
        imagePullPolicy: IfNotPresent
        resources: 
                limits:
                  cpu: 1
                  memory: 1Gi
                requests:
                  cpu: 5m
                  memory: 10Mi
        command:
          - '/bin/bash'
          - '-c'
          - >
            echo "Running init db scripts";
            bash /scripts/setupPostgres.sh
        env:
          - name: PGUSERNAME
            value: postgres
          - name: DB_HOST
            value: my-release-postgresql
          - name: DB_PORT
            value: "5432"
          - name: DB_SSL_MODE
            value: "disable"
          - name: DB_NAME
            value: artifactory
          - name: DB_USERNAME
            valueFrom:
              secretKeyRef:
                name: my-release-artifactory-unified-secret
                key: db-user
          - name: DB_PASSWORD
            valueFrom:
              secretKeyRef:
                name: my-release-artifactory-unified-secret
                key: db-password
          - name: PGPASSWORD
            value: postgres
          - name: CHART_NAME
            value: artifactory
        volumeMounts:
          - name: postgres-setup-init-vol
            mountPath: "/scripts"
      
      - name: "delete-db-properties"
        image: releases-docker.jfrog.io/ubi9/ubi-minimal:9.4.949
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 50Mi
        command:
          - 'bash'
          - '-c'
          - 'rm -fv /var/opt/jfrog/artifactory/etc/db.properties'
        volumeMounts:
          - name: artifactory-volume
            mountPath: "/var/opt/jfrog/artifactory"
      - name: 'copy-system-configurations'
        image: releases-docker.jfrog.io/ubi9/ubi-minimal:9.4.949
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 50Mi
        command:
        - '/bin/bash'
        - '-c'
        - >
          if [[ -e "/var/opt/jfrog/artifactory/etc/filebeat.yaml" ]]; then chmod 644 /var/opt/jfrog/artifactory/etc/filebeat.yaml; fi;
          echo "Copy system.yaml to /var/opt/jfrog/artifactory/etc";
          mkdir -p /var/opt/jfrog/artifactory/etc;
          mkdir -p /var/opt/jfrog/artifactory/etc/access/keys/trusted;
          cp -fv /tmp/etc/system.yaml /var/opt/jfrog/artifactory/etc/system.yaml;
          echo "Copy binarystore.xml file";
          mkdir -p /var/opt/jfrog/artifactory/etc/artifactory;
          cp -fv /tmp/etc/artifactory/binarystore.xml /var/opt/jfrog/artifactory/etc/artifactory/binarystore.xml;
          echo "Copy access.config.patch.yml to /var/opt/jfrog/artifactory/etc/access";
          mkdir -p /var/opt/jfrog/artifactory/etc/access;
          cp -fv /tmp/etc/access.config.patch.yml /var/opt/jfrog/artifactory/etc/access/access.config.patch.yml;
          echo "Copy joinKey to /var/opt/jfrog/artifactory/bootstrap/access/etc/security";
          mkdir -p /var/opt/jfrog/artifactory/bootstrap/access/etc/security;
          echo -n ${ARTIFACTORY_JOIN_KEY} > /var/opt/jfrog/artifactory/bootstrap/access/etc/security/join.key;
          echo "Copy masterKey to /var/opt/jfrog/artifactory/etc/security";
          mkdir -p /var/opt/jfrog/artifactory/etc/security;
          echo -n ${ARTIFACTORY_MASTER_KEY} > /var/opt/jfrog/artifactory/etc/security/master.key;
        env:
        - name: ARTIFACTORY_JOIN_KEY
          valueFrom:
            secretKeyRef:
              name: "my-release-artifactory-unified-secret"
              key: join-key
        - name: ARTIFACTORY_MASTER_KEY
          valueFrom:
            secretKeyRef:
              name: "my-release-artifactory-unified-secret"
              key: master-key
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        - name: artifactory-unified-secret-volume
          mountPath: "/tmp/etc/system.yaml"
          subPath: "system.yaml"

        ######################## Binarystore  ##########################
        - name: artifactory-unified-secret-volume
          mountPath: "/tmp/etc/artifactory/binarystore.xml"
          subPath: binarystore.xml

        ######################## Access config  ##########################
        - name: artifactory-unified-secret-volume
          mountPath: "/tmp/etc/access.config.patch.yml"
          subPath: "access.config.patch.yml"

        ######################## Access certs external secret  ##########################
      containers:
      - name: router
        image: releases-docker.jfrog.io/jfrog/router:7.108.0
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/router/app/bin/entrypoint-router.sh
        lifecycle:
          preStop:
            exec:
              command:
              - sh
              - -c
              - while [[ $(curl --fail --silent --connect-timeout 2 http://localhost:8081/artifactory/api/v1/system/liveness)
                =~ OK ]]; do echo Artifactory is still alive; sleep 2; done
        env:
        - name: JF_ROUTER_TOPOLOGY_LOCAL_REQUIREDSERVICETYPES
          value: jfrt,jfac,jfob,jfmd,jfevt,jffe,jfcon,jfmc
        ports:
          - name: http
            containerPort: 8082
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/router"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/readiness
          initialDelaySeconds: 10
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        readinessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/readiness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
      - name: frontend
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.14
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/third-party/node/bin/node /opt/jfrog/artifactory/app/frontend/bin/server/dist/bundle.js /opt/jfrog/artifactory/app/frontend
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name   
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8070/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8070/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: metadata
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.14
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/metadata/bin/jf-metadata start
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "my-release-artifactory-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "my-release-artifactory-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "my-release-artifactory-unified-secret"
              key: db-url
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8086/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8086/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: event
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.14
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/event/bin/jf-event start
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8061/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8061/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: jfconnect
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.14
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/jfconnect/bin/jf-connect start
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8030/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8030/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: observability
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.14
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/observability/bin/jf-observability start
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8036/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8036/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: artifactory
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.14
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
        - '/bin/bash'
        - '-c'
        - >
          set -e;
          if [ -d /artifactory_extra_conf ] && [ -d /artifactory_bootstrap ]; then
            echo "Copying bootstrap config from /artifactory_extra_conf to /artifactory_bootstrap";
            cp -Lrfv /artifactory_extra_conf/ /artifactory_bootstrap/;
          fi;
          exec /entrypoint-artifactory.sh
        env:
        - name : JF_ROUTER_ENABLED
          value: "true"
        - name : JF_ROUTER_SERVICE_ENABLED
          value: "false"
        - name : JF_EVENT_ENABLED
          value: "false"
        - name : JF_METADATA_ENABLED
          value: "false"
        - name : JF_FRONTEND_ENABLED
          value: "false"
        - name: JF_FEDERATION_ENABLED
          value: "false"
        - name : JF_OBSERVABILITY_ENABLED
          value: "false"
        - name : JF_JFCONNECT_SERVICE_ENABLED
          value: "false"
        - name: SKIP_WAIT_FOR_EXTERNAL_DB
          value: "true"
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "my-release-artifactory-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "my-release-artifactory-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "my-release-artifactory-unified-secret"
              key: db-url
        ports:
        - containerPort: 8082
          name: http
        - containerPort: 8081
          name: http-internal
        - containerPort: 8025
          name: http-rtfs
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"

      ######################## Artifactory config map ##########################

      ######################## Artifactory persistence nfs ##########################

      ######################## Artifactory persistence binarystoreXml ##########################
        - name: artifactory-unified-secret-volume
          mountPath: "/tmp/etc/artifactory/binarystore.xml"
          subPath: binarystore.xml

      ######################## Artifactory persistence googleStorage ##########################

      ######################## Artifactory license ##########################

        - name: installer-info
          mountPath: "/artifactory_bootstrap/info/installer-info.json"
          subPath: installer-info.json
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8091/artifactory/api/v1/system/readiness
          initialDelaySeconds: 10
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8091/artifactory/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
      
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app: artifactory
                    release: my-release
      volumes:
      ########## External secrets ###########
      # ca-certs secret

      # aws licence

      # binarystore-xml secret

      # access-certs secrets

      # system yaml

      # artifactory license secrets
      
      # user Plugin Secrets

      # access bootstarp

      # gcpcreds secret

      ############ Config map, Volumes and Custom Volumes ##############
      
      - name: postgres-setup-init-vol
        configMap:
          name: my-release-setup-script
      
      - name: installer-info
        configMap:
          name: my-release-artifactory-installer-info

    #########  unifiedSecretInstallation ###########
      - name: artifactory-unified-secret-volume
        secret:
          secretName: "my-release-artifactory-unified-secret"
    ########## volumeClaimTemplates #######
  volumeClaimTemplates:
  - metadata:
      name: artifactory-volume
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
---
# Source: jfrog-platform/charts/postgresql/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
  namespace: jfrog-platform-10.18.2.tgz
spec:
  serviceName: my-release-postgresql-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: my-release
      role: primary
  template:
    metadata:
      name: my-release-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-10.3.18
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        role: primary
        app.kubernetes.io/component: primary
    spec:      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/component: primary
                namespaces:
                  - "jfrog-platform-10.18.2.tgz"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      containers:
        - name: my-release-postgresql
          image: releases-docker.jfrog.io/bitnami/postgresql:15.6.0-debian-11-r16
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_USER
              value: "postgres"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: postgresql-password
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: postgresql-extended-config
              mountPath: /bitnami/postgresql/conf/conf.d/
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
      volumes:
        - name: postgresql-extended-config
          configMap:
            name: my-release-postgresql-extended-configuration
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "500Gi"
---
# Source: jfrog-platform/charts/rabbitmq/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-rabbitmq
  namespace: "jfrog-platform-10.18.2.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: my-release-rabbitmq-headless
  podManagementPolicy: OrderedReady
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: rabbitmq
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      labels:
        app.kubernetes.io/name: rabbitmq
        helm.sh/chart: rabbitmq-11.9.3
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
      annotations:
        checksum/config: 44ea07bf1058af6242947ec26b7989c2f18336d1c05a445f2a946ed0bf4bdd74
        checksum/secret: 27fbd5eaae060e707b43b82c5d4ade7c9bb5af31e2be0dc241aa33df78bf108a
    spec:
      
      serviceAccountName: my-release-rabbitmq
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: rabbitmq
                    app.kubernetes.io/instance: my-release
                namespaces:
                  - "jfrog-platform-10.18.2.tgz"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      terminationGracePeriodSeconds: 120
      initContainers:
      containers:
        - name: rabbitmq
          image: releases-docker.jfrog.io/bitnami/rabbitmq:3.12.10-debian-11-r1
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/bash
                  - -ec
                  - |
                    if [[ -f /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh ]]; then
                        /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh -t "120" -d "false"
                    else
                        rabbitmqctl stop_app
                    fi
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: K8S_SERVICE_NAME
              value: my-release-rabbitmq-headless
            - name: K8S_ADDRESS_TYPE
              value: hostname
            - name: RABBITMQ_FEATURE_FLAGS
              value: drop_unroutable_metric,empty_basic_get_metric,implicit_default_bindings,maintenance_mode_status,quorum_queue,stream_queue,user_limits,virtual_host_metadata
            - name: RABBITMQ_FORCE_BOOT
              value: "no"
            - name: RABBITMQ_NODE_NAME
              value: "rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local"
            - name: K8S_HOSTNAME_SUFFIX
              value: ".$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local"
            - name: RABBITMQ_MNESIA_DIR
              value: "/bitnami/rabbitmq/mnesia/$(RABBITMQ_NODE_NAME)"
            - name: RABBITMQ_LDAP_ENABLE
              value: "no"
            - name: RABBITMQ_LOGS
              value: "-"
            - name: RABBITMQ_ULIMIT_NOFILES
              value: "65536"
            - name: RABBITMQ_USE_LONGNAME
              value: "true"
            - name: RABBITMQ_ERL_COOKIE
              valueFrom:
                secretKeyRef:
                  name: my-release-rabbitmq
                  key: rabbitmq-erlang-cookie
            - name: RABBITMQ_LOAD_DEFINITIONS
              value: "yes"
            - name: RABBITMQ_DEFINITIONS_FILE
              value: "/app/load_definition.json"
            - name: RABBITMQ_SECURE_PASSWORD
              value: "yes"
            - name: RABBITMQ_USERNAME
              value: "admin"
            - name: RABBITMQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-rabbitmq
                  key: rabbitmq-password
            - name: RABBITMQ_PLUGINS
              value: "rabbitmq_management, rabbitmq_peer_discovery_k8s, rabbitmq_auth_backend_ldap"
            - name: RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS
              value: +S 2:2 +sbwt none +sbwtdcpu none +sbwtdio none
          envFrom:
          ports:
            - name: amqp
              containerPort: 5672
            - name: dist
              containerPort: 25672
            - name: stats
              containerPort: 15672
            - name: epmd
              containerPort: 4369
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 120
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 20
            exec:
              command:
                - /bin/bash
                - -ec
                - rabbitmq-diagnostics -q ping
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 20
            exec:
              command:
                - /bin/bash
                - -ec
                - rabbitmq-diagnostics -q check_running && rabbitmq-diagnostics -q check_local_alarms
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: configuration
              mountPath: /bitnami/rabbitmq/conf
            - name: data
              mountPath: /bitnami/rabbitmq/mnesia
            - name: load-definition-volume
              mountPath: /app
              readOnly: true
      volumes:
        - name: configuration
          projected:
            sources:
              - secret:
                  name: my-release-rabbitmq-config
        - name: load-definition-volume
          secret:
            secretName: "my-release-load-definition"
  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app.kubernetes.io/name: rabbitmq
          app.kubernetes.io/instance: my-release
      spec:
        accessModes:
            - "ReadWriteOnce"
        resources:
          requests:
            storage: "50Gi"
---
# Source: jfrog-platform/charts/xray/templates/xray-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-xray
  labels:
    app: xray
    chart: xray-103.96.1
    heritage: Helm
    release: my-release
    component: xray
spec:
  serviceName: "my-release-xray"
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: xray
      release: my-release
      component: xray
  template:
    metadata:
      labels:
        app: xray
        release: my-release
        component: xray
      annotations:
        checksum/xray-unified-secret: 63a5a3fe27e8227b7e2c9f9db5f49e5b7d14c11ef576133308b53f2949875904
    spec:
      serviceAccountName: default
      securityContext:
        fsGroup: 1035
        runAsGroup: 1035
        runAsNonRoot: true
        runAsUser: 1035
      initContainers:
      
      - name: postgres-setup-init
        image: "releases-docker.jfrog.io/postgres:15.6-alpine"
        imagePullPolicy: IfNotPresent
        resources: 
                limits:
                  cpu: 1
                  memory: 1Gi
                requests:
                  cpu: 5m
                  memory: 10Mi
        command:
          - '/bin/bash'
          - '-c'
          - >
            echo "Running init db scripts";
            bash /scripts/setupPostgres.sh
        env:
          - name: PGUSERNAME
            value: postgres
          - name: DB_HOST
            value: my-release-postgresql
          - name: DB_PORT
            value: "5432"
          - name: DB_SSL_MODE
            value: "disable"
          - name: DB_NAME
            value: xray
          - name: DB_USERNAME
            valueFrom:
              secretKeyRef:
                name: xray-unified-secret
                key: db-user
          - name: DB_PASSWORD
            valueFrom:
              secretKeyRef:
                name: xray-unified-secret
                key: db-password
          - name: PGPASSWORD
            value: postgres
          - name: CHART_NAME
            value: xray
        volumeMounts:
          - name: postgres-setup-init-vol
            mountPath: "/scripts"
      
      - name: 'copy-system-yaml'
        image: releases-docker.jfrog.io/ubi9/ubi-minimal:9.4.949
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 50Mi
        command:
        - 'bash'
        - '-c'
        - >
          if [[ -e "/var/opt/jfrog/xray/etc/filebeat.yaml" ]]; then chmod 644 /var/opt/jfrog/xray/etc/filebeat.yaml; fi;
          echo "Copy system.yaml to /var/opt/jfrog/xray/etc";
          mkdir -p /var/opt/jfrog/xray/etc;
          cp -fv /tmp/etc/system.yaml /var/opt/jfrog/xray/etc/system.yaml;
          echo "Remove /var/opt/jfrog/xray/lost+found folder if exists";
          rm -rfv /var/opt/jfrog/xray/lost+found;
          echo "Copy joinKey to /var/opt/jfrog/xray/etc/security";
          mkdir -p /var/opt/jfrog/xray/etc/security;
          echo ${XRAY_JOIN_KEY} > /var/opt/jfrog/xray/etc/security/join.key;
          echo "Copy masterKey to /var/opt/jfrog/xray/etc/security";
          mkdir -p /var/opt/jfrog/xray/etc/security;
          echo ${XRAY_MASTER_KEY} > /var/opt/jfrog/xray/etc/security/master.key;
        env:
        - name: XRAY_JOIN_KEY
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: join-key
        - name: XRAY_MASTER_KEY
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: master-key
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        - name: xray-unified-secret-volume
          mountPath: "/tmp/etc/system.yaml"
          subPath: system.yaml
      containers:
      - name: router
        image: releases-docker.jfrog.io/jfrog/router:7.108.0
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/sh'
          - '-c'
          - >
            exec /opt/jfrog/router/app/bin/entrypoint-router.sh;
        env:
        - name: JF_ROUTER_TOPOLOGY_LOCAL_REQUIREDSERVICETYPES
          value: jfxr,jfxana,jfxidx,jfxpst,jfob
        ports:
          - name: http-router
            containerPort: 8082
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/router"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
        readinessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/readiness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
      - name: observability
        image: releases-docker.jfrog.io/jfrog/observability:1.28.0
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/sh'
          - '-c'
          - >
            exec /opt/jfrog/observability/app/bin/entrypoint-observability.sh;
        env:
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/observability"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8036/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8036/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: xray-server
        image: releases-docker.jfrog.io/jfrog/xray-server:3.96.1
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/xray/app/bin/wrapper.sh;
        env:
              
        - name: XRAY_CHART_FULL_NAME
          value: 'my-release-xray'
        - name: XRAY_CHART_NAME
          value: 'xray'
        - name: XRAY_CHART_UNIFIED_SECRET_INSTALLATION
          value: "true"
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_EXISTING_SECRET
          value: ""
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_DATA_KEY
          value: ""
              
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-url
        - name: XRAY_K8S_ENV
          value: "true"
        - name: EXECUTION_JOB_AES_KEY
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: execution-service-aes-key
        - name: "JF_SHARED_RABBITMQ_VHOST"
          value: "xray"
        
        ports:
        - containerPort: 8000
          name: http-server
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8000/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8000/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
          
      - name: xray-analysis
        image: releases-docker.jfrog.io/jfrog/xray-analysis:3.96.1
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/xray/app/bin/wrapper.sh;
        env:
              
        - name: XRAY_CHART_FULL_NAME
          value: 'my-release-xray'
        - name: XRAY_CHART_NAME
          value: 'xray'
        - name: XRAY_CHART_UNIFIED_SECRET_INSTALLATION
          value: "true"
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_EXISTING_SECRET
          value: ""
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_DATA_KEY
          value: ""
              
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-url
        - name: XRAY_HA_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: XRAY_K8S_ENV
          value: "true"
        - name: EXECUTION_JOB_AES_KEY
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: execution-service-aes-key
        - name: "JF_SHARED_RABBITMQ_VHOST"
          value: "xray"
        
        ports:
        - containerPort: 7000
          name: http-analysis
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7000/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7000/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
          
      - name: xray-indexer
        image: releases-docker.jfrog.io/jfrog/xray-indexer:3.96.1
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/xray/app/bin/wrapper.sh;
        env:
              
        - name: XRAY_CHART_FULL_NAME
          value: 'my-release-xray'
        - name: XRAY_CHART_NAME
          value: 'xray'
        - name: XRAY_CHART_UNIFIED_SECRET_INSTALLATION
          value: "true"
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_EXISTING_SECRET
          value: ""
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_DATA_KEY
          value: ""
              
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-url
        - name: XRAY_HA_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: XRAY_K8S_ENV
          value: "true"
        - name: "JF_SHARED_RABBITMQ_VHOST"
          value: "xray"
        
        ports:
        - containerPort: 7002
          name: http-indexer
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7002/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7002/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
          
      - name: xray-persist
        image: releases-docker.jfrog.io/jfrog/xray-persist:3.96.1
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/xray/app/bin/wrapper.sh;
        env:
              
        - name: XRAY_CHART_FULL_NAME
          value: 'my-release-xray'
        - name: XRAY_CHART_NAME
          value: 'xray'
        - name: XRAY_CHART_UNIFIED_SECRET_INSTALLATION
          value: "true"
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_EXISTING_SECRET
          value: ""
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_DATA_KEY
          value: ""
              
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-url
        - name: XRAY_K8S_ENV
          value: "true"
        - name: "JF_SHARED_RABBITMQ_VHOST"
          value: "xray"
        
        ports:
        - containerPort: 7003
          name: http-persist
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7003/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7003/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
          
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app: xray
                    release: my-release
      volumes:
      ########## External secrets ###########
      ############ Config map, Volumes and Custom Volumes ##############
      #########  unifiedSecretInstallation ###########
      - name: xray-unified-secret-volume
        secret:
          secretName: xray-unified-secret
      
      - name: postgres-setup-init-vol
        configMap:
          name: my-release-setup-script
      
  volumeClaimTemplates:
  - metadata:
      name: data-volume
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
---
# Source: jfrog-platform/charts/xray/templates/migration-hook.yaml
---
---
# Source: jfrog-platform/templates/migration-hook.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.2
        release: "my-release"
        heritage: "Helm"
    name: my-release-rabbitmq-migration
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
automountServiceAccountToken: true
---
# Source: jfrog-platform/templates/upgrade-hook.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.2
        release: "my-release"
        heritage: "Helm"
    name: my-release-jfrog-platform
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
automountServiceAccountToken: true
---
# Source: jfrog-platform/templates/migration-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.2
        release: "my-release"
        heritage: "Helm"
    name: my-release-rabbitmq-migration
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
rules:
- apiGroups:
  - ""
  resources:
  - pods/exec
  - pods
  verbs:
  - create
  - get
  - list
---
# Source: jfrog-platform/templates/upgrade-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.2
        release: "my-release"
        heritage: "Helm"
    name: my-release-jfrog-platform
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
rules:
- apiGroups:
    - ""
  resources:
    - pods/exec
    - pods
  verbs:
    - create
    - get
    - list
---
# Source: jfrog-platform/templates/migration-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.2
        release: "my-release"
        heritage: "Helm"
    name: my-release-rabbitmq-migration
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
subjects:
    - kind: ServiceAccount
      name: my-release-rabbitmq-migration
roleRef:
    kind: Role
    apiGroup: rbac.authorization.k8s.io
    name: my-release-rabbitmq-migration
---
# Source: jfrog-platform/templates/upgrade-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.2
        release: "my-release"
        heritage: "Helm"
    name: my-release-jfrog-platform
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
subjects:
    - kind: ServiceAccount
      name: my-release-jfrog-platform
roleRef:
    kind: Role
    apiGroup: rbac.authorization.k8s.io
    name: my-release-jfrog-platform
---
# Source: jfrog-platform/templates/migration-hook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app: jfrog-platform
    chart: jfrog-platform-10.18.2
    heritage: Helm
    release: my-release
  name: my-release-jfrog-platform-pre-upgrade-hook
  annotations:
    "helm.sh/hook": "pre-upgrade"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.2
        heritage: Helm
        release: my-release
    spec:
      serviceAccountName: my-release-rabbitmq-migration
      securityContext:
        fsGroup: 1001
      containers:
        - name: pre-upgrade-container
          image: "releases-docker.jfrog.io/bitnami/kubectl:1.24.12"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 1
              memory: 1Gi
            requests:
              cpu: 5m
              memory: 10Mi
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - sh
            - -c
            - |
                #!/bin/sh
                if [ "$(kubectl get pods -l "app.kubernetes.io/name=rabbitmq" -o jsonpath='{..status.conditions[?(@.type=="Ready")].status}')" = "True" ]; then
                    kubectl exec -it my-release-rabbitmq-0 -- rabbitmqctl enable_feature_flag all
                    if [ "$?" -ne 0 ]; then
                      echo "Failed to perform the migration. Please make sure to enable the feature flag in rabbitmq manually [rabbitmqctl enable_feature_flag all] "
                      exit 1
                    else
                      echo Feature flags executed successfully!
                    fi
                else
                    echo "Rabbitmq pod is not in running state. Ignoring feature flag migration for rabbitmq"
                fi
      restartPolicy: Never
      terminationGracePeriodSeconds: 0
---
# Source: jfrog-platform/templates/upgrade-hook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app: jfrog-platform
    chart: jfrog-platform-10.18.2
    heritage: Helm
    release: my-release
  name: my-release-jfrog-platform-pre-upgrade-check
  annotations:
    "helm.sh/hook": "pre-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.2
        heritage: Helm
        release: my-release
    spec:
      serviceAccountName: my-release-jfrog-platform
      containers:
        - name: pre-upgrade-check
          image: "releases-docker.jfrog.io/bitnami/kubectl:1.24.12"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 1
              memory: 1Gi
            requests:
              cpu: 5m
              memory: 10Mi
          command:
            - sh
            - -c
            - |
                #!/bin/sh
                if [ "$(kubectl get pods -l "statefulset.kubernetes.io/pod-name=my-release-distribution-0" -o jsonpath='{..status.conditions[?(@.type=="Ready")].status}')" = "True" ]; then
                    if [ "$?" -eq 0 ]; then
                      echo "Failed to perform the upgrade. Refer to https://github.com/jfrog/charts/blob/master/stable/jfrog-platform/CHANGELOG.md#10180"
                      echo "From chart verison 10.18.x, Products - Distribution, Insight and Pipelines are disabled. If you are using these products in the previous release(s)."
                      echo "Enable them using your custom-values.yaml file "
                      exit 1
                    fi
                else
                    echo "Distribution pod(s) don't exist. Allowing upgrade"
                fi
                if [ "$(kubectl get pods -l "statefulset.kubernetes.io/pod-name=my-release-insight-0" -o jsonpath='{..status.conditions[?(@.type=="Ready")].status}')" = "True" ]; then
                    if [ "$?" -eq 0 ]; then
                      echo "Failed to perform the upgrade. Refer to https://github.com/jfrog/charts/blob/master/stable/jfrog-platform/CHANGELOG.md#10180"
                      echo "From chart verison 10.18.x, Products - Distribution, Insight and Pipelines are disabled. If you are using these products in the previous release(s)."
                      echo "Enable them using your custom-values.yaml file "
                      exit 1
                    fi
                else
                    echo "Insight pod(s) don't exist. Allowing upgrade"
                fi
                if [ "$(kubectl get pods -l "statefulset.kubernetes.io/pod-name=my-release-pipelines-0" -o jsonpath='{..status.conditions[?(@.type=="Ready")].status}')" = "True" ]; then
                    if [ "$?" -eq 0 ]; then
                      echo "Failed to perform the upgrade. Refer to https://github.com/jfrog/charts/blob/master/stable/jfrog-platform/CHANGELOG.md#10180"
                      echo "From chart verison 10.18.x, Products - Distribution, Insight and Pipelines are disabled. If you are using these products in the previous release(s)."
                      echo "Enable them using your custom-values.yaml file "
                      exit 1
                    fi
                else
                    echo "Pipelines pod(s) don't exist. Allowing upgrade"
                fi
      restartPolicy: Never
      terminationGracePeriodSeconds: 10
