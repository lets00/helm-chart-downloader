---
# Source: zoo-project-hpgc/charts/rabbitmq/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-rabbitmq
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.5.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
secrets:
  - name: my-release-rabbitmq
---
# Source: zoo-project-hpgc/charts/redis/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: my-release-redis
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
---
# Source: zoo-project-hpgc/templates/processing-manager-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-zoo-project-hpgc-processing-manager
  labels:
    helm.sh/chart: zoo-project-hpgc-0.0.3
    app.kubernetes.io/name: zoo-project-hpgc
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.0.6"
    app.kubernetes.io/managed-by: Helm
---
# Source: zoo-project-hpgc/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-zoo-project-hpgc
  labels:
    helm.sh/chart: zoo-project-hpgc-0.0.3
    app.kubernetes.io/name: zoo-project-hpgc
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.0.6"
    app.kubernetes.io/managed-by: Helm
---
# Source: zoo-project-hpgc/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-postgresql
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.9
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  postgres-password: "S0p4VjJnUzdWdA=="
  password: "em9v"
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: zoo-project-hpgc/charts/rabbitmq/templates/config-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-rabbitmq-config
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.5.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  rabbitmq.conf: |-
    IyMgVXNlcm5hbWUgYW5kIHBhc3N3b3JkCiMjCmRlZmF1bHRfdXNlciA9IFJBQkJJVE1RX1VTRVJOQU1FCiMjIENsdXN0ZXJpbmcKIyMKY2x1c3Rlcl9mb3JtYXRpb24ucGVlcl9kaXNjb3ZlcnlfYmFja2VuZCAgPSByYWJiaXRfcGVlcl9kaXNjb3ZlcnlfazhzCmNsdXN0ZXJfZm9ybWF0aW9uLms4cy5ob3N0ID0ga3ViZXJuZXRlcy5kZWZhdWx0CmNsdXN0ZXJfZm9ybWF0aW9uLm5vZGVfY2xlYW51cC5pbnRlcnZhbCA9IDEwCmNsdXN0ZXJfZm9ybWF0aW9uLm5vZGVfY2xlYW51cC5vbmx5X2xvZ193YXJuaW5nID0gdHJ1ZQpjbHVzdGVyX3BhcnRpdGlvbl9oYW5kbGluZyA9IGF1dG9oZWFsCmxvYWRfZGVmaW5pdGlvbnMgPSAvYXBwL2xvYWRfZGVmaW5pdGlvbi5qc29uCiMgcXVldWUgbWFzdGVyIGxvY2F0b3IKcXVldWVfbWFzdGVyX2xvY2F0b3IgPSBtaW4tbWFzdGVycwojIGVuYWJsZSBsb29wYmFjayB1c2VyCmxvb3BiYWNrX3VzZXJzLlJBQkJJVE1RX1VTRVJOQU1FID0gZmFsc2UKbG9hZF9kZWZpbml0aW9ucyA9IC9hcHAvbG9hZF9kZWZpbml0aW9uLmpzb24K
---
# Source: zoo-project-hpgc/charts/rabbitmq/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-rabbitmq
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.5.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  rabbitmq-password: "Q0hBTkdFTUU="
  
  rabbitmq-erlang-cookie: "MmpuNEZldmpZbUszc0QzRTVoWFc0UHBoc2lFYVJmc2E="
---
# Source: zoo-project-hpgc/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-redis
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  redis-password: "eFpBRE9JaEVuQw=="
---
# Source: zoo-project-hpgc/templates/rabbitmq-definition-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: load-definition
type: Opaque
stringData:
  load_definition.json: "{\n  \"rabbit_version\": \"3.8.9\",\n  \"rabbitmq_version\": \"3.8.9\",\n  \"product_name\": \"RabbitMQ\",\n  \"product_version\": \"3.8.9\",\n  \"users\": [\n    {\n      \"name\": \"guest\",\n      \"password_hash\": \"4+GY9SXaXs4JKn5uz0kVOQ/bklsy9dJRnxF2HwVco23TMFPg\",\n      \"hashing_algorithm\": \"rabbit_password_hashing_sha256\",\n      \"tags\": \"administrator\"\n    }\n  ],\n  \"vhosts\": [\n    {\n      \"name\": \"/\"\n    }\n  ],\n  \"permissions\": [\n    {\n      \"user\": \"guest\",\n      \"vhost\": \"/\",\n      \"configure\": \".*\",\n      \"write\": \".*\",\n      \"read\": \".*\"\n    }\n  ],\n  \"topic_permissions\": [],\n  \"parameters\": [],\n  \"global_parameters\": [\n    {\n      \"name\": \"cluster_name\",\n      \"value\": \"rabbit@7ef77dc5021e\"\n    },\n    {\n      \"name\": \"internal_cluster_id\",\n      \"value\": \"rabbitmq-cluster-id-I25xJdt3QpmEFzeKaPqmdQ\"\n    }\n  ],\n  \"policies\": [],\n  \"queues\": [\n    {\n      \"name\": \"amq.gen-67C6b7LbpXCa_2JKu5hsbQ\",\n      \"vhost\": \"/\",\n      \"durable\": false,\n      \"auto_delete\": true,\n      \"arguments\": {\n        \"x-message-ttl\": 6000\n      }\n    },\n    {\n      \"name\": \"amq.gen-A_NBM-thDA0ivfU5ni05eg\",\n      \"vhost\": \"/\",\n      \"durable\": false,\n      \"auto_delete\": true,\n      \"arguments\": {\n        \"x-message-ttl\": 6000\n      }\n    },\n    {\n      \"name\": \"amq.gen--15Q21vMHiRYsrhyftTmVw\",\n      \"vhost\": \"/\",\n      \"durable\": false,\n      \"auto_delete\": true,\n      \"arguments\": {\n        \"x-message-ttl\": 6000\n      }\n    },\n    {\n      \"name\": \"amq.gen-rsQm2-BNFiyT_1KEcDldsQ\",\n      \"vhost\": \"/\",\n      \"durable\": false,\n      \"auto_delete\": true,\n      \"arguments\": {\n        \"x-message-ttl\": 6000\n      }\n    },\n    {\n      \"name\": \"zoo_service_queue\",\n      \"vhost\": \"/\",\n      \"durable\": true,\n      \"auto_delete\": false,\n      \"arguments\": {\n        \"x-queue-type\": \"classic\"\n      }\n    }\n  ],\n  \"exchanges\": [],\n  \"bindings\": []\n}"
---
# Source: zoo-project-hpgc/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-configuration
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: zoo-project-hpgc/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-health
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: zoo-project-hpgc/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-scripts
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--requirepass" "${REDIS_PASSWORD}")
    ARGS+=("--masterauth" "${REDIS_PASSWORD}")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
  start-replica.sh: |
    #!/bin/bash

    get_port() {
        hostname="$1"
        type="$2"

        port_var=$(echo "${hostname^^}_SERVICE_PORT_$type" | sed "s/-/_/g")
        port=${!port_var}

        if [ -z "$port" ]; then
            case $type in
                "SENTINEL")
                    echo 26379
                    ;;
                "REDIS")
                    echo 6379
                    ;;
            esac
        else
            echo $port
        fi
    }

    get_full_hostname() {
        hostname="$1"
        echo "${hostname}.${HEADLESS_SERVICE}"
    }

    REDISPORT=$(get_port "$HOSTNAME" "REDIS")

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/replica.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/replica.conf /opt/bitnami/redis/etc/replica.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi

    echo "" >> /opt/bitnami/redis/etc/replica.conf
    echo "replica-announce-port $REDISPORT" >> /opt/bitnami/redis/etc/replica.conf
    echo "replica-announce-ip $(get_full_hostname "$HOSTNAME")" >> /opt/bitnami/redis/etc/replica.conf
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--replicaof" "${REDIS_MASTER_HOST}" "${REDIS_MASTER_PORT_NUMBER}")
    ARGS+=("--requirepass" "${REDIS_PASSWORD}")
    ARGS+=("--masterauth" "${REDIS_MASTER_PASSWORD}")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/replica.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: zoo-project-hpgc/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-zoo-project-hpgc-configmap
  namespace: zoo-project-hpgc-0.0.3.tgz
  labels:
    chart: "zoo-project-hpgc-0.0.3"
    release: my-release
    heritage: Helm
data:
  maincfg: "[main]\nencoding = utf-8\nversion = 1.0.0\nserverAddress = http://127.0.0.1\nlanguage = en-US\nlang = fr-FR,en-CA,en-US\ntmpPath=/tmp/zTmp\ntmpUrl = http://localhost:8080/temp/\ndataPath = /usr/com/zoo-project\ncacheDir =/tmp/zTmp\ntemplatesPath = /var/www/\n\n[identification]\ntitle = The ZOO-Project with DRU support for CWL deployment through OGC API - Processes - Part 2: Deploy, Replace, Undeploy\nabstract = Developement version of the ZOO-Project with support for:<br><ul><li>OGC API - Processes: Part1: Core standard</li><li>OGC API - Processes - Part 2: Deploy, Replace, Undeploy draft</li></ul><br> See <a target=\"_blank\" href=\"http://www.zoo-project.org\">http://zoo-project.org</a> for more informations. <br/>You can access the current <a href=\"https://docs.ogc.org/DRAFTS/20-044.html\" target=\"_blank\">OGC API - Processes - Part 2: Deploy, Replace, Undeploy draft specification</a>.\nfees = None\naccessConstraints = none\nkeywords = WPS,GIS,buffer\n\n[provider]\nproviderName=ZOO-Project\nproviderSite=http://www.zoo-project.org\nindividualName=Gerald FENOY\npositionName=Developer\nrole=Dev\naddressDeliveryPoint=1280, avenue des Platanes\naddressCity=Lattes\naddressAdministrativeArea=False\naddressPostalCode=34970\naddressCountry=fr\naddressElectronicMailAddress=gerald.fenoy@geolabs.fr\nphoneVoice=False\nphoneFacsimile=False\n\n\n[env]\nPYTHONPATH=/usr/miniconda3/envs/ades-dev/lib/python3.8/site-packages\nCONTEXT_DOCUMENT_ROOT=/usr/lib/cgi-bin/\n\n[database]\ndbname=zoo\nport=5432\nuser=zoo\npassword=zoo\nhost=my-release-postgresql\ntype=PG\nschema=public\n\n[metadb]\ndbname=zoo\nport=5432\nuser=zoo\npassword=zoo\nhost=my-release-postgresql\ntype=PG\nschema=public\n\n[security]\nattributes=Authorization,Cookie,User-Agent\nhosts=*\n\n[cookiecutter]\nconfigurationFile=/tmp/zTmp/cookiecutter_config.yaml\ntemplatesPath=/tmp/zTmp/cookiecutter-templates\ntemplateUrl=https://github.com/EOEPCA/proc-service-template.git\ntemplateBranch=\n\n\n[servicesNamespace]\npath= /opt/zooservices_user\ndeploy_service_provider=DeployProcess\nundeploy_service_provider=UndeployProcess\nrequired_files=securityOut.zcfg,security_service.py,DeployProcess.zcfg,DeployProcess.py,UndeployProcess.zcfg,UndeployProcess.py,deploy_util.py\n\n[rabbitmq]\nhost=my-release-rabbitmq\nport=5672\nuser=guest\npasswd=guest\nexchange=amq.direct\nroutingkey=zoo\nqueue=zoo_service_queue\n\n[server]\nasync_worker=20\n\n[HPC]\npreview_max_pixels=820800\npreview_max_features=100000\npreview_conf=hpc-config-2\nfullres_conf=hpc-config-1\n\n[hpc-config-1]\nssh_host=anvil.rcac.purdue.edu\nssh_port=22\nssh_user=x-gfenoy\nssh_key=/var/www/.ssh/id_rsa.pub\nessh_password=\nremote_data_path=/home/x-gfenoy/wps_executions/data\nremote_persitent_data_path=/home/x-gfenoy/wps_executions/datap\nremote_work_path=/home/x-gfenoy/wps_executions/script\njobscript_header=/usr/lib/cgi-bin/config-hpc1_header.txt\njobscript_body=/usr/lib/cgi-bin/config-hpc1_body.txt\nsbatch_substr=Submitted batch job\nbilling_nb_cpu=1\nremote_command_opt=Account%30,AdminComment%30,AllocCPUS%30,AllocNodes%30,AllocTRES%30,AssocID%30,AveCPU%30,AveCPUFreq%30,AveDiskRead%30,AveDiskWrite%30,AvePages%30,AveRSS%30,AveVMSize%30,BlockID%30,Cluster%30,Comment%30,Constraints%30,ConsumedEnergy%30,ConsumedEnergyRaw%30,Container%30,CPUTime%30,CPUTimeRAW%30,DBIndex%30,DerivedExitCode%30,Elapsed%30,ElapsedRaw%30,Eligible%30,End%30,ExitCode%30,Extra%30,FailedNode%30,Flags%30,GID%30,Group%30,JobID%30,JobIDRaw%30,JobName%30,Layout%30,Licenses%30,MaxDiskRead%30,MaxDiskReadNode%30,MaxDiskReadTask%30,MaxDiskWrite%30,MaxDiskWriteNode%30,MaxDiskWriteTask%30,MaxPages%30,MaxPagesNode%30,MaxPagesTask%30,MaxRSS%30,MaxRSSNode%30,MaxRSSTask%30,MaxVMSize%30,MaxVMSizeNode%30,MaxVMSizeTask%30,McsLabel%30,MinCPU%30,MinCPUNode%30,MinCPUTask%30,NCPUS%30,NNodes%30,NodeList%30,NTasks%30,Partition%30,Planned%30,PlannedCPU%30,PlannedCPURAW%30,Priority%30,QOS%30,QOSRAW%30,Reason%30,ReqCPUFreq%30,ReqCPUFreqGov%30,ReqCPUFreqMax%30,ReqCPUFreqMin%30,ReqCPUS%30,ReqMem%30,ReqNodes%30,ReqTRES%30,Reservation%30,ReservationId%30,Start%30,State%30,Submit%30,SubmitLine%30,Suspended%30,SystemComment%30,SystemCPU%30,Timelimit%30,TimelimitRaw%30,TotalCPU%30,TRESUsageInAve%30,TRESUsageInMax%30,TRESUsageInMaxNode%30,TRESUsageInMaxTask%30,TRESUsageInMin%30,TRESUsageInMinNode%30,TRESUsageInMinTask%30,TRESUsageInTot%30,TRESUsageOutAve%30,TRESUsageOutMax%30,TRESUsageOutMaxNode%30,TRESUsageOutMaxTask%30,TRESUsageOutMin%30,TRESUsageOutMinNode%30,TRESUsageOutMinTask%30,TRESUsageOutTot%30,UID%30,User%30,UserCPU%30,WCKey%30,WCKeyID%30,WorkDir%30\n\n[hpc-config-2]\nssh_host=anvil.rcac.purdue.edu\nssh_port=22\nssh_user=x-gfenoy\nssh_key=/var/www/.ssh/id_rsa.pub\nessh_password=\nremote_data_path=/home/x-gfenoy/wps_executions/data\nremote_persitent_data_path=/home/x-gfenoy/wps_executions/datap\nremote_work_path=/home/x-gfenoy/wps_executions/script\njobscript_header=/usr/lib/cgi-bin/config-hpc1_header.txt\njobscript_body=/usr/lib/cgi-bin/config-hpc1_body.txt\nsbatch_substr=Submitted batch job\nbilling_nb_cpu=1\nremote_command_opt=Account%30,AdminComment%30,AllocCPUS%30,AllocNodes%30,AllocTRES%30,AssocID%30,AveCPU%30,AveCPUFreq%30,AveDiskRead%30,AveDiskWrite%30,AvePages%30,AveRSS%30,AveVMSize%30,BlockID%30,Cluster%30,Comment%30,Constraints%30,ConsumedEnergy%30,ConsumedEnergyRaw%30,Container%30,CPUTime%30,CPUTimeRAW%30,DBIndex%30,DerivedExitCode%30,Elapsed%30,ElapsedRaw%30,Eligible%30,End%30,ExitCode%30,Extra%30,FailedNode%30,Flags%30,GID%30,Group%30,JobID%30,JobIDRaw%30,JobName%30,Layout%30,Licenses%30,MaxDiskRead%30,MaxDiskReadNode%30,MaxDiskReadTask%30,MaxDiskWrite%30,MaxDiskWriteNode%30,MaxDiskWriteTask%30,MaxPages%30,MaxPagesNode%30,MaxPagesTask%30,MaxRSS%30,MaxRSSNode%30,MaxRSSTask%30,MaxVMSize%30,MaxVMSizeNode%30,MaxVMSizeTask%30,McsLabel%30,MinCPU%30,MinCPUNode%30,MinCPUTask%30,NCPUS%30,NNodes%30,NodeList%30,NTasks%30,Partition%30,Planned%30,PlannedCPU%30,PlannedCPURAW%30,Priority%30,QOS%30,QOSRAW%30,Reason%30,ReqCPUFreq%30,ReqCPUFreqGov%30,ReqCPUFreqMax%30,ReqCPUFreqMin%30,ReqCPUS%30,ReqMem%30,ReqNodes%30,ReqTRES%30,Reservation%30,ReservationId%30,Start%30,State%30,Submit%30,SubmitLine%30,Suspended%30,SystemComment%30,SystemCPU%30,Timelimit%30,TimelimitRaw%30,TotalCPU%30,TRESUsageInAve%30,TRESUsageInMax%30,TRESUsageInMaxNode%30,TRESUsageInMaxTask%30,TRESUsageInMin%30,TRESUsageInMinNode%30,TRESUsageInMinTask%30,TRESUsageInTot%30,TRESUsageOutAve%30,TRESUsageOutMax%30,TRESUsageOutMaxNode%30,TRESUsageOutMaxTask%30,TRESUsageOutMin%30,TRESUsageOutMinNode%30,TRESUsageOutMinTask%30,TRESUsageOutTot%30,UID%30,User%30,UserCPU%30,WCKey%30,WCKeyID%30,WorkDir%30\n\n[headers]\nX-Powered-By=ZOO-Project-HPGC\nAccess-Control-Allow-Origin=*\nAccess-Control-Allow-Methods=GET,PUT,POST,DELETE\nAccess-Control-Allow-Headers=Content-Type,Authorization\n"
  oas: "[openapi]\nuse_content=false\nrootUrl=http://localhost/ogc-api\nrootHost=http://localhost:8080\nrootPath=ogc-api\nlinks=/,/api,/conformance,/processes,/jobs\npaths=/root,/api,/conformance,/processes,/processes/{processID},/processes/snuggs/execution,/processes/{processID}/execution,/jobs,/jobs/{jobID},/jobs/{jobID}/results\nparameters=processID,jobID,resultID\nheader_parameters=oas-header1,oas-header2,oas-header3,limitParam,skipParam,processIdParam,statusParam,minDurationParam,maxDurationParam,typeParam,datetimeParam,wParam\nversion=3.0.3\nlicense_name=OGC license\nlicense_url=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/LICENSE\nfull_html_support=false\npartial_html_support=false\nwsUrl=ws://localhost:8888/\npublisherUrl=http://zookernel/cgi-bin/publish.py?jobid=\nlink_href=http://zoo-project.org/dl/link.json\ntags=Home,API,Conformance,GetCapabilities,Deploy,Replace,Undeploy,ProcessDescription,ExecuteEndpoint,JobList,GetStatus,GetResult,Dismiss\nexamplesPath=/var/www/html/examples/\nexamplesUrl=http://localhost/examples/\nexceptionsUrl=https://www.opengis.net/def/exceptions/ogcapi-processes-1/1.0\nexceptionsUrl_1=https://www.opengis.net/def/exceptions/ogcapi-processes-2/1.0\nuse_problem_json_content_type_for_exception=true\n\n[oas-header1]\nin=header\nname=Prefer\ntype=string\nrequired=true\nenum=return=representation,return=minimal,respond-async;return=representation\nenum1=,return=representation,return=minimal,respond-async;return=representation,respond-async;return=minimal\n\n[oas-header2]\nin=header\nname=Prefer\ntype=string\nrequired=false\nenum=return=representation,return=minimal\n\n[oas-header3]\nin=header\nname=Prefer\ntype=string\nrequired=true\nenum=respond-async;return=representation\n\n[limitParam]\nname=limit\ntitle=The limit parameter\nabstract=The limit parameter indicates the number of elements to return in an array\nin=query\ntype=integer\nschema_minimum=1\nschema_maximum=10000\nschema_default=1000\nrequired=false\n\n[skipParam]\nname=skip\ntitle=The skip parameter\nabstract=The skip parameter indicates the number of elements to skip before starting returning values in an array\nin=query\ntype=integer\nschema_minimum=0\nrequired=false\n\n[wParam]\nname=w\ntitle=The workflow id parameter\nabstract=The workflow parameter indicates the name of an existing entry point within the CWL workflow definition associated with\nin=query\ntype=string\nschema_default=snuggs\nrequired=false\n\n[/]\nrel=self\ntype=application/json\ntitle=this document\n\n[root]\nmethod=get\ntitle=landing page of this API\nabstract=The landing page provides links to the API definition, the Conformance statements and the metadata about the processes offered by this service.\ntags=Home\ntags_description=\nschema=https://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/LandingPage.yaml\n\n[/index.html]\nrel=alternate\ntype=text/html\n\n[/api]\nrel=service-desc\ntype=application/vnd.oai.openapi+json;version=3.0\ntitle=the API definition\n\n[/api.html]\nrel=service-doc\ntype=text/html\n\n[api.html]\nhref=http://localhost:8080/swagger-ui/oapip/\n\n[api]\nmethod=get\ntitle=This document\nabstract=This document\ntags=API\ntags_description=\nschema=\n\n[/conformance]\nrel=https://www.opengis.net/def/rel/ogc/1.0/conformance\ntype=application/json\ntitle=OGC API - Processes conformance classes implemented by this server\n\n[conformance]\nmethod=get\ntitle=information about standards that this API conforms to\nabstract=list all requirements classes specified in a standard (e.g., WPS REST/JSON Binding Core) that the server conforms to\ntags=Conformance\ntags_description=\nschema=https://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/ConformanceDeclaration.yaml\n\n[/conformance.html]\nrel=alternate\ntype=text/html\n\n[/processes]\nrel=http://www.opengis.net/def/rel/ogc/1.0/processes\ntype=application/json\ntitle=The processes offered by this server\n\n[processes]\nlength=2\nmethod=get\ntitle=retrieve available processes\nabstract=Information about the available processes\ntags=GetCapabilities\ntags_description=\nparameters=/components/parameters/limitParam,/components/parameters/skipParam\nschema=https://raw.githubusercontent.com/GeoLabs/ogcapi-processes/rel-1.0/core/openapi/responses/ProcessList.yaml\nmethod_1=post\ncode_1=201\ntitle_1=deploy a new processes\nabstract_1=Deploy a new processes\ntags_1=Deploy\ntags_description_1=\nparameters_1=/components/parameters/wParam\nschema_1=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/openapi/responses/processes-dru/rDeployProcess.yaml\neschema_1=https://raw.githubusercontent.com/GeoLabs/ogcapi-processes/master/extensions/deploy_replace_undeploy/standard/openapi/responses/DeployProcess.yaml\necode_1=500\nisecured_1=BasicAuth\nrequestBody_length_1=2\nrequestBody_1=requestBodyPkg\nexamples_1=deployment-job.json,deployment-job1.json,deployment-job2.json,\nexamples_summary_1=Deploy snuggs process\nexamples_summary_1_1=Deploy vegetation-index process\nexamples_summary_1_2=Deploy dNBR process\nrequestBody_1_1=requestBodyCwl\nexamples_ref_1_1=https://raw.githubusercontent.com/EOEPCA/app-snuggs/main/app-package.cwl\nexamples_1_1=app-package.cwl\nexamples_summary_1_3=Deploy snuggs process as CWL\n\n[/processes.html]\nrel=alternate\ntype=text/html\n\n[processes/{processID}]\nprel=http://www.opengis.net/def/rel/iana/1.0/describedby\nrel=self\nlength=3\nmethod=get\ntitle=retrieve a process description\nabstract=A process description.\ntags=ProcessDescription\ntags_description=\nschema=https://raw.githubusercontent.com/GeoLabs/ogcapi-processes/rel-1.0/core/openapi/responses/swagger/ProcessDescription.yaml\necode=404\nparameters=/components/parameters/processID\nmethod_1=delete\ncode_1=204\ntitle_1=undeploy a mutable process\nisecured_1=BasicAuth\nabstract_1=Undeploy a mutable process.\ntags_1=Undeploy\ntags_description_1=\necode_1=404\nparameters_1=/components/parameters/processID\nmethod_2=put\ncode_2=204\ntitle_2=Update a mutable process\nrequestBody_length_2=2\nrequestBody_2=requestBodyPkg\nrequestBody_2_1=requestBodyCwl\nabstract_2=Update a mutable process.\ntags_2=Replace\ntags_description_2=\necode_2=404\nisecured_2=BasicAuth\nparameters_2=/components/parameters/processID\nexamples_2=deployment-job.json\nexamples_summary_2=Update snuggs process\nexamples_ref_2_1=https://raw.githubusercontent.com/EOEPCA/app-snuggs/main/app-package.cwl\nexamples_summary_2_1=Update test snuggs process\n\n[processes/{processID}/execution]\nrel=http://www.opengis.net/def/rel/ogc/1.0/execute\nlength=1\nmethod=post\ntitle=execute a job\nabstract=An execute endpoint.\ntags=ExecuteEndpoint\ntags_description=\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/ExecuteSync.yaml\nparameters=/components/parameters/processID,/components/parameters/oas-header1\necode=400,404,500\neschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/ExecuteAsync.yaml\nrequestBody=requestBody\ncallbacksReference=callbacks\n\n\n[processes/snuggs/execution]\nlength=1\nmethod=post\npname=snuggs\ntitle=execute a job\nabstract=An execute endpoint.\ntags=ExecuteEndpoint\ntags_description=\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/ExecuteSync.yaml\nparameters=/components/parameters/oas-header3\ncallbacksReference=callbacks\necode=400,404,500\neschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/ExecuteAsync.yaml\nexamples=job_order1.json,job_order2.json,job_order3.json\nexamples_summary=Execute suggs-0_3_0 producing ndvi and nbr for a single image\nexamples_summary_1=Execute suggs-0_3_0 producing ndvi and nbr for another image\nexamples_summary_2=Execute suggs-0_3_0 producing ndvi and nbr for the two images\n\n[/jobs]\nrel=http://www.opengis.net/def/rel/ogc/1.0/job-list\ntype=application/json\ntitle=Job Management\n\n[jobs]\nlength=1\nmethod=get\ntitle=retrieve a list of jobs run\nabstract=A list of jobs run.\ntags=JobList\ntags_description=\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/JobList.yaml\nparameters=/components/parameters/limitParam,/components/parameters/skipParam,/components/parameters/processIdParam,/components/parameters/statusParam,/components/parameters/minDurationParam,/components/parameters/maxDurationParam,/components/parameters/typeParam,/components/parameters/datetimeParam\necode=500\nmethod_1=post\ntitle_1=execute a job\nabstract_1=An execute endpoint.\ntags_1=ExecuteEndpoint\ntags_description_1=\nschema_1=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/ExecuteSync.yaml\nparameters_1=\necode_1=400,404,500\neschema_1=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/ExecuteAsync.yaml\nep=,/components/parameters/oas-header1\n\n[requestBody]\nabstract=Mandatory execute request in JSON format\ntype=application/json\nschema=https://raw.githubusercontent.com/GeoLabs/ogcapi-processes/rel-1.0/core/openapi/schemas/execute.yaml\n\n[requestBodyPkg]\nabstract=Mandatory OGC Application Package in JSON format\ntype=application/ogcapppkg+json\nschema=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/openapi/schemas/processes-dru/ogcapppkg.yaml\neschema=https://raw.githubusercontent.com/GeoLabs/ogcapi-processes/master/extensions/deploy_replace_undeploy/standard/openapi/schemas/swagger/ogcapppkg.yaml\n\n[requestBodyCwl]\nabstract=Mandatory OGC Application Package in CWL format\ntype=application/cwl+yaml\nschema=https://raw.githubusercontent.com/common-workflow-language/schema_salad/main/schema_salad/metaschema/metaschema.yml\n\n[/jobs.html]\nrel=alternate\ntype=text/html\n\n[/jobs/{jobID}]\nrel=canonical\ntype=application/json\ntitle=Status\n\n[jobs/{jobID}]\nlength=2\nmethod=get\ntitle=The status of a job.\nabstract=The status of a job.\ntags=GetStatus\ntags_description=\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/Status.yaml\nparameters=/components/parameters/jobID\necode=404,500\nmethod_1=delete\ntitle_1=Cancel a job\nabstract_1=Cancel the job execution.\ntags_1=Dismiss\ntags_description_1=Cancel a job execution\nschema_1=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/Status.yaml\nparameters_1=/components/parameters/jobID\necode_1=404,500\n\n[/jobs/{jobID}/results]\nrel=http://www.opengis.net/def/rel/ogc/1.0/results\ntype=application/json\ntitle=Get Result\n\n[jobs/{jobID}/results]\nmethod=get\ntitle=The result of a job execution.\nabstract=The result of a job execution.\ntags=GetResult\ntags_description=\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/Results.yaml\nparameters=/components/parameters/jobID\necode=404,500\nep=,/components/parameters/oas-header2\n\n[{processID}]\ntype=string\ntitle=The id of a process\nabstract=The id of a process\nin=path\nrequired=true\nexample=snuggs\n\n[{jobID}]\ntype=string\ntitle=The id of a job\nabstract=The id of a job\nin=path\nrequired=true\n\n[{resultID}]\ntype=string\ntitle=The id of an output\nabstract=The id of an output\nin=path\nrequired=true\n\n[statusParam]\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/parameters/status.yaml\n\n[processIdParam]\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/parameters/processIdQueryParam.yaml\n\n[minDurationParam]\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/parameters/minDuration.yaml\n\n[maxDurationParam]\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/parameters/maxDuration.yaml\n\n[typeParam]\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/parameters/type.yaml\n\n[datetimeParam]\nschema=https://schemas.opengis.net/ogcapi/features/part1/1.0/openapi/parameters/datetime.yaml\n\n[{f}]\ndefault=json\nenum=json\ntitle=The optional f parameter\nabstract=The optional f parameter indicates the output format which the server shall provide as part of the response document.  The default format is JSON.\nin=query\nrequired=false\n\n[conformsTo]\nrootUrl=http://www.opengis.net/spec/ogcapi-processes/1.0/req/\nextentionsLength=1\nextentionUrl=http://www.opengis.net/spec/ogcapi-processes-2/1.0/req/\nlink=core\nlink_1=oas30\nlink_2=json\nlink_3=job-list\nlink_4=dismiss\nlink_5=callback\nlink_6=ogc-process-description\nlink_7=deploy-replace-undeploy\nextention_7=true\nextid_7=0\nlink_8=cwl\nextention_8=true\nextid_8=0\nlink_9=cwl\nextention_9=true\nextid_9=0\nlength=10\n\n[exception]\nabstract=Exception\ntype=application/json\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/NotFound.yaml\ndefault_schema=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/openapi/responses/common-core/rServerError.yaml\n\n[responses]\nlength=5\ncode=404\nschema=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/openapi/responses/common-core/rNotFound.yaml\naschema=https://raw.githubusercontent.com/GeoLabs/ogcapi-processes/master/core/openapi/responses/NotFound.yaml\neschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/NotFound.yaml\ntype=application/json\ntitle=NotFound\ncode_1=500\nschema_1=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/openapi/responses/common-core/rServerError.yaml\ntype_1=application/json\ntitle_1=ServerError\ncode_2=400\nschema_2=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/openapi/responses/common-core/rInvalidParameter.yaml\naschema_2=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/core/openapi/responses/InvalidParameter.yaml\neschema_2=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/InvalidParameter.yaml\ntype_2=appliction/json\ntitle_2=InvalidParameter\ncode_3=405\nschema_3=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/core/openapi/responses/NotAllowed.yaml\neschema_3=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/NotAllowed.yaml\ntype_3=appliction/json\ntitle_3=NotAllowed\ncode_4=406\nschema_4=https://raw.githubusercontent.com/opengeospatial/ogcapi-processes/master/core/openapi/responses/NotSupported.yaml\neschema_4=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/responses/NotSupported.yaml\ntype_4=appliction/json\ntitle_4=NotSupported\n\n[callbacks]\nlength=3\nstate=jobSuccess\nuri=successUri\nschema=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/schemas/results.yaml\ntype=application/json\ntitle=Results received successfully\nstate_1=jobInProgress\nuri_1=inProgressUri\nschema_1=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/schemas/statusInfo.yaml\ntype_1=application/json\ntitle_1=Status received successfully\nstate_2=jobFailed\nuri_2=failedUri\nschema_2=http://schemas.opengis.net/ogcapi/processes/part1/1.0/openapi/schemas/exception.yaml\ntype_2=application/json\ntitle_2=Exception received successfully\n\n[links_title]\nself=View this document in JSON.\nalternate=View the alternative version in HTML.\nconformance=View the conformance classes that the link's context conforms to.\nservice-desc=View the service description.\nservice-doc=View service documentation.\nprocesses=View the list of processes the API offers.\nresults=View the results of a process.\nstatus=View the current status of a job execution.\nexecute=View the execution endpoint of a process.\njob-list=View the list of job available on this server.\n\n[provider_alt]\naddressDeliveryPoint=streetAddress\naddressCity=addressLocality\naddressAdministrativeArea=addressRegion\naddressPostalCode=postalCode\naddressCountry=addressCountry\naddressElectronicMailAddress=email\nphoneVoice=telephone\nphoneFacsimile=faxNumber\nhoursOfService=hoursAvailable\ncontactInstructions=contactOption\n\n[osecurity]\nname=BasicAuth\ntype=http\nscheme=basic\nrealm=Secured section\ncharset=utf-8\npasswd=/tmp/htpasswords\n\n[filter_in]\npath=/usr/lib/cgi-bin\nservice=securityIn\n\n[filter_out]\npath=/usr/lib/cgi-bin\nservice=securityOut\n\n"
  htaccess: "RewriteEngine On\nSetEnvIf Request_URI \"^\\/?(\\w+)\\/ogc-api(.*)\" SERVICES_NAMESPACE=$1\nRewriteRule ^\\/?(\\w+)\\/ogc-api/(.*) /ogc-api/$2 [PT]\nRewriteCond %{REQUEST_FILENAME} !-f\nRewriteCond %{REQUEST_FILENAME} !-d\nRewriteRule ^ogc-api/api.html$ /cgi-bin/zoo_loader.cgi?/api.html [L,QSA]\nRewriteRule ^ogc-api/index.html$ /cgi-bin/zoo_loader.cgi?service=WPS&service=WPS&request=Execute&version=1.0.0&Identifier=display&RawDataOutput=Result&DataInputs=tmpl=@xlink:href=http://localhost/ogc-api/ [L,QSA]\nRewriteRule ^ogc-api(.*).html$ /cgi-bin/zoo_loader.cgi?service=WPS&service=WPS&request=Execute&version=1.0.0&Identifier=display&RawDataOutput=Result&DataInputs=tmpl=@xlink:href=http://localhost/ogc-api$1 [L,QSA]\nRewriteRule ^ogc-api(.*)$ /cgi-bin/zoo_loader.cgi?$1 [L,QSA]\n"
  cookiecutter_config: "replay_dir: \"/tmp/zTmp/cookiecutter-templates/\"\ncookiecutters_dir: \"/tmp/zTmp/cookiecutter-templates/\"\n"
  additional_inputs: "APP: zoo-project-hpgc\nSTAGEIN_AWS_ACCESS_KEY_ID: minio-admin\nSTAGEIN_AWS_REGION: RegionOne\nSTAGEIN_AWS_SECRET_ACCESS_KEY: minio-secret-password\nSTAGEIN_AWS_SERVICEURL: http://zoo-project-hpgc-minio.zp.svc.cluster.local:9000\nSTAGEOUT_AWS_ACCESS_KEY_ID: minio-admin\nSTAGEOUT_AWS_REGION: RegionOne\nSTAGEOUT_AWS_SECRET_ACCESS_KEY: minio-secret-password\nSTAGEOUT_AWS_SERVICEURL: http://zoo-project-hpgc-minio.zp.svc.cluster.local:9000\nSTAGEOUT_OUTPUT: s3://processingresults"
  pod_env_vars: "{}"
  pod_nodeselectors: "{}"
  pod_imagePullSecrets: "[]"
---
# Source: zoo-project-hpgc/templates/cwlwrapper-assets-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-zoo-project-hpgc-cwlwrapper-configmap
data:
  maincwl: "class: Workflow\n$namespaces:\n    cwltool: http://commonwl.org/cwltool#\ndoc: Main stage manager\nid: main\nlabel: macro-cwl\ninputs: {}\noutputs: \n    StacCatalogUri:\n        outputSource:\n          - node_stage_out/StacCatalogUri\n        type: string\nhints:\n    \"cwltool:Secrets\":\n        secrets: []\nrequirements:\n    SubworkflowFeatureRequirement: {}\n    ScatterFeatureRequirement: {}\n    InlineJavascriptRequirement: {}"
  maincwlmetrics: "class: Workflow\ndoc: Main stage manager\nid: stage-manager\nlabel: theStage\ninputs:\n  workflow:\n    doc: workflow\n    label: workflow\n    type: string\n  process:\n    doc: process\n    label: process\n    type: string\n\noutputs: {}\n\nrequirements:\n  SubworkflowFeatureRequirement: {}\n  ScatterFeatureRequirement: {}\n\nsteps:\n\n  node_metrics_in:\n    in:\n      inp1: workflow\n      inp2: process\n    out:\n      - results\n    run:\n      baseCommand: metrics\n      hints:\n        DockerRequirement:\n          dockerPull: terradue/metrics:0.1\n      class: CommandLineTool\n      id: clt\n      arguments:\n        - prefix: --event\n          position: 3\n          valueFrom: \"started\"\n      inputs:\n        inp1:\n          inputBinding:\n            position: 1\n            prefix: --workflow\n          type: string\n        inp2:\n          inputBinding:\n            position: 2\n            prefix: --process\n          type: string\n      outputs:\n        results:\n          type: stdout\n      requirements:\n        EnvVarRequirement:\n          envDef:\n            PATH: /srv/conda/envs/env_metrics/bin:/opt/anaconda/bin:/usr/share/java/maven/bin:/opt/anaconda/bin:/opt/anaconda/envs/notebook/bin:/opt/anaconda/bin:/usr/share/java/maven/bin:/opt/anaconda/bin:/opt/anaconda/condabin:/opt/anaconda/bin:/usr/lib64/qt-3.3/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin\n        ResourceRequirement: { }\n\n  node_stage_in:\n    in:\n      metrics: node_metrics_in/results\n    out: []\n    run: ''\n#\n#  on_stage:\n#    in: {}\n#    out: []\n#    run: ''\n\n#  node_stage_out:\n#    in: {}\n#    out: []\n#    run: ''\n\n  node_metrics_out:\n    in:\n      inp1: workflow\n      inp2: process\n\n    out:\n      - results\n    run:\n      baseCommand: metrics\n      hints:\n        DockerRequirement:\n          dockerPull: terradue/metrics:0.1\n      class: CommandLineTool\n      id: clt\n      arguments:\n        - prefix: --event\n          position: 3\n          valueFrom: \"succeeded\"\n      inputs:\n        inp1:\n          inputBinding:\n            position: 1\n            prefix: --workflow\n          type: string\n        inp2:\n          inputBinding:\n            position: 1\n            prefix: --process\n          type: string\n      outputs:\n        results:\n          type: stdout\n      requirements:\n        EnvVarRequirement:\n          envDef:\n            PATH: /srv/conda/envs/env_metrics/bin:/opt/anaconda/bin:/usr/share/java/maven/bin:/opt/anaconda/bin:/opt/anaconda/envs/notebook/bin:/opt/anaconda/bin:/usr/share/java/maven/bin:/opt/anaconda/bin:/opt/anaconda/condabin:/opt/anaconda/bin:/usr/lib64/qt-3.3/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin\n        ResourceRequirement: { }\n"
  rules: "rulez:\n  version: 1\n\nparser:\n  type: $graph\n  driver: cwl\n\nonstage:\n  driver: cwl\n\n  stage_in:\n    connection_node: node_stage_in\n    if_scatter:\n      scatterMethod: dotproduct\n    input:\n      template:\n        overwrite: True\n\n  on_stage:\n    connection_node: on_stage\n\n  stage_out:\n    connection_node: node_stage_out\n    scatter: False\n    if_scatter:\n      scatterMethod: dotproduct\n    follow_node: node_metrics_out\n\n\noutput:\n  driver: cwl\n  name: '-'\n  type: $graph\n\n\ncwl:\n  GlobalInput:\n    Directory: string\n    Directory[]: string[]\n\n  OptionalInput:\n    Directory: string?\n    Directory[]: string[]?\n\n  stage_in:\n    Directory:\n      type: string\n      inputBinding:\n        position: 2\n\n    Directory[]:\n      type: string[]\n      inputBinding:\n        position: 2\n\n  stage_out:\n    Directory:\n      type: Directory\n\n    Directory[]:\n      type: Directory[]\n\n  outputBindingResult:\n    command:\n      Directory:\n        outputBinding:\n          glob: .\n        type: Directory\n      Directory[]:\n        outputBinding:\n          glob: .\n        type: Directory[]\n    stepOut:\n      type:\n        items: Directory\n        type: array"
  stagein: "cwlVersion: v1.0\ndoc: \"Run Stars for staging input data\"\nclass: CommandLineTool\nhints:\n  DockerRequirement:\n    dockerPull: terradue/stars:1.0.0-beta.11\n  \"cwltool:Secrets\":\n    secrets:\n    - STAGEIN_AWS_SERVICEURL\n    - STAGEIN_AWS_ACCESS_KEY_ID\n    - STAGEIN_AWS_SECRET_ACCESS_KEY\nid: stars\ninputs:\n  STAGEIN_AWS_SERVICEURL:\n    type: string?\n  STAGEIN_AWS_ACCESS_KEY_ID:\n    type: string?\n  STAGEIN_AWS_SECRET_ACCESS_KEY:\n    type: string?\noutputs: {}\nbaseCommand: ['/bin/bash', 'stagein.sh']\nrequirements:\n  InitialWorkDirRequirement:\n    listing:\n    - entryname: stagein.sh\n      entry: |-\n        #!/bin/bash\n        export AWS__ServiceURL=$(inputs.STAGEIN_AWS_SERVICEURL)\n        export AWS_ACCESS_KEY_ID=$(inputs.STAGEIN_AWS_ACCESS_KEY_ID)\n        export AWS_SECRET_ACCESS_KEY=$(inputs.STAGEIN_AWS_SECRET_ACCESS_KEY)\n        url=$1\n        if curl --output /dev/null --silent --head --fail \"$url\"; then\n          echo \"URL: $url\"\n        else\n          echo \"URL does not exist: $url\"\n          exit 1\n        fi\n        Stars copy -v -rel -r 4 -o ./ --harvest $url\n  EnvVarRequirement:\n    envDef:\n      PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n  ResourceRequirement: {}"
  stageout: "cwlVersion: v1.0\nbaseCommand: ['/bin/bash', 'stageout.sh']\ndoc: \"Run Stars for staging results\"\nclass: CommandLineTool\nhints:\n  DockerRequirement:\n    dockerPull: terradue/stars:2.3.1\n  \"cwltool:Secrets\":\n    secrets:\n    - STAGEOUT_AWS_SERVICEURL\n    - STAGEOUT_AWS_REGION\n    - STAGEOUT_AWS_ACCESS_KEY_ID\n    - STAGEOUT_AWS_SECRET_ACCESS_KEY\nid: stars\narguments:\n  - copy\n  - -v\n  - -r\n  - '4'\n  - -o\n  - $( inputs.STAGEOUT_OUTPUT + \"/\" + inputs.process )\n  - -res\n  - $( inputs.process + \".res\" )\n  - valueFrom: |\n            ${\n                if( !Array.isArray(inputs.wf_outputs) ) \n                {\n                    return inputs.wf_outputs.path + \"/catalog.json\";\n                }\n                var args=[];\n                for (var i = 0; i < inputs.wf_outputs.length; i++) \n                {\n                    args.push(inputs.wf_outputs[i].path + \"/catalog.json\");\n                }\n                return args;\n            }\ninputs: \n  STAGEOUT_AWS_PROFILE:\n    type: string?\n  STAGEOUT_AWS_SERVICEURL: \n    type: string?\n  STAGEOUT_AWS_ACCESS_KEY_ID: \n    type: string?\n  STAGEOUT_AWS_SECRET_ACCESS_KEY: \n    type: string?\n  aws_profiles_location:\n    type: File?\n  STAGEOUT_OUTPUT:\n    type: string?\n  STAGEOUT_AWS_REGION:\n    type: string?\n  process:\n    type: string?\noutputs: \n  StacCatalogUri:\n    outputBinding:\n      outputEval: ${  return inputs.STAGEOUT_OUTPUT + \"/\" + inputs.process + \"/catalog.json\"; }\n    type: string\nrequirements:\n  InitialWorkDirRequirement:\n    listing:\n    - entryname: stageout.sh\n      entry: |-\n        #!/bin/bash\n        export AWS__ServiceURL=$(inputs.STAGEOUT_AWS_SERVICEURL)\n        export AWS__Region=$(inputs.STAGEOUT_AWS_REGION)\n        export AWS__AuthenticationRegion=$(inputs.STAGEOUT_AWS_REGION)\n        export AWS_ACCESS_KEY_ID=$(inputs.STAGEOUT_AWS_ACCESS_KEY_ID)\n        export AWS_SECRET_ACCESS_KEY=$(inputs.STAGEOUT_AWS_SECRET_ACCESS_KEY)\n        Stars $@\n  InlineJavascriptRequirement: {}\n  EnvVarRequirement:\n    envDef:\n      PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n  ResourceRequirement: {}"
---
# Source: zoo-project-hpgc/templates/initdb-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgresql-primary-init-scripts
data:
  1-schema.sql: "--------------------------------------------------------------------------------\n--\n-- PostgreSQL definition of tables required byt the ZOO-Kernel version >= 1.5.0\n-- if the the db-backend option is activated\n--\n-- Copyright (C) 2015 GeoLabs SARL. All rights reserved.\n-- Author: David Saggiorato <david.saggiorato@geolabs.fr>\n--\n-- Permission is hereby granted, free of charge, to any person obtaining a copy\n-- of this software and associated documentation files (the \"Software\"), to deal\n-- in the Software without restriction, including without limitation the rights\n-- to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-- copies of the Software, and to permit persons to whom the Software is\n-- furnished to do so, subject to the following conditions:\n--\n-- The above copyright notice and this permission notice shall be included in\n-- all copies or substantial portions of the Software.\n--\n-- THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-- IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-- FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-- AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-- LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-- OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n-- THE SOFTWARE.\n--\n-------------------------------------------------------------------------------- \n-- If your database is not using UTF-8 per default then uncomment the following \n-- SET client_encoding = 'UTF8';\n-------------------------------------------------------------------------------- \n-- Create a dedicated schema to store all tables\n-- Uncomment the following 2 lines to activate the schema use\n-- CREATE SCHEMA processdb;\n-- SET search_path TO processdb;\n--------------------------------------------------------------------------------\n-- Users table \n-- Used to store the user name provided in case of authentication\ncreate table users (\n       id serial PRIMARY KEY,\n       name varchar(255),\n       provider varchar(255),\n       creation_time timestamp with time zone default now(),\n       access_time timestamp with time zone default now()\n);\nINSERT INTO users (id,name,provider) VALUES (0,'anonymous','unknown');\n--------------------------------------------------------------------------------\n-- Services table\n-- Used to store information about services running asynchronously\ncreate table services (\n       osid TEXT,\n       sid TEXT,\n       uuid TEXT unique,\n       processid TEXT,\n       fstate varchar(25),\n       status TEXT,\n       response TEXT,\n       creation_time timestamp with time zone default now(),\n       start_time timestamp with time zone default now(),\n       updated_time timestamp with time zone default now(),\n       finished_time timestamp with time zone default NULL,\n       end_time timestamp with time zone default NULL,\n       progress int,\n       itype varchar(10),\n       message TEXT,\n       user_id int REFERENCES users(id) ON DELETE CASCADE\n);\n--------------------------------------------------------------------------------\n-- Responses table \n-- Used to store the response provided by a services running asynchronously\ncreate table responses (\n       uuid text references services(uuid) ON DELETE CASCADE,\n       content text,\n       creation_time timestamp with time zone default now()\n);\n--------------------------------------------------------------------------------\n-- Files table\n-- Used to store the files generated during the service execution\ncreate table files (\n       uuid TEXT references services(uuid) ON DELETE CASCADE,\n       filename text,\n       nature varchar(10),\n       name varchar(255),\n       creation_time timestamp with time zone default now(),\n       expiration_time timestamp with time zone default now() + interval '48 hours'\n);\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n-- Function to display date respecting the RFC 3339\nCREATE OR REPLACE FUNCTION display_date_rfc3339(param_in timestamp with time zone)\nRETURNS text AS\n$$\nDECLARE var_out varchar;\nBEGIN\n\tPERFORM set_config('timezone', 'UTC', true);\n\tvar_out := to_char(param_in , 'YYYY-MM-DD\"T\"HH24:MI:SS.MS\"Z\"');\n\tRETURN var_out;\nEND;\n$$ language plpgsql VOLATILE;\n--------------------------------------------------------------------------------"
  2-schema.sql: "--------------------------------------------------------------------------------\n--\n-- PostgreSQL definition of tables required byt the ZOO-Kernel version >= 1.8.0\n-- if the the rabbitmq option is activated\n--\n-- Copyright (C) 2020 GeoLabs SARL. All rights reserved.\n-- Author: Gérald Fenoy <gerald.fenoy@geolabs.fr>\n--\n-- Permission is hereby granted, free of charge, to any person obtaining a copy\n-- of this software and associated documentation files (the \"Software\"), to deal\n-- in the Software without restriction, including without limitation the rights\n-- to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-- copies of the Software, and to permit persons to whom the Software is\n-- furnished to do so, subject to the following conditions:\n--\n-- The above copyright notice and this permission notice shall be included in\n-- all copies or substantial portions of the Software.\n--\n-- THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-- IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-- FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-- AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-- LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-- OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n-- THE SOFTWARE.\n--\n-------------------------------------------------------------------------------- \n-- If your database is not using UTF-8 per default then uncomment the following \n-- SET client_encoding = 'UTF8';\n-------------------------------------------------------------------------------- \n-- Create a dedicated schema to store all tables\n-- Uncomment the following 2 lines to activate the schema use\n-- CREATE SCHEMA processdb;\n-- SET search_path TO processdb;\n--------------------------------------------------------------------------------\nCREATE TABLE workers (\n       id serial primary key,\n       uuid text,\n       pid int,\n       status int,\n       creation_time timestamp with time zone default now(),\n       UNIQUE(uuid)\n);\n\n\nCREATE OR REPLACE FUNCTION checkAvailableExecutionSlot(schema text,uuid text, pid int) RETURNS boolean AS \n$BODY$\nDECLARE\n\tres int;\n        cnt int;\nBEGIN\n        EXECUTE 'SELECT count(*) from '||schema||'.workers where uuid = '''||uuid||'''' INTO cnt;\n\tIF cnt = 0  THEN\n\t   EXECUTE 'INSERT INTO '||schema||'.workers (uuid,pid,status) VALUES ('''||uuid||''','||pid||',1)';\n\t   RETURN true;\n\tELSE\n\t   RETURN false;\n\tEND IF;\nEND;\n$BODY$\nLANGUAGE 'plpgsql' COST 100.0 SECURITY INVOKER;\n"
  3-schema.sql: "--------------------------------------------------------------------------------\n--\n-- PostgreSQL definition of tables required byt the ZOO-Kernel version >= 1.8.0\n-- if the the metadb is activated\n--\n-- Copyright (C) 2018-2022 GeoLabs SARL. All rights reserved.\n-- Author: Gérald Fenoy <gerald.fenoy@geolabs.fr>\n--\n-- Permission is hereby granted, free of charge, to any person obtaining a copy\n-- of this software and associated documentation files (the \"Software\"), to deal\n-- in the Software without restriction, including without limitation the rights\n-- to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-- copies of the Software, and to permit persons to whom the Software is\n-- furnished to do so, subject to the following conditions:\n--\n-- The above copyright notice and this permission notice shall be included in\n-- all copies or substantial portions of the Software.\n--\n-- THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-- IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-- FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-- AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-- LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-- OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n-- THE SOFTWARE.\n--\n--------------------------------------------------------------------------------\n-- If your database is not using UTF-8 per default then uncomment the following\n-- SET client_encoding = 'UTF8';\n--------------------------------------------------------------------------------\n\ncreate schema CollectionDB;\n\nset search_path = CollectionDB, pg_catalog;\n\nCREATE OR REPLACE FUNCTION update_Description() RETURNS trigger AS\n$$\nDECLARE\n\ti integer;\nBEGIN\n\tINSERT INTO CollectionDB.Descriptions (id) VALUES (NEW.id);\n\tRETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE FUNCTION is_in_ows_DataDescription(i integer) RETURNS boolean\n    LANGUAGE plpgsql\n    AS $$\nDECLARE\n        res int;\n        mymax int;\nBEGIN\n\tSELECT id from CollectionDB.ows_DataDescription where id=i INTO res ;\n\tif res is NULL then\n\t   return false;\n\telse\n\t   return true;\n\tend if;\nEND;\n$$;\n\ncreate table CollectionDB.Descriptions (\n       id serial primary key\n);\n\ncreate table CollectionDB.ows_Metadata (\n       id serial primary key,\n       title text,\n       role text,\n       href text\n);\n\ncreate table CollectionDB.DescriptionsMetadataAssignment(\n       descriptions_id int references CollectionDB.Descriptions(id) ON DELETE CASCADE,\n       metadata_id int references CollectionDB.ows_Metadata(id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.ows_Keywords (\n    id serial primary key,\n    keyword varchar\n);\n\ncreate table CollectionDB.DescriptionsKeywordsAssignment(\n       descriptions_id int references CollectionDB.Descriptions(id) ON DELETE CASCADE,\n       keywords_id int references CollectionDB.ows_Keywords(id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.ows_AdditionalParameters (\n    id serial primary key,\n    title varchar,\n    role varchar,\n    href varchar\n);\n\ncreate table CollectionDB.DescriptionsAdditionalParametersAssignment (\n       descriptions_id int references CollectionDB.Descriptions(id) ON DELETE CASCADE,\n       additional_parameters_id int references CollectionDB.ows_AdditionalParameters(id) ON DELETE CASCADE\n);\n\n--\n-- See reference for primitive datatypes\n-- https://www.w3.org/TR/xmlschema-2/#built-in-primitive-datatypes\n--\ncreate table CollectionDB.PrimitiveDataTypes (\n       id serial primary key,\n       name varchar(255)\n);\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('string');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('boolean');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('integer');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('float');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('double');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('duration');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('dateTime');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('time');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('date');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('gYearMonth');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('gYear');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('gMonthDay');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('gDay');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('gMonth');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('hexBinary');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('base64Binary');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('anyURI');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('QName');\nINSERT INTO CollectionDB.PrimitiveDataTypes (name) VALUES ('NOTATION');\n\n--\n-- List all primitive formats\n--\ncreate table CollectionDB.PrimitiveFormats (\n       id serial primary key,\n       mime_type varchar(255),\n       encoding varchar(15),\n       schema varchar(255)\n);\n\n-- https://tools.ietf.org/html/rfc4180\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding) VALUES ('text/csv','utf-8');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding) VALUES ('text/css','utf-8');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding) VALUES ('text/html','utf-8');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding) VALUES ('text/javascript','utf-8');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding) VALUES ('text/plain','utf-8');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding,schema)\n       VALUES ('text/xml','utf-8','http://schema.opengis.net/gml/3.2.1/gml.xsd');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding,schema)\n       VALUES ('text/xml','utf-8','http://schema.opengis.net/gml/3.1.0/gml.xsd');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding) VALUES ('application/gml+xml','utf-8');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding) VALUES ('application/json','utf-8');\n-- https://tools.ietf.org/html/rfc3302\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('image/tiff');\n-- https://www.ietf.org/rfc/rfc4047.txt\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('image/fits');\n-- https://tools.ietf.org/html/rfc3745\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('image/jp2');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('image/png');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('image/jpeg');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('image/gif');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('application/octet-stream');\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('application/vnd.google-earth.kml+xml');\n-- https://www.iana.org/assignments/media-types/application/zip\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type) VALUES ('application/zip');\n-- https://www.iana.org/assignments/media-types/application/xml\nINSERT INTO CollectionDB.PrimitiveFormats (mime_type,encoding) VALUES ('application/xml','utf-8');\n\ncreate table CollectionDB.ows_Format (\n    id serial primary key,\n    primitive_format_id int references CollectionDB.PrimitiveFormats(id) ON DELETE CASCADE,\n    maximum_megabytes int,\n    def boolean,\n\tuse_mapserver bool,\n\tms_styles text\n);\n\ncreate table CollectionDB.ows_DataDescription (\n    id serial primary key,\n    format_id int references CollectionDB.ows_Format(id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.PrimitiveUom (\n\tid serial primary key,\n\tuom varchar\n);\n-- source : Open Geospatial Consortium - URNs of definitions in ogc namespace\ninsert into CollectionDB.PrimitiveUom (uom) values ('degree');\ninsert into CollectionDB.PrimitiveUom (uom) values ('radian');\ninsert into CollectionDB.PrimitiveUom (uom) values ('metre');\ninsert into CollectionDB.PrimitiveUom (uom) values ('unity');\n\ncreate table CollectionDB.LiteralDataDomain (\n    possible_literal_values varchar,\n    default_value varchar,\n    data_type_id int references CollectionDB.PrimitiveDataTypes(id) ON DELETE CASCADE,\n    uom int references CollectionDB.PrimitiveUom(id) ON DELETE CASCADE,\n    def boolean\n) inherits (CollectionDB.ows_DataDescription);\nalter table CollectionDB.LiteralDataDomain add constraint literal_data_domain_id unique (id);\n\ncreate table CollectionDB.BoundingBoxData (\n    epsg int\n) inherits (CollectionDB.ows_DataDescription);\nalter table CollectionDB.BoundingBoxData add constraint bounding_box_data_id unique (id);\n\ncreate table CollectionDB.ComplexData (\n) inherits (CollectionDB.ows_DataDescription);\nalter table CollectionDB.ComplexData add constraint complex_data_id unique (id);\n\ncreate table CollectionDB.AllowedValues (\n    id serial primary key,\n    allowed_value varchar(255)\n);\n\ncreate table CollectionDB.AllowedValuesAssignment (\n    id serial primary key,\n    literal_data_domain_id int references CollectionDB.LiteralDataDomain (id) ON DELETE CASCADE,\n    allowed_value_id int references CollectionDB.AllowedValues (id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.ows_AdditionalParameter (\n    id serial primary key,\n    key varchar,\n    value varchar,\n    additional_parameters_id int references CollectionDB.ows_AdditionalParameters(id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.ows_Input (\n    id int primary key default nextval('collectiondb.descriptions_id_seq'::regclass),\n    title text,\n    abstract text,\n    identifier varchar(255),\n    min_occurs int,\n    max_occurs int\n); -- inherits (CollectionDB.Descriptions);\nalter table CollectionDB.ows_Input add constraint codb_input_id unique (id);\nCREATE TRIGGER ows_Input_proc AFTER INSERT ON CollectionDB.ows_Input FOR EACH ROW EXECUTE PROCEDURE update_Description();\n\ncreate table CollectionDB.ows_Output (\n    id int primary key default nextval('collectiondb.descriptions_id_seq'::regclass),\n    title text,\n    abstract text,\n    identifier varchar(255)\n); --inherits (CollectionDB.Descriptions);\nalter table CollectionDB.ows_Output add constraint codb_output_id unique (id);\nCREATE TRIGGER ows_Output_proc AFTER INSERT ON CollectionDB.ows_Output FOR EACH ROW EXECUTE PROCEDURE update_Description();\n\ncreate table CollectionDB.zoo_PrivateMetadata (\n    id serial primary key,\n    identifier varchar,\n    metadata_date timestamp\n);\n\ncreate table CollectionDB.ows_Process (\n    id int primary key default nextval('collectiondb.descriptions_id_seq'::regclass),\n    title text,\n    abstract text,\n    identifier varchar(255),\n    availability boolean,\n    mutable boolean,\n    process_description_xml text,\n    private_metadata_id int references CollectionDB.zoo_PrivateMetadata(id) ON DELETE CASCADE,\n    user_id int REFERENCES public.users(id) ON DELETE CASCADE\n); -- inherits (CollectionDB.Descriptions);\nalter table CollectionDB.ows_Process add constraint codb_process_id unique (id);\nalter table CollectionDB.ows_Process add constraint codb_process_identifier unique (identifier,user_id);\nCREATE TRIGGER ows_Process_proc AFTER INSERT ON CollectionDB.ows_Process FOR EACH ROW EXECUTE PROCEDURE update_Description();\n\ncreate table CollectionDB.InputInputAssignment (\n    id serial primary key,\n    parent_input int references CollectionDB.ows_Input(id) ON DELETE CASCADE,\n    child_input int references CollectionDB.ows_Input(id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.InputDataDescriptionAssignment (\n    id serial primary key,\n    input_id int references CollectionDB.ows_Input(id) ON DELETE CASCADE,\n    data_description_id int check (CollectionDB.is_in_ows_DataDescription(data_description_id))\n);\n\ncreate table CollectionDB.OutputOutputAssignment (\n    id serial primary key,\n    parent_output int references CollectionDB.ows_Output(id) ON DELETE CASCADE,\n    child_output int references CollectionDB.ows_Output(id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.OutputDataDescriptionAssignment (\n    id serial primary key,\n    output_id int references CollectionDB.ows_Output(id) ON DELETE CASCADE,\n    data_description_id int check (CollectionDB.is_in_ows_DataDescription(data_description_id))\n);\n\ncreate table CollectionDB.zoo_ServiceTypes (\n\tid serial primary key,\n\tservice_type varchar\n);\ninsert into CollectionDB.zoo_ServiceTypes (service_type) VALUES ('HPC');\ninsert into CollectionDB.zoo_ServiceTypes (service_type) VALUES ('C');\ninsert into CollectionDB.zoo_ServiceTypes (service_type) VALUES ('Java');\ninsert into CollectionDB.zoo_ServiceTypes (service_type) VALUES ('Mono');\ninsert into CollectionDB.zoo_ServiceTypes (service_type) VALUES ('JS');\ninsert into CollectionDB.zoo_ServiceTypes (service_type) VALUES ('PHP');\ninsert into CollectionDB.zoo_ServiceTypes (service_type) VALUES ('Python');\n\ninsert into CollectionDB.zoo_ServiceTypes (service_type) VALUES ('OTB');\n\ncreate table CollectionDB.zoo_DeploymentMetadata (\n    id serial primary key,\n    executable_name varchar,\n    configuration_identifier varchar,\n        service_type_id int references CollectionDB.zoo_ServiceTypes(id) ON DELETE CASCADE);\n\ncreate table CollectionDB.zoo_PrivateProcessInfo (\n    id serial primary key\n);\n\ncreate table CollectionDB.PrivateMetadataDeploymentMetadataAssignment (\n    id serial primary key,\n    private_metadata_id int references CollectionDB.zoo_PrivateMetadata(id) ON DELETE CASCADE,\n    deployment_metadata_id int references CollectionDB.zoo_DeploymentMetadata(id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.PrivateMetadataPrivateProcessInfoAssignment (\n    id serial primary key,\n    private_metadata_id int references CollectionDB.zoo_PrivateMetadata(id) ON DELETE CASCADE,\n    private_process_info_id int references CollectionDB.zoo_PrivateProcessInfo(id) ON DELETE CASCADE\n);\n\ncreate table CollectionDB.ProcessInputAssignment (\n    id serial primary key,\n    process_id int references CollectionDB.ows_Process(id) ON DELETE CASCADE,\n    input_id int references CollectionDB.ows_Input(id) ON DELETE CASCADE,\n    index int\n);\n\ncreate table CollectionDB.ProcessOutputAssignment (\n    id serial primary key,\n    process_id int references CollectionDB.ows_Process(id) ON DELETE CASCADE,\n    output_id int references CollectionDB.ows_Output(id) ON DELETE CASCADE,\n    index int\n);\n\nCREATE OR REPLACE VIEW public.ows_process AS\n       (SELECT\n\tid,\n\tidentifier,\n\ttitle,\n\tabstract,\n\t(SELECT service_type FROM CollectionDB.zoo_ServiceTypes WHERE id = (SELECT service_type_id FROM CollectionDB.zoo_DeploymentMetadata WHERE id = (SELECT deployment_metadata_id FROM CollectionDB.PrivateMetadataDeploymentmetadataAssignment WHERE private_metadata_id=(SELECT id FROM CollectionDB.zoo_PrivateMetadata WHERE id = CollectionDB.ows_Process.private_metadata_id)))) as service_type,\n\t(SELECT executable_name FROM CollectionDB.zoo_DeploymentMetadata WHERE id = (SELECT deployment_metadata_id FROM CollectionDB.PrivateMetadataDeploymentmetadataAssignment WHERE private_metadata_id=(SELECT id FROM CollectionDB.zoo_PrivateMetadata WHERE id = CollectionDB.ows_Process.private_metadata_id))) as service_provider,\n\t(SELECT configuration_identifier FROM CollectionDB.zoo_DeploymentMetadata WHERE id = (SELECT deployment_metadata_id FROM CollectionDB.PrivateMetadataDeploymentmetadataAssignment WHERE private_metadata_id=(SELECT id FROM CollectionDB.zoo_PrivateMetadata WHERE id = CollectionDB.ows_Process.private_metadata_id))) as conf_id,\n\tmutable,\n\tavailability,\n\tuser_id\n\tFROM CollectionDB.ows_Process\n\tWHERE\n\t availability\n\t);"
---
# Source: zoo-project-hpgc/templates/openapi_startup_configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-zoo-project-hpgc-startup-configmap
  namespace: zoo-project-hpgc-0.0.3.tgz
  labels:
    chart: "zoo-project-hpgc-0.0.3"
    release: my-release
    heritage: Helm
data:
  startUp.sh: "#!/bin/bash\n# Author: Gérald Fenoy\n# Copyright GeoLabs 2021\necho \"hello\"\nmkdir -p /tmp/zTmp/statusInfos\ncp /var/www/html/data/* /usr/com/zoo-project\nchown www-data:www-data -R /tmp/zTmp /usr/com/zoo-project\nchmod 777 -R /tmp/zTmp\n\nCMD=\"curl -o toto.out my-release-rabbitmq:15672\"\n$CMD\ncat toto.out\nif [ -e toto.out ]; then echo \"Should start\" ; else echo wait; sleep 1; $CMD ; fi\n\nwhile [ ! -e toto.out ]; do echo wait; sleep 1; $CMD ;  done\n\n\necho \"START FPM in 5 seconds\"\n\nsleep 5\n\ncd /usr/lib/cgi-bin\ntouch /var/log/zoofpm.log\nchown www-data:www-data /var/log/zoofpm.log\nsu www-data -s /bin/bash -c \"./zoo_loader_fpm ./main.cfg 2> /var/log/zoofpm.log >> /var/log/zoofpm.log\"\n\necho \"STARTING FPM DONE\"\n"
---
# Source: zoo-project-hpgc/templates/services-data-pv-claim.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-release-zoo-project-hpgc-processing-services
  namespace: zoo-project-hpgc-0.0.3.tgz
  labels:
    app: my-release-zoo-project-hpgc
    chart: "zoo-project-hpgc-0.0.3"
    release: my-release
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  storageClassName: "standard"
  resources:
    requests:
      storage:  "5Gi"
---
# Source: zoo-project-hpgc/templates/zoo-tmp-pv-claim.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-release-zoo-project-hpgc-tmp-folder
  namespace: zoo-project-hpgc-0.0.3.tgz
  labels:
    app: my-release-zoo-project-hpgc
    chart: "zoo-project-hpgc-0.0.3"
    release: my-release
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteMany"
  storageClassName: "standard"
  resources:
    requests:
      storage:  "2Gi"
---
# Source: zoo-project-hpgc/templates/processing-rolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-zoo-project-hpgc-processing
subjects:
  - kind: ServiceAccount
    name: my-release-zoo-project-hpgc-processing-manager
    namespace: zoo-project-hpgc-0.0.3.tgz
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
---
# Source: zoo-project-hpgc/charts/rabbitmq/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-rabbitmq-endpoint-reader
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.5.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create"]
---
# Source: zoo-project-hpgc/charts/rabbitmq/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-rabbitmq-endpoint-reader
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.5.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: my-release-rabbitmq
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-release-rabbitmq-endpoint-reader
---
# Source: zoo-project-hpgc/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql-hl
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.9
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: primary
---
# Source: zoo-project-hpgc/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.9
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: primary
---
# Source: zoo-project-hpgc/charts/rabbitmq/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-rabbitmq-headless
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.5.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  clusterIP: None
  ports:
    - name: epmd
      port: 4369
      targetPort: epmd
    - name: amqp
      port: 5672
      targetPort: amqp
    - name: dist
      port: 25672
      targetPort: dist
    - name: http-stats
      port: 15672
      targetPort: stats
  selector: 
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: my-release
  publishNotReadyAddresses: true
---
# Source: zoo-project-hpgc/charts/rabbitmq/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-rabbitmq
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.5.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: amqp
      port: 5672
      targetPort: amqp
      nodePort: null
    - name: epmd
      port: 4369
      targetPort: epmd
      nodePort: null
    - name: dist
      port: 25672
      targetPort: dist
      nodePort: null
    - name: http-stats
      port: 15672
      targetPort: stats
      nodePort: null
  selector: 
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: my-release
---
# Source: zoo-project-hpgc/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-redis-headless
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
  annotations:
    
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: my-release
---
# Source: zoo-project-hpgc/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-redis-master
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: master
---
# Source: zoo-project-hpgc/charts/redis/templates/replicas/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-redis-replicas
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: replica
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: replica
---
# Source: zoo-project-hpgc/templates/service-proxy.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-zoo-project-hpgc-kubeproxy
spec:
  type: ClusterIP
  ports:
    - port: 8001
      targetPort: 8001
      protocol: TCP
      name: http-kubeproxy
  selector:
    app.kubernetes.io/name: zoo-project-hpgc-kubeproxy
---
# Source: zoo-project-hpgc/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-zoo-project-hpgc
  labels:
    helm.sh/chart: zoo-project-hpgc-0.0.3
    app.kubernetes.io/name: zoo-project-hpgc
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.0.6"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: zoo-project-hpgc
    app.kubernetes.io/instance: my-release
---
# Source: zoo-project-hpgc/templates/deployment-proxy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-zoo-project-hpgc-kubeproxy
  labels:
    app.kubernetes.io/name: zoo-project-hpgc-kubeproxy
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: zoo-project-hpgc-kubeproxy
  template:
    metadata:
      labels:
        app.kubernetes.io/name: zoo-project-hpgc-kubeproxy
    spec:
      serviceAccountName: my-release-zoo-project-hpgc-processing-manager
      securityContext:
        {}
      containers:
        - name: my-release-zoo-project-hpgc-kubeproxy
          securityContext:
            {}
          image: eoepca/kubectl-proxy:latest
          ports:
            - containerPort: 8001
      restartPolicy: Always
---
# Source: zoo-project-hpgc/templates/zoofpm-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-zoo-project-hpgc-zoofpm
  labels:
    app.kubernetes.io/version: "0.0.6"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: zoo-project-hpgc-zoofpm
    app.kubernetes.io/instance: my-release-zoofpm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: zoo-project-hpgc-zoofpm
      app.kubernetes.io/instance: my-release-zoofpm
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: zoo-project-hpgc-zoofpm
        app.kubernetes.io/instance: my-release-zoofpm
    spec:
      serviceAccountName: my-release-zoo-project-hpgc-processing-manager
      initContainers:
        - name: init-wait-for-dependencies-zoofpm
          image: docker.io/wshihadeh/wait_for:latest
          imagePullPolicy: IfNotPresent
          command: [ "/docker-entrypoint.sh" ]
          args: [ "wait_for", "rabbitmq:my-release-rabbitmq"]
          env:
            - name: ZOO_RABBITMQ_HOST
              value: my-release-rabbitmq
      containers:
        - env:
            - name: ZOO_RABBITMQ_HOST
              value: my-release-rabbitmq
            - name: STORAGE_CLASS
              value: standard
            - name: DEFAULT_VOLUME_SIZE
              value: "10190"
            - name: DEFAULT_MAX_RAM
              value: "1024"
            - name: DEFAULT_MAX_CORES
              value: "2"
            - name: CALRISSIAN_IMAGE
              value: "terradue/calrissian:0.12.0"
            - name: HTTP_PROXY
              value: "http://my-release-zoo-project-hpgc-kubeproxy:8001"
            - name: PGHOST
              value: "my-release-postgresql-hl"
            - name: PGDATABASE
              value: "zoo"
            - name: PGPASSWORD
              value: "zoo"
            - name: PGUSER
              value: "zoo"
            - name: PGPORT
              value: "5432"


          name: zoofpm
          image: "zooproject/zoo-project:hpgc-6bc484cab9ae7ca650e4591c1cda19f70142c686"
          imagePullPolicy: IfNotPresent
          command: ["/startup.sh"]
          resources: {}
          volumeMounts:
            - name: ades-config
              mountPath: /usr/lib/cgi-bin/main.cfg
              subPath: maincfg
            - name: ades-config
              mountPath: /usr/lib/cgi-bin/oas.cfg
              subPath: oas
            - name: ades-config
              mountPath: /var/www/html/.htaccess
              subPath: htaccess
            - name: startupsh
              mountPath: /startup.sh
              subPath: startUp.sh
            - name: ades-config
              mountPath: /tmp/zTmp/cookiecutter_config.yaml
              subPath: cookiecutter_config

            - name: ades-config
              mountPath: /assets/additional_inputs.yaml
              subPath: additional_inputs
            - name: ades-config
              mountPath: /assets/pod_env_vars.yaml
              subPath: pod_env_vars
            - name: ades-config
              mountPath: /assets/pod_nodeselectors.yaml
              subPath: pod_nodeselectors
            - name: ades-config
              mountPath: /assets/pod_imagePullSecrets.yaml
              subPath: pod_imagePullSecrets

            - name: cwlwrapper-config
              mountPath: /assets/maincwl.yaml
              subPath: maincwl
            - name: cwlwrapper-config
              mountPath: /assets/maincwlmetrics.yaml
              subPath: maincwlmetrics
            - name: cwlwrapper-config
              mountPath: /assets/rules.yaml
              subPath: rules
            - name: cwlwrapper-config
              mountPath: /assets/stagein.yaml
              subPath: stagein
            - name: cwlwrapper-config
              mountPath: /assets/stageout.yaml
              subPath: stageout
            - name: ades-processing-services
              mountPath: /opt/zooservices_user
            - name: tmp-folder
              mountPath: /tmp/zTmp
      restartPolicy: Always
      volumes:
        - name: ades-config
          configMap:
            name: my-release-zoo-project-hpgc-configmap
        - name: cwlwrapper-config
          configMap:
            name: my-release-zoo-project-hpgc-cwlwrapper-configmap
        - name: startupsh
          configMap:
            name: my-release-zoo-project-hpgc-startup-configmap
            defaultMode: 0744
        - name: tmp-folder
          persistentVolumeClaim:
            claimName: my-release-zoo-project-hpgc-tmp-folder

        - name: ades-processing-services
          persistentVolumeClaim:
            claimName: my-release-zoo-project-hpgc-processing-services
status: {}
---
# Source: zoo-project-hpgc/templates/zookernel-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-zoo-project-hpgc-zookernel
  labels:
    helm.sh/chart: zoo-project-hpgc-0.0.3
    app.kubernetes.io/name: zoo-project-hpgc
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.0.6"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: zoo-project-hpgc
      app.kubernetes.io/instance: my-release
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: zoo-project-hpgc
        app.kubernetes.io/instance: my-release
    spec:
      initContainers:
        - name: init-wait-for-dependencies-zookernel
          image: docker.io/wshihadeh/wait_for:latest
          imagePullPolicy: IfNotPresent
          command: [ "/docker-entrypoint.sh" ]
          args: [ "wait_for", "rabbitmq:my-release-rabbitmq" ]
          env:
            - name: ZOO_RABBITMQ_HOST
              value: my-release-rabbitmq
      containers:
        - env:
            - name: ZOO_REDIS_HOST
              value: my-release-zoo-project-hpgc-redis-master
          name: zookernel
          image: "zooproject/zoo-project:hpgc-6bc484cab9ae7ca650e4591c1cda19f70142c686"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources: {}
          volumeMounts:
            - name: ades-config
              mountPath: /usr/lib/cgi-bin/main.cfg
              subPath: maincfg
            - name: ades-config
              mountPath: /usr/lib/cgi-bin/oas.cfg
              subPath: oas
            - name: ades-config
              mountPath: /var/www/html/.htaccess
              subPath: htaccess
            - name: ades-config
              mountPath: /tmp/zTmp/cookiecutter_config.yaml
              subPath: cookiecutter_config

            - name: ades-config
              mountPath: /assets/additional_inputs.yaml
              subPath: additional_inputs
            - name: ades-config
              mountPath: /assets/pod_env_vars.yaml
              subPath: pod_env_vars
            - name: ades-config
              mountPath: /assets/pod_nodeselectors.yaml
              subPath: pod_nodeselectors
            - name: ades-config
              mountPath: /assets/pod_imagePullSecrets.yaml
              subPath: pod_imagePullSecrets


            - name: ades-processing-services
              mountPath: /opt/zooservices_user
            - name: tmp-folder
              mountPath: /tmp/zTmp
      restartPolicy: Always
      volumes:
        - name: ades-config
          configMap:
            name: my-release-zoo-project-hpgc-configmap
        - name: tmp-folder
          persistentVolumeClaim:
            claimName: my-release-zoo-project-hpgc-tmp-folder
        - name: ades-processing-services
          persistentVolumeClaim:
            claimName: my-release-zoo-project-hpgc-processing-services
status: {}
---
# Source: zoo-project-hpgc/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-postgresql
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.9
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  replicas: 1
  serviceName: my-release-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: my-release-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-12.1.9
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
      annotations:
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      initContainers:
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:15.1.0-debian-11-r20
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "zoo"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: postgres-password
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: password
            - name: POSTGRES_DB
              value: "zoo"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "zoo" -d "dbname=zoo" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                
                - |
                  exec pg_isready -U "zoo" -d "dbname=zoo" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: custom-init-scripts
              mountPath: /docker-entrypoint-initdb.d/
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: custom-init-scripts
          configMap:
            name: postgresql-primary-init-scripts
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: zoo-project-hpgc/charts/rabbitmq/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-rabbitmq
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.5.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: my-release-rabbitmq-headless
  podManagementPolicy: OrderedReady
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: rabbitmq
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      labels:
        app.kubernetes.io/name: rabbitmq
        helm.sh/chart: rabbitmq-11.5.0
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
      annotations:
        checksum/config: 66ca1dd52cd27b424df05113613556e992bc30e708095603c7ff7cf63d212c95
        checksum/secret: be15091bdae131b4309abf4862d7e36306ccaae5cf545512b5dc4c487849eec9
    spec:
      
      serviceAccountName: my-release-rabbitmq
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: rabbitmq
                    app.kubernetes.io/instance: my-release
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      terminationGracePeriodSeconds: 120
      initContainers:
      containers:
        - name: rabbitmq
          image: docker.io/bitnami/rabbitmq:3.11.6-debian-11-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/bash
                  - -ec
                  - |
                    if [[ -f /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh ]]; then
                        /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh -t "120" -d "false"
                    else
                        rabbitmqctl stop_app
                    fi
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: K8S_SERVICE_NAME
              value: my-release-rabbitmq-headless
            - name: K8S_ADDRESS_TYPE
              value: hostname
            - name: RABBITMQ_FORCE_BOOT
              value: "no"
            - name: RABBITMQ_NODE_NAME
              value: "rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local"
            - name: K8S_HOSTNAME_SUFFIX
              value: ".$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local"
            - name: RABBITMQ_MNESIA_DIR
              value: "/bitnami/rabbitmq/mnesia/$(RABBITMQ_NODE_NAME)"
            - name: RABBITMQ_LDAP_ENABLE
              value: "no"
            - name: RABBITMQ_LOGS
              value: "-"
            - name: RABBITMQ_ULIMIT_NOFILES
              value: "65536"
            - name: RABBITMQ_USE_LONGNAME
              value: "true"
            - name: RABBITMQ_ERL_COOKIE
              valueFrom:
                secretKeyRef:
                  name: my-release-rabbitmq
                  key: rabbitmq-erlang-cookie
            - name: RABBITMQ_LOAD_DEFINITIONS
              value: "yes"
            - name: RABBITMQ_DEFINITIONS_FILE
              value: "/app/load_definition.json"
            - name: RABBITMQ_SECURE_PASSWORD
              value: "yes"
            - name: RABBITMQ_USERNAME
              value: "RABBITMQ_USERNAME"
            - name: RABBITMQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-rabbitmq
                  key: rabbitmq-password
            - name: RABBITMQ_PLUGINS
              value: "rabbitmq_management, rabbitmq_peer_discovery_k8s, rabbitmq_auth_backend_ldap"
          envFrom:
          ports:
            - name: amqp
              containerPort: 5672
            - name: dist
              containerPort: 25672
            - name: stats
              containerPort: 15672
            - name: epmd
              containerPort: 4369
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 120
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 20
            exec:
              command:
                - /bin/bash
                - -ec
                - rabbitmq-diagnostics -q ping
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 20
            exec:
              command:
                - /bin/bash
                - -ec
                - rabbitmq-diagnostics -q check_running && rabbitmq-diagnostics -q check_local_alarms
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: configuration
              mountPath: /bitnami/rabbitmq/conf
            - name: data
              mountPath: /bitnami/rabbitmq/mnesia
            - name: load-definition-volume
              mountPath: /app
              readOnly: true
      volumes:
        - name: configuration
          projected:
            sources:
              - secret:
                  name: my-release-rabbitmq-config
        - name: load-definition-volume
          secret:
            secretName: "load-definition"
  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app.kubernetes.io/name: rabbitmq
          app.kubernetes.io/instance: my-release
      spec:
        accessModes:
            - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: zoo-project-hpgc/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-redis-master
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: master
  serviceName: my-release-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis
        helm.sh/chart: redis-17.6.0
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: ec53ea48b90ba53ec690e54fb39453013c13563f00e08a6feaee677a5a36a078
        checksum/health: 345303d2132293f3a4cb915154a86c75ac44b7e4c22f522279c46bb13c0f27a4
        checksum/scripts: c567c4ae99ba0ad298b27c0ebbc888decdb9b85b441c39cc9257d2cf58a0994b
        checksum/secret: 3e1e3889743156b0735bf0ed42150b763afdaa61038666bfc59e1b839e42aa13
    spec:
      
      securityContext:
        fsGroup: 1001
      serviceAccountName: my-release-redis
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.0.8-debian-11-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc/
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: start-scripts
          configMap:
            name: my-release-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: my-release-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: my-release-redis-configuration
        - name: redis-tmp-conf
          emptyDir: {}
        - name: tmp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app.kubernetes.io/name: redis
          app.kubernetes.io/instance: my-release
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: zoo-project-hpgc/charts/redis/templates/replicas/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-redis-replicas
  namespace: "zoo-project-hpgc-0.0.3.tgz"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.6.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: replica
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: replica
  serviceName: my-release-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis
        helm.sh/chart: redis-17.6.0
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: replica
      annotations:
        checksum/configmap: ec53ea48b90ba53ec690e54fb39453013c13563f00e08a6feaee677a5a36a078
        checksum/health: 345303d2132293f3a4cb915154a86c75ac44b7e4c22f522279c46bb13c0f27a4
        checksum/scripts: c567c4ae99ba0ad298b27c0ebbc888decdb9b85b441c39cc9257d2cf58a0994b
        checksum/secret: 23e6d4dc6b0965e9f7e18c3a6fea1e6f5e81768bd8fbd661565b4ad941a18b90
    spec:
      
      securityContext:
        fsGroup: 1001
      serviceAccountName: my-release-redis
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/component: replica
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.0.8-debian-11-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-replica.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: replica
            - name: REDIS_MASTER_HOST
              value: my-release-redis-master-0.my-release-redis-headless.zoo-project-hpgc-0.0.3.tgz.svc.cluster.local
            - name: REDIS_MASTER_PORT_NUMBER
              value: "6379"
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
            - name: REDIS_MASTER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          startupProbe:
            failureThreshold: 22
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: redis
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local_and_master.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local_and_master.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc
      volumes:
        - name: start-scripts
          configMap:
            name: my-release-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: my-release-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: my-release-redis-configuration
        - name: redis-tmp-conf
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app.kubernetes.io/name: redis
          app.kubernetes.io/instance: my-release
          app.kubernetes.io/component: replica
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: zoo-project-hpgc/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-zoo-project-hpgc-test-connection"
  labels:
    helm.sh/chart: zoo-project-hpgc-0.0.3
    app.kubernetes.io/name: zoo-project-hpgc
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.0.6"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['my-release-zoo-project-hpgc:80']
  restartPolicy: Never
