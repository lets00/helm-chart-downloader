---
# Source: nautobot/charts/redis/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-release-redis
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: redis
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 6379
---
# Source: nautobot/charts/redis/templates/master/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: my-release-redis-master
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
---
# Source: nautobot/templates/service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-nautobot
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
automountServiceAccountToken: false
---
# Source: nautobot/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-postgresql
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.4.0
    helm.sh/chart: postgresql-12.12.10
type: Opaque
data:
  postgres-password: "YzZKTllQODluWQ=="
  password: "aG10Q3JXSEdiQQ=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: nautobot/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-redis
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
type: Opaque
data:
  redis-password: "Y29zNm9DMEpqZg=="
---
# Source: nautobot/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-nautobot-env
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
    app.kubernetes.io/component: nautobot
type: Opaque
data:
  NAUTOBOT_SECRET_KEY: "X05PWWxwQ0RfZ0BCVFlDQkB1bUBvRWFwTEB6eElXSkBYRkBSQDhAQHBAdnh4QEBtUTFYVEB1MEBAbEBAenRqXw=="
  NAUTOBOT_SUPERUSER_API_TOKEN: "QVFycjJHY0dOMUc1c2dBT05jamM0SkcxYUpWdE1hSlF6bTJRc1h5MQ=="
  NAUTOBOT_SUPERUSER_PASSWORD: "X3lAQEB0QDM0QE1EQE9VX0BHbEBXQFNNQDZudFJtc19AdV9kc0hAQkQ3eVZAQEBLQEBKQEhERVBISTE1QHNAQA=="
---
# Source: nautobot/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-configuration
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: nautobot/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-health
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: nautobot/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-redis-scripts
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--requirepass" "${REDIS_PASSWORD}")
    ARGS+=("--masterauth" "${REDIS_PASSWORD}")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: nautobot/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-nautobot-env
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
data:
  NAUTOBOT_ALLOWED_HOSTS: "*"
  NAUTOBOT_CREATE_SUPERUSER: "true"
  NAUTOBOT_DB_ENGINE: "django_prometheus.db.backends.postgresql"
  NAUTOBOT_DB_HOST: "my-release-postgresql"
  NAUTOBOT_DB_NAME: "nautobot"
  NAUTOBOT_DB_PORT: "5432"
  NAUTOBOT_DB_TIMEOUT: "300"
  NAUTOBOT_DB_USER: "nautobot"
  NAUTOBOT_DEBUG: "False"
  NAUTOBOT_LOG_LEVEL: "INFO"
  NAUTOBOT_METRICS_ENABLED: "True"
  NAUTOBOT_REDIS_HOST: "my-release-redis-master"
  NAUTOBOT_REDIS_PORT: "6379"
  NAUTOBOT_REDIS_USERNAME: ""
  NAUTOBOT_REDIS_SSL: "False"
  NAUTOBOT_SUPERUSER_EMAIL: "admin@example.com"
  NAUTOBOT_SUPERUSER_NAME: "admin"
---
# Source: nautobot/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-nautobot-config
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
data:
  
  uwsgi.ini: |
    [uwsgi]
    ; The IP address (typically localhost) and port that the WSGI process should listen on
    http = 0.0.0.0:8080
    https = 0.0.0.0:8443,/opt/nautobot/nautobot.crt,/opt/nautobot/nautobot.key
    
    
    ; Fail to start if any parameter in the configuration file isnâ€™t explicitly understood by uWSGI
    strict = true
    
    ; Enable master process to gracefully re-spawn and pre-fork workers
    master = true
    
    ; Allow Python app-generated threads to run
    enable-threads = true
    
    ;Try to remove all of the generated file/sockets during shutdown
    vacuum = true
    
    ; Do not use multiple interpreters, allowing only Nautobot to run
    single-interpreter = true
    
    ; Shutdown when receiving SIGTERM (default is respawn)
    die-on-term = true
    
    ; Prevents uWSGI from starting if it is unable load Nautobot (usually due to errors)
    need-app = true
    
    ; By default, uWSGI has rather verbose logging that can be noisy
    disable-logging = true
    
    ; Assert that critical 4xx and 5xx errors are still logged
    log-4xx = true
    log-5xx = true
    
    ; Enable HTTP 1.1 keepalive support
    http-keepalive = 1
    
    ;
    ; Advanced settings (disabled by default)
    ; Customize these for your environment if and only if you need them.
    ; Ref: https://uwsgi-docs.readthedocs.io/en/latest/Options.html
    ;
    
    ; Number of uWSGI workers to spawn. This should typically be 2n+1, where n is the number of CPU cores present. Default 3 as n will be >= 1
    processes = 3
    
    ; Number of uWSGI threads each worker will be pre-forked into before starting
    threads = 2
    
    ; set the socket listen queue size, in production the suggested value is 1024, however RHEL based kernels have a max of 128 by default
    ; you may need to increase the somaxconn parameter in your kernel
    listen = 128
    
    ; If using subdirectory hosting e.g. example.com/nautobot, you must uncomment this line. Otherwise you'll get double paths e.g. example.com/nautobot/nautobot/.
    ; See: https://uwsgi-docs.readthedocs.io/en/latest/Changelog-2.0.11.html#fixpathinfo-routing-action
    ; route-run = fixpathinfo:
    
    ; If hosted behind a load balancer uncomment these lines, the harakiri timeout should be greater than your load balancer timeout.
    ; Ref: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html?highlight=keepalive#http-keep-alive
    
    ; harakiri = 65
    ; add-header = Connection: Keep-Alive
    ; http-keepalive = 1
    
    ; For larger installations, certain API calls (example: Relationships, GraphQL) can have a length of query parameters that go over uWSGI default limit.
    ; Setting the buffer size to larger than default (4096) can have an impact on memory utilization, but can be set as high as the header limit of 65535.
    buffer-size = 4096
---
# Source: nautobot/templates/nginx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-nautobot-nginx-config
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
    app.kubernetes.io/component: nautobot-nginx
data:
  nautobot.conf: |-
    server {
        listen 8443 ssl http2 default_server;
        listen [::]:8443 ssl http2 default_server;
    
        server_name _;
    
        ssl_certificate /opt/nautobot_certs/nautobot.crt;
        ssl_certificate_key /opt/nautobot_certs/nautobot.key;
    
        client_max_body_size 25m;
    
        location /static/ {
            alias /opt/nautobot/static/;
        }
    
        location / {
            include uwsgi_params;
            uwsgi_pass  127.0.0.1:8001;
            uwsgi_param Host $host;
            uwsgi_param X-Real-IP $remote_addr;
            uwsgi_param X-Forwarded-For $proxy_add_x_forwarded_for;
            uwsgi_param X-Forwarded-Proto $http_x_forwarded_proto;
        }
    }
    
    server {
        listen 8080 default_server;
        listen [::]:8080 default_server;
    
        server_name _;
    
        client_max_body_size 25m;
    
        location /static/ {
            alias /opt/nautobot/static/;
        }
    
        location / {
            include uwsgi_params;
            uwsgi_pass  127.0.0.1:8001;
            uwsgi_param Host $host;
            uwsgi_param X-Real-IP $remote_addr;
            uwsgi_param X-Forwarded-For $proxy_add_x_forwarded_for;
            uwsgi_param X-Forwarded-Proto $http_x_forwarded_proto;
        }
    }
    server {
        listen 8002;
        location / {
            stub_status;
        }
    }
---
# Source: nautobot/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql-hl
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.4.0
    helm.sh/chart: postgresql-12.12.10
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: nautobot/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.4.0
    helm.sh/chart: postgresql-12.12.10
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: nautobot/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-redis-headless
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: redis
---
# Source: nautobot/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-redis-master
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: master
---
# Source: nautobot/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-nautobot-default
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
    app.kubernetes.io/component: nautobot-default
spec:
  type: ClusterIP
  ports:
    - protocol: "TCP"
      port: 443
      targetPort: "https"
      name: "https"
    - protocol: "TCP"
      port: 80
      targetPort: "http"
      name: "http"
  selector:
    app.kubernetes.io/name: nautobot
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: nautobot-default
---
# Source: nautobot/templates/celery-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-nautobot-celery-beat
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
    app.kubernetes.io/component: nautobot-celery-beat
spec:
  replicas: 1
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: nautobot
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: nautobot-celery-beat
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nautobot
        helm.sh/chart: nautobot-2.1.2
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "2.2.5"
        app.kubernetes.io/component: nautobot-celery-beat
    spec:
      serviceAccountName: my-release-nautobot
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: nautobot
                    app.kubernetes.io/component: nautobot-celery-beat
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 999
        seccompProfile:
          type: RuntimeDefault
      initContainers:
      containers:
        - name: nautobot-celery
          tty: true
          image: ghcr.io/nautobot/nautobot:2.2.5-py3.11
          imagePullPolicy: Always
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsUser: 999
          command:
            - nautobot-server
            - celery
            - beat
            - --loglevel
            - $(NAUTOBOT_LOG_LEVEL)
          env:
            - name: "NAUTOBOT_K8S_COMPONENT"
              value: "nautobot-celery-beat"
            - name: NAUTOBOT_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: password
            - name: NAUTOBOT_REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
          envFrom:
            - configMapRef:
                name: my-release-nautobot-env
            - secretRef:
                name: my-release-nautobot-env
          resources:
            limits:
              cpu: 3328m
              memory: 6656M
            requests:
              cpu: 5m
              memory: 256M
          volumeMounts:
            - name: "git-repos"
              mountPath: "/opt/nautobot/git"
      terminationGracePeriodSeconds: 30
      volumes:
        - name: "git-repos"
          emptyDir: {}
---
# Source: nautobot/templates/celery-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-nautobot-celery-default
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
    app.kubernetes.io/component: nautobot-celery-default
spec:
  replicas: 2
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: nautobot
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: nautobot-celery-default
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nautobot
        helm.sh/chart: nautobot-2.1.2
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "2.2.5"
        app.kubernetes.io/component: nautobot-celery-default
    spec:
      serviceAccountName: my-release-nautobot
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: nautobot
                    app.kubernetes.io/component: nautobot-celery-default
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 999
        seccompProfile:
          type: RuntimeDefault
      initContainers:
      containers:
        - name: nautobot-celery
          tty: true
          image: ghcr.io/nautobot/nautobot:2.2.5-py3.11
          imagePullPolicy: Always
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsUser: 999
          command:
            - nautobot-server
            - celery
            - worker
            - --loglevel
            - $(NAUTOBOT_LOG_LEVEL)
            - --queues
            - $(CELERY_TASK_QUEUES)
            - --events
          env:
            - name: "NAUTOBOT_K8S_COMPONENT"
              value: "nautobot-celery-default"
            - name: "CELERY_TASK_QUEUES"
              value: "default"
            - name: NAUTOBOT_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: password
            - name: NAUTOBOT_REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
          envFrom:
            - configMapRef:
                name: my-release-nautobot-env
            - secretRef:
                name: my-release-nautobot-env
          resources:
            limits:
              cpu: 3328m
              memory: 6656M
            requests:
              cpu: 400m
              memory: 1G
          volumeMounts:
            - name: "git-repos"
              mountPath: "/opt/nautobot/git"
      terminationGracePeriodSeconds: 30
      volumes:
        - name: "git-repos"
          emptyDir: {}
---
# Source: nautobot/templates/nautobot-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-nautobot-default
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/name: nautobot
    helm.sh/chart: nautobot-2.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.2.5"
    app.kubernetes.io/component: nautobot-default
spec:
  replicas: 2
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: nautobot
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: nautobot-default
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nautobot
        helm.sh/chart: nautobot-2.1.2
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "2.2.5"
        app.kubernetes.io/component: nautobot-default
    spec:
      serviceAccountName: my-release-nautobot
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: nautobot
                    app.kubernetes.io/component: nautobot-default
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 999
        seccompProfile:
          type: RuntimeDefault
      initContainers:
        # This init container will run post_upgrade which initializes/upgrades the DB as well as collects static files
        - name: nautobot-init
          image: ghcr.io/nautobot/nautobot:2.2.5-py3.11
          imagePullPolicy: Always
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsGroup: 999
            runAsUser: 999
          args:
            - "echo"
            - "Nautobot Initialization Done"
          env:
            - name: NAUTOBOT_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: password
            - name: NAUTOBOT_REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
            - name: NAUTOBOT_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-release-nautobot-env
                  key: NAUTOBOT_SECRET_KEY
            
          envFrom:
            - configMapRef:
                name: my-release-nautobot-env
            - secretRef:
                name: my-release-nautobot-env
          resources:
            limits:
              cpu: 1000m
              memory: 8704M
            requests:
              cpu: 300m
              memory: 1280M
          volumeMounts:
            - name: "nautobot-static"
              mountPath: "/opt/nautobot/static"
            - name: "git-repos"
              mountPath: "/opt/nautobot/git"
            - name: "nautobot-config"
              mountPath: "/opt/nautobot/uwsgi.ini"
              subPath: "uwsgi.ini"
      containers:
        - name: nautobot
          tty: true
          image: ghcr.io/nautobot/nautobot:2.2.5-py3.11
          imagePullPolicy: Always
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsGroup: 999
            runAsUser: 999
          command:
            - nautobot-server
            - start
            - --ini
            - /opt/nautobot/uwsgi.ini
          env:
            - name: "NAUTOBOT_K8S_COMPONENT"
              value: "nautobot-default"
            - name: NAUTOBOT_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: password
            - name: NAUTOBOT_REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
            - name: NAUTOBOT_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: my-release-nautobot-env
                  key: NAUTOBOT_SECRET_KEY
            
          envFrom:
            - configMapRef:
                name: my-release-nautobot-env
            - secretRef:
                name: my-release-nautobot-env
          resources:
            limits:
              cpu: 1000m
              memory: 8704M
            requests:
              cpu: 300m
              memory: 1280M
          livenessProbe:
            exec:
              command:
              - bash
              - -c
              - nautobot-server health_check
            failureThreshold: 3
            initialDelaySeconds: 3
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 10
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /health/
              port: http
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          volumeMounts:
            - name: "nautobot-static"
              mountPath: "/opt/nautobot/static"
            - name: "nautobot-media"
              mountPath: "/opt/nautobot/media"
            - name: "git-repos"
              mountPath: "/opt/nautobot/git"
            - name: "nautobot-config"
              mountPath: "/opt/nautobot/uwsgi.ini"
              subPath: "uwsgi.ini"
          ports:
            - name: "https"
              containerPort: 8443
            - name: "http"
              containerPort: 8080
            
      terminationGracePeriodSeconds: 30
      volumes:
        - name: "nautobot-static"
          emptyDir: {}
        - name: "nautobot-media"
          emptyDir: {}
        - name: "git-repos"
          emptyDir: {}
        - name: "nautobot-config"
          configMap:
            name: my-release-nautobot-config
---
# Source: nautobot/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-postgresql
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.4.0
    helm.sh/chart: postgresql-12.12.10
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: my-release-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: my-release-postgresql
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 15.4.0
        helm.sh/chart: postgresql-12.12.10
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        seccompProfile:
          type: RuntimeDefault
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:15.4.0-debian-11-r45
          imagePullPolicy: "Always"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "nautobot"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "nautobot"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "nautobot" -d "dbname=nautobot" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "nautobot" -d "dbname=nautobot" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: nautobot/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-redis-master
  namespace: "nautobot-2.1.2.tgz"
  labels:
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.19.4
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
  serviceName: my-release-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: redis
        app.kubernetes.io/version: 7.2.4
        helm.sh/chart: redis-18.19.4
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: e888d0f18b05c7bd70a8c6ee0ee303f66b2775fd57390463254884461a8cdf6c
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 560c33ff34d845009b51830c332aa05fa211444d1877d3526d3599be7543aaa5
        checksum/secret: b20aa8153e77ea79ffc43c53ae0e0595f6d4c57a949eb99e9d52ad3786dd1213
    spec:
      
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        seccompProfile:
          type: RuntimeDefault
        supplementalGroups: []
        sysctls: []
      serviceAccountName: my-release-redis-master
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      enableServiceLinks: true
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.2.4-debian-12-r9
          imagePullPolicy: "Always"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-redis
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: empty-dir
              mountPath: /opt/bitnami/redis/etc/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
      volumes:
        - name: start-scripts
          configMap:
            name: my-release-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: my-release-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: my-release-redis-configuration
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: redis-data
        labels:
          app.kubernetes.io/instance: my-release
          app.kubernetes.io/name: redis
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: nautobot/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-nautobot-default-test"
  namespace: "nautobot-2.1.2.tgz"
  labels:
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: "docker.io/library/busybox"
      imagePullPolicy: "Always"
      command: ['wget']
      args: ['-O', '/dev/null', 'my-release-nautobot-default.nautobot-2.1.2.tgz.svc:80']
      resources:
        limits:
          memory: "128Mi"
          cpu: "500m"
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        runAsUser: 10000
        capabilities:
          drop:
            - "ALL"
  restartPolicy: Never
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsNonRoot: true
