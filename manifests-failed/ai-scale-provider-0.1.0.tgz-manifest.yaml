---
# Source: ai-scale-provider/templates/base-all.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-ai-scale-provider
  labels:
    app.kubernetes.io/name: ai-scale-provider
    helm.sh/chart: ai-scale-provider-0.1.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
---
# Source: ai-scale-provider/templates/base-all.yaml
apiVersion: v1
kind: ConfigMap
immutable: false
metadata:
  name: my-release-ai-scale-provider
  labels:
    app.kubernetes.io/name: ai-scale-provider
    helm.sh/chart: ai-scale-provider-0.1.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
data:
  configs.yaml: |
    debugMode: true
    grpc:
      compression:
        enabled: true
        type: Zstd
      connection:
        host: 0.0.0.0
        insecure: true
        maxMessageSize: 30MiB
        port: 8091
        readBufferSize: 100MiB
        timeout: 15s
        writeBufferSize: 100MiB
      enabled: true
      keepalive:
        enforcementPolicy:
          minTime: 20m
          permitWithoutStream: false
        time: 5m
        timeout: 5m
      useReflection: true
    metricsSource:
      metricsSourceType: Prometheus
      prometheus:
        concurrency: 10
        httpTransport:
          maxIdleConnDuration: 1m
          readTimeout: 7s
          writeTimeout: 7s
        url: http://localhost:9090
    monitoring:
      enabled: true
    profiling:
      enabled: true
    single:
      buffer:
        readBufferSize: 4MiB
        writeBufferSize: 4MiB
      concurrency: 100000
      enabled: true
      host: 0.0.0.0
      httptransport:
        maxIdleConnDuration: 15s
        readTimeout: 7s
        writeTimeout: 7s
      name: pprof/monitoring server
      port: 8097
      tcpKeepalive:
        enabled: true
        period: 1s
  queries.yaml: |
    Cpu:
    - |-
      sum(
              node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}"})
    - |-
      sum(
              node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}"})
    - |-
      sum(
              kube_pod_container_resource_requests{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", resource="cpu"})
    - |-
      sum(
              node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}"})
          /sum(
              kube_pod_container_resource_requests{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", resource="cpu"})
    Memory:
    - |-
      sum(
              container_memory_working_set_bytes{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", container!="", image!=""})
    - |-
      sum(
              container_memory_working_set_bytes{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", container!="", image!=""})
    - |-
      sum(
              kube_pod_container_resource_requests{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", resource="memory"})
    - |-
      sum(
              container_memory_working_set_bytes{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", container!="", image!=""})
          /sum(
              kube_pod_container_resource_requests{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", resource="memory"})
    - |-
      sum(
              kube_pod_container_resource_limits{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", resource="memory"})
    - |-
      sum(
              container_memory_working_set_bytes{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", container!="", image!=""})
          /sum(
              kube_pod_container_resource_limits{cluster="{{ .Cluster }}", namespace="{{ .Namespace }}", resource="memory"})
    Network:
    - (sum(irate(container_network_receive_bytes_total{cluster="{{ .Cluster }}", namespace=~"{{
      .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (sum(irate(container_network_transmit_bytes_total{cluster="{{ .Cluster }}", namespace=~"{{
      .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (sum(irate(container_network_receive_packets_total{cluster="{{ .Cluster }}", namespace=~"{{
      .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (sum(irate(container_network_transmit_packets_total{cluster="{{ .Cluster }}", namespace=~"{{
      .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (sum(irate(container_network_receive_packets_dropped_total{cluster="{{ .Cluster
      }}", namespace=~"{{ .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (sum(irate(container_network_transmit_packets_dropped_total{cluster="{{ .Cluster
      }}", namespace=~"{{ .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (avg(irate(container_network_receive_bytes_total{cluster="{{ .Cluster }}", namespace=~"{{
      .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (avg(irate(container_network_transmit_bytes_total{cluster="{{ .Cluster }}", namespace=~"{{
      .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (sum(irate(container_network_receive_packets_dropped_total{cluster="{{ .Cluster
      }}", namespace=~"{{ .Namespace }}"}[{{ .Period.GetDurationString }}])))
    - (sum(irate(container_network_transmit_packets_droppd_total{cluster="{{ .Cluster
      }}", namespace=~"{{ .Namespace }}"}[{{ .Period.GetDurationString }}])))
    Nginx:
    - sum(irate(nginx_http_requests_total{pod=~".*{{ .Name }}.*", cluster="{{ .Cluster
      }}", namespace=~"{{ .Namespace }}"}[{{ .Period.GetDurationString }}]))
    - max(irate(nginx_http_requests_total{pod=~".*{{ .Name }}.*", cluster="{{ .Cluster
      }}", namespace=~"{{ .Namespace }}"}[{{ .Period.GetDurationString }}]))
    - min(irate(nginx_http_requests_total{pod=~".*{{ .Name }}.*", cluster="{{ .Cluster
      }}", namespace=~"{{ .Namespace }}"}[{{ .Period.GetDurationString }}]))
    ReplicasCount:
    - min(kube_{{ .Kind }}_status_replicas_ready{job="kube-state-metrics", {{ .Kind }}=~".*{{
      .Name }}.*", namespace=~"{{ .Namespace }}"}) without (instance, pod)
    - min(kube_{{ .Kind }}_status_replicas{job="kube-state-metrics", {{ .Kind }}=~".*{{
      .Name }}.*", namespace=~"{{ .Namespace }}"}) without (instance, pod)
    - max(kube_{{ .Kind }}_status_replicas_ready{job="kube-state-metrics", {{ .Kind }}=~".*{{
      .Name }}.*", namespace=~"{{ .Namespace }}"}) without (instance, pod)
    - max(kube_{{ .Kind }}_status_replicas{job="kube-state-metrics", {{ .Kind }}=~".*{{
      .Name }}.*", namespace=~"{{ .Namespace }}"}) without (instance, pod)
---
# Source: ai-scale-provider/templates/base-all.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-ai-scale-provider
  labels:
    app.kubernetes.io/name: ai-scale-provider
    helm.sh/chart: ai-scale-provider-0.1.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  ports:
    - name: grpc
      port: 8091
      protocol: TCP
      targetPort: grpc
    - name: monitoring
      port: 8097
      protocol: TCP
      targetPort: monitoring
  selector:
    app.kubernetes.io/name: ai-scale-provider
    app.kubernetes.io/instance: my-release
---
# Source: ai-scale-provider/templates/base-all.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-ai-scale-provider
  labels:
    app.kubernetes.io/name: ai-scale-provider
    helm.sh/chart: ai-scale-provider-0.1.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: ai-scale-provider
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        checksum/config: '7f658cd94aa3c460c6756d87b554def2f8e61a09a8fc6de09d40eea9a5ff338b'
      labels:
        app.kubernetes.io/name: ai-scale-provider
        helm.sh/chart: ai-scale-provider-0.1.0
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
    spec:      
      serviceAccountName: my-release-ai-scale-provider
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: ai-scale-provider
                    app.kubernetes.io/instance: my-release
                namespaces:
                  - "ai-scale-provider-0.1.0.tgz"
                topologyKey: kubernetes.io/hostname
              weight: 1
      securityContext: 
        fsGroup: 1001
      
      containers:
        -
          name: ai-scale-provider
          image: alex6021710/ai-scale-provider:latest
          imagePullPolicy: Always
          securityContext: 
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - /app
          args:
            - -conf=/etc/provider/configs/configs.yaml
            - -queries=/etc/provider/configs/queries.yaml
          resources:
            limits: {}
            requests: {}
          ports:  
            - name: grpc
              containerPort: 8091
            - name: monitoring
              containerPort: 8097
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8097
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8097
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          volumeMounts:  
            - mountPath: /etc/provider/configs
              name: configs
              readOnly: true
      volumes:   
        - configMap:
            name: 'my-release-ai-scale-provider'
          name: configs
