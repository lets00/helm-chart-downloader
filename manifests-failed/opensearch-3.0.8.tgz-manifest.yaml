---
# Source: opensearch/templates/cluster_manager/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-opensearch-cluster-manager
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: cluster_manager
automountServiceAccountToken: false
---
# Source: opensearch/templates/coordinating/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-opensearch-coordinating
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: coordinating-only
automountServiceAccountToken: false
---
# Source: opensearch/templates/data/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-opensearch-data
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: data
automountServiceAccountToken: false
---
# Source: opensearch/templates/hooks/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-opensearch-securityadmin
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: securityadmin
automountServiceAccountToken: false
---
# Source: opensearch/templates/ingest/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-opensearch-ingest
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: ingest
automountServiceAccountToken: false
---
# Source: opensearch/templates/keystore-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-opensearch-keystore
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
type: Opaque
data:
  secrets: "e30="
---
# Source: opensearch/templates/s3-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-opensearch-s3
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
type: Opaque
data:
  access_key: ""
  secret_key: ""
---
# Source: opensearch/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-opensearch
  namespace: opensearch-3.0.8.tgz
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
type: Opaque
data:
  opensearch-password: "RzZJTVgzTnpJS2VGbUVURTY1WVE3RjlmTjlQOWFYU1U="
  dashboards-password: "eWc1ZXM0cXZ6S3NQQjFLY0N1R2FIbzZSR05YVFZPRUs="
  monitoring-password: "OGM4WnZBRlZwb25hb25ZeWVQMVdNb01CN2oycnZLZUE="
---
# Source: opensearch/templates/configmap-lib-scripts.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-opensearch-lib-scripts
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
data:
  liblog.sh: |-
    #!/bin/bash
    #
    # Library for logging functions

    # Constants
    RESET='\033[0m'
    RED='\033[38;5;1m'
    GREEN='\033[38;5;2m'
    YELLOW='\033[38;5;3m'
    MAGENTA='\033[38;5;5m'
    CYAN='\033[38;5;6m'

    # Functions

    ########################
    # Print to STDERR
    # Arguments:
    #   Message to print
    # Returns:
    #   None
    #########################
    stderr_print() {
        # 'is_boolean_yes' is defined in libvalidations.sh, but depends on this file so we cannot source it
        local bool="${IMAGE_QUIET:-false}"
        # comparison is performed without regard to the case of alphabetic characters
        shopt -s nocasematch
        if ! [[ "$bool" = 1 || "$bool" =~ ^(yes|true)$ ]]; then
            printf "%b\\n" "${*}" >&2
        fi
    }

    ########################
    # Log message
    # Arguments:
    #   Message to log
    # Returns:
    #   None
    #########################
    log() {
        stderr_print "${CYAN}${MODULE:-} ${MAGENTA}$(date "+%T.%2N ")${RESET}${*}"
    }
    ########################
    # Log an 'info' message
    # Arguments:
    #   Message to log
    # Returns:
    #   None
    #########################
    info() {
        log "${GREEN}INFO ${RESET} ==> ${*}"
    }
    ########################
    # Log message
    # Arguments:
    #   Message to log
    # Returns:
    #   None
    #########################
    warn() {
        log "${YELLOW}WARN ${RESET} ==> ${*}"
    }
    ########################
    # Log an 'error' message
    # Arguments:
    #   Message to log
    # Returns:
    #   None
    #########################
    error() {
        log "${RED}ERROR${RESET} ==> ${*}"
    }
    ########################
    # Log a 'debug' message
    # Globals:
    #   IMAGE_DEBUG
    # Arguments:
    #   None
    # Returns:
    #   None
    #########################
    debug() {
        # 'is_boolean_yes' is defined in libvalidations.sh, but depends on this file so we cannot source it
        local bool="${IMAGE_DEBUG:-false}"
        # comparison is performed without regard to the case of alphabetic characters
        shopt -s nocasematch
        if [[ "$bool" = 1 || "$bool" =~ ^(yes|true)$ ]]; then
            log "${MAGENTA}DEBUG${RESET} ==> ${*}"
        fi
    }

    ########################
    # Indent a string
    # Arguments:
    #   $1 - string
    #   $2 - number of indentation characters (default: 4)
    #   $3 - indentation character (default: " ")
    # Returns:
    #   None
    #########################
    indent() {
        local string="${1:-}"
        local num="${2:?missing num}"
        local char="${3:-" "}"
        # Build the indentation unit string
        local indent_unit=""
        for ((i = 0; i < num; i++)); do
            indent_unit="${indent_unit}${char}"
        done
        # shellcheck disable=SC2001
        # Complex regex, see https://github.com/koalaman/shellcheck/wiki/SC2001#exceptions
        echo "$string" | sed "s/^/${indent_unit}/"
    }
  libopensearch.sh: |-
    #!/bin/bash
    #
    # Library for network functions

    # shellcheck disable=SC1091

    # Load Generic Libraries
    . /opt/scripts/liblog.sh

    # Functions

    ########################
    # Install Opensearch plugins
    # Globals:
    #   OPENSEARCH_*
    # Arguments:
    #   None
    # Returns:
    #   None
    #########################
    installPlugins() {
        read -r -a plugins_list <<<"$(tr ',;' ' ' <<<"$OPENSEARCH_PLUGINS")"
        local mandatory_plugins=""

        # Helper function for extracting the plugin name from a tarball name
        # Examples:
        #   get_plugin_name plugin -> plugin
        #   get_plugin_name file://plugin.zip -> plugin
        #   get_plugin_name http://plugin-0.1.2.zip -> plugin
        get_plugin_name() {
            local plugin="${1:?missing plugin}"
            # Remove any paths, and strip both the .zip extension and the version
            basename "$plugin" | sed -E -e 's/.zip$//' -e 's/-[0-9]+\.[0-9]+(\.[0-9]+){0,}$//'
        }

        # Collect plugins that should be installed offline
        read -r -a mounted_plugins <<<"$(find "$OPENSEARCH_MOUNTED_PLUGINS_DIR" -type f -name "*.zip" -print0 | xargs -0)"
        if [[ "${#mounted_plugins[@]}" -gt 0 ]]; then
            for plugin in "${mounted_plugins[@]}"; do
                plugins_list+=("file://${plugin}")
            done
        fi

        # Skip if there isn't any plugin to install
        [[ -z "${plugins_list[*]:-}" ]] && return

        # Install plugins
        debug "Installing plugins: ${plugins_list[*]}"
        for plugin in "${plugins_list[@]}"; do
            plugin_name="$(get_plugin_name "$plugin")"
            [[ -n "$mandatory_plugins" ]] && mandatory_plugins="${mandatory_plugins},${plugin_name}" || mandatory_plugins="$plugin_name"

            # Check if the plugin was already installed
            if [[ -d "${OPENSEARCH_PLUGINS_DIR}/${plugin_name}" ]]; then
                debug "Plugin already installed: ${plugin}"
                continue
            fi

            debug "Installing plugin: ${plugin}"
            if [[ "${IMAGE_DEBUG:-false}" = true ]]; then
                opensearch-plugin install -b -v "$plugin"
            else
                opensearch-plugin install -b -v "$plugin" >/dev/null 2>&1
            fi
        done
    }

    ########################
    # Set S3 credentials in Opensearch keystore
    # Globals:
    #   OPENSEARCH_*
    # Arguments:
    #   None
    # Returns:
    #   None
    #########################
    setS3Credentials() {
        #/usr/share/opensearch/bin/opensearch-plugin install --batch repository-s3

        if [[ -f "/usr/share/opensearch/config/opensearch.keystore" ]]; then
            debug "Keystore already exists"
        else
            info "Creating Opensearch keystore"
            /usr/share/opensearch/bin/opensearch-keystore create
        fi
        info "Adding S3 credentials on Opensearch keystore for s3.client.default"
        echo $AWS_ACCESS_KEY_ID | /usr/share/opensearch/bin/opensearch-keystore add --stdin s3.client.default.access_key
        echo $AWS_SECRET_ACCESS_KEY | /usr/share/opensearch/bin/opensearch-keystore add --stdin s3.client.default.secret_key
    }

    ########################
    # Set extra secrets K/V in Opensearch keystore
    # Globals:
    #   OPENSEARCH_*
    # Arguments:
    #   None
    # Returns:
    #   None
    #########################
    setExtraSecrets() {
        if [[ -f "/usr/share/opensearch/config/opensearch.keystore" ]]; then
            debug "Keystore already exists"
        else
            info "Creating Opensearch keystore"
            /usr/share/opensearch/bin/opensearch-keystore create
        fi

        if [[ ! -z "/tmp/keystore-secrets" ]]; then
            for file in $(ls /tmp/keystore-secrets); do
                IFS=$'\n'
                for line in $(cat /tmp/keystore-secrets/${file})
                do
                    if [[ "${line}" =~ ^[[:graph:]]*:[[:blank:]][[:graph:]]*$ ]]; then
                        IFS=': ' read -r KEY VALUE <<< ${line}
                        info "Adding secret value in Opensearch keystore for ${KEY}"
                        echo -n ${VALUE} | /usr/share/opensearch/bin/opensearch-keystore add -f --stdin ${KEY}
                        if [[ $? -eq 0 ]]; then
                            info "${KEY} added to Opensearch keystore"
                        else
                            error "Failed to add ${KEY} to Opensearch keystore"
                        fi
                    else
                        error "Failed to add ${line} to Opensearch keystore: wrong format, should be 'key: value'"
                    fi
                done
            done
        fi
    }

    ########################
    # Add CA certs in Opensearch truststore
    # Globals:
    #   OPENSEARCH_*
    # Arguments:
    #   None
    # Returns:
    #   None
    #########################
    addCACerts() {
        if [[ ! -z "${OPENSEARCH_CACERTS_PATH}" ]]; then
            for cert in $(ls ${OPENSEARCH_CACERTS_PATH}); do
                /usr/share/opensearch/jdk/bin/keytool -import -trustcacerts -file ${OPENSEARCH_CACERTS_PATH}/${cert} -alias $(basename "${cert}" | sed 's/\(.*\)\..*/\1/') -keystore /usr/share/opensearch/jdk/lib/security/cacerts -storepass changeit -noprompt
                if [[ $? -eq 0 ]]; then
                    info "CA cert ${OPENSEARCH_CACERTS_PATH}/${cert} added to Java truststore"
                else
                    error "Failed to add CA cert ${OPENSEARCH_CACERTS_PATH}/${cert} to Java truststore"
                fi
            done
        fi
    }
---
# Source: opensearch/templates/configmap-os.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-opensearch
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
data:
  opensearch.yml: |
    cluster.name: "opensearch"

    # Bind to all interfaces because we don't know what IP address Docker will assign to us.
    network.host: 0.0.0.0

    # # minimum_master_nodes need to be explicitly set when bound on a public IP
    # # set to 1 to allow single node clusters
    # discovery.zen.minimum_master_nodes: 1

    # Setting network.host to a non-loopback address enables the annoying bootstrap checks. "Single-node" mode disables them again.
    # discovery.type: single-node

    # Start OpenSearch Security Demo Configuration
    plugins:
      security:
        ssl:
          transport:
            pemcert_filepath: transport-tls.crt
            pemkey_filepath: transport-tls.key
            pemtrustedcas_filepath: transport-ca.crt
            enforce_hostname_verification: false
          http:
            enabled: true
            pemcert_filepath: http-tls.crt
            pemkey_filepath: http-tls.key
            pemtrustedcas_filepath: http-ca.crt
        allow_unsafe_democertificates: false
        allow_default_init_securityindex: true
        authcz:
          admin_dn:
            - CN=admin,OU=opensearchUsers,O=example,C=com
            - CN=admin,OU=opensearchUsers,O=example,C=com
        nodes_dn:
          - 'CN=*,OU=opensearch,O=example,C=com'
        audit:
          type: internal_opensearch
          #enable_rest: true
          #enable_transport: true
          #resolve_indices: true
          config:
            index: "'security-auditlog-'YYYY.MM.dd"
        enable_snapshot_restore_privilege: true
        check_snapshot_restore_write_privileges: true
        restapi:
          roles_enabled: ["all_access", "security_rest_api_access"]
        system_indices:
          enabled: true
          indices:
            [
              ".opendistro-alerting-config",
              ".opendistro-alerting-alert*",
              ".opendistro-anomaly-results*",
              ".opendistro-anomaly-detector*",
              ".opendistro-anomaly-checkpoints",
              ".opendistro-anomaly-detection-state",
              ".opendistro-reports-*",
              ".opendistro-notifications-*",
              ".opendistro-notebooks",
              ".opendistro-asynchronous-search-response*",

              ".opensearch-alerting-config",
              ".opensearch-alerting-alert*",
              ".opensearch-anomaly-results*",
              ".opensearch-anomaly-detector*",
              ".opensearch-anomaly-checkpoints",
              ".opensearch-anomaly-detection-state",
              ".opensearch-reports-*",
              ".opensearch-notifications-*",
              ".opensearch-notebooks",
              ".opensearch-asynchronous-search-response*"
            ]
---
# Source: opensearch/templates/configmap-scripts.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-opensearch-scripts
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
data:
  generate-internal-users.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    cp /usr/share/opensearch/plugins/opensearch-security/securityconfig/internal_users.yml /tmp/internal_users.yml

    TEMP_HASH=$(/usr/share/opensearch/plugins/opensearch-security/tools/hash.sh -p "${OPENSEARCH_PASSWORD}")
    OPENSEARCH_PASSWORD_HASH=$(echo $TEMP_HASH | awk '{print $(NF)}')
    sed -i "s!OPENSEARCH_PASSWORD_HASH!$OPENSEARCH_PASSWORD_HASH!" /tmp/internal_users.yml

    TEMP_HASH=$(/usr/share/opensearch/plugins/opensearch-security/tools/hash.sh -p "${DASHBOARD_PASSWORD}")
    DASHBOARDS_PASSWORD_HASH=$(echo $TEMP_HASH | awk '{print $(NF)}')
    sed -i "s!DASHBOARDS_PASSWORD_HASH!$DASHBOARDS_PASSWORD_HASH!" /tmp/internal_users.yml

    TEMP_HASH=$(/usr/share/opensearch/plugins/opensearch-security/tools/hash.sh -p "${MONITORING_PASSWORD}")
    MONITORING_PASSWORD_HASH=$(echo $TEMP_HASH | awk '{print $(NF)}')
    sed -i "s!MONITORING_PASSWORD_HASH!$MONITORING_PASSWORD_HASH!" /tmp/internal_users.yml

    /usr/share/opensearch/plugins/opensearch-security/tools/securityadmin.sh -f /tmp/internal_users.yml \
      -icl \
      -nhnv \
      -cacert /usr/share/opensearch/config/ca.crt \
      -cert /usr/share/opensearch/config/tls.crt \
      -key /usr/share/opensearch/config/tls.key \
      -h my-release-opensearch-cluster-manager-hl

  readiness-probe-script.sh: |-
    #!/usr/bin/env bash

    # fail should be called as a last resort to help the user to understand why the probe failed
    function fail {
    timestamp=$(date --iso-8601=seconds)
    echo "{\"timestamp\": \"${timestamp}\", \"message\": \"readiness probe failed\", "$1"}" | tee /proc/1/fd/2 2> /dev/null
    exit 1
    }

    READINESS_PROBE_TIMEOUT=${READINESS_PROBE_TIMEOUT:=3}

    BASIC_AUTH="-u monitoring:${MONITORING_PASSWORD}"

    # Check if we are using IPv6
    if [[ $POD_IP =~ .*:.* ]]; then
    LOOPBACK="[::1]"
    else
    LOOPBACK=127.0.0.1
    fi

    # request Opensearch on /
    # we are turning globbing off to allow for unescaped [] in case of IPv6
    ENDPOINT="${READINESS_PROBE_PROTOCOL:-https}://${LOOPBACK}:9200/"
    status=$(curl -o /dev/null -w "%{http_code}" --max-time ${READINESS_PROBE_TIMEOUT} -XGET -g -s -k ${BASIC_AUTH} $ENDPOINT)
    curl_rc=$?

    if [[ ${curl_rc} -ne 0 ]]; then
    fail "\"curl_rc\": \"${curl_rc}\""
    fi

    # ready if status code 200
    if [[ ${status} == "200" ]] || [[ ${status} == "401" ]]; then
    exit 0
    else
    fail " \"status\": \"${status}\" "
    fi
  pre-stop-hook-script.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    # This script will wait for up to $PRE_STOP_ADDITIONAL_WAIT_SECONDS before allowing termination of the Pod
    # This slows down the process shutdown and allows to make changes to the pool gracefully, without blackholing traffic when DNS
    # still contains the IP that is already inactive.
    # As this runs in parallel to grace period after which process is SIGKILLed,
    # it should be set to allow enough time for the process to gracefully terminate.
    # It allows kube-proxy to refresh its rules and remove the terminating Pod IP.
    # Kube-proxy refresh period defaults to every 30 seconds, but the operation itself can take much longer if
    # using iptables with a lot of services, in which case the default 30sec might not be enough.
    # Also gives some additional bonus time to in-flight requests to terminate, and new requests to still
    # target the Pod IP before Elasticsearch stops.
    PRE_STOP_ADDITIONAL_WAIT_SECONDS=${PRE_STOP_ADDITIONAL_WAIT_SECONDS:=50}

    sleep $PRE_STOP_ADDITIONAL_WAIT_SECONDS
  opensearch-docker-entrypoint.sh: |-
    #!/bin/bash

    # Copyright OpenSearch Contributors
    # SPDX-License-Identifier: Apache-2.0

    # This script specify the entrypoint startup actions for opensearch
    # It will start both opensearch and performance analyzer plugin cli
    # If either process failed, the entire docker container will be removed
    # in favor of a newly started container

    # Export OpenSearch Home
    export OPENSEARCH_HOME=/usr/share/opensearch
    export OPENSEARCH_PATH_CONF=$OPENSEARCH_HOME/config

    # The virtual file /proc/self/cgroup should list the current cgroup
    # membership. For each hierarchy, you can follow the cgroup path from
    # this file to the cgroup filesystem (usually /sys/fs/cgroup/) and
    # introspect the statistics for the cgroup for the given
    # hierarchy. Alas, Docker breaks this by mounting the container
    # statistics at the root while leaving the cgroup paths as the actual
    # paths. Therefore, OpenSearch provides a mechanism to override
    # reading the cgroup path from /proc/self/cgroup and instead uses the
    # cgroup path defined the JVM system property
    # opensearch.cgroups.hierarchy.override. Therefore, we set this value here so
    # that cgroup statistics are available for the container this process
    # will run in.
    export OPENSEARCH_JAVA_OPTS="-Dopensearch.cgroups.hierarchy.override=/ $OPENSEARCH_JAVA_OPTS"

    # Holds the PID of opensearch and performance analyzer processes.
    declare OPENSEARCH_PID
    declare PA_PID

    export OPENSEARCH_MOUNTED_PLUGINS_DIR="/usr/share/opensearch/plugins"
    export OPENSEARCH_PLUGINS_DIR="/usr/share/opensearch/plugins"

    # Load Generic Libraries
    . /opt/scripts/liblog.sh
    . /opt/scripts/libopensearch.sh

    # Trap function that is used to terminate opensearch and performance analyzer
    # when a relevant signal is caught.
    function terminateProcesses {
        if kill -0 $OPENSEARCH_PID >& /dev/null; then
            info "Killing opensearch process $OPENSEARCH_PID"
            kill -TERM $OPENSEARCH_PID
            wait $OPENSEARCH_PID
        fi
        if kill -0 $PA_PID >& /dev/null; then
            info "Killing performance analyzer process $PA_PID"
            kill -TERM $PA_PID
            wait $PA_PID
        fi
    }

    # Start up the opensearch and performance analyzer agent processes.
    # When either of them halts, this script exits, or we receive a SIGTERM or SIGINT signal then we want to kill both these processes.
    function runOpensearch {

        # Files created by OpenSearch should always be group writable too
        umask 0002

        if [[ "$(id -u)" == "0" ]]; then
            error "OpenSearch cannot run as root. Please start your container as another user."
            exit 1
        fi

        # Parse Docker env vars to customize OpenSearch
        #
        # e.g. Setting the env var cluster.name=testcluster
        # will cause OpenSearch to be invoked with -Ecluster.name=testcluster
        opensearch_opts=()
        while IFS='=' read -r envvar_key envvar_value
        do
            # OpenSearch settings need to have at least two dot separated lowercase
            # words, e.g. `cluster.name`, except for `processors` which we handle
            # specially
            if [[ "$envvar_key" =~ ^[a-z0-9_]+\.[a-z0-9_]+ || "$envvar_key" == "processors" ]]; then
                if [[ ! -z $envvar_value ]]; then
                opensearch_opt="-E${envvar_key}=${envvar_value}"
                opensearch_opts+=("${opensearch_opt}")
                fi
            fi
        done < <(env)

        if [[ "${OPENSEARCH_ALLOCATION_AWARENESS:-false}" = true ]]; then
            if [[ ! -z ${OPENSEARCH_TOPOLOGY_KEY} ]]; then
                debug "Getting ${OPENSEARCH_TOPOLOGY_KEY} label value for node ${WORKER_NODE_NAME} to set Allocation Awareness using kube-api"
                ZONE=$(curl -s https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_SERVICE_PORT}/api/v1/nodes/${WORKER_NODE_NAME} \
                    --header "Authorization: Bearer $(cat /run/secrets/kubernetes.io/serviceaccount/token)" \
                    --cacert /run/secrets/kubernetes.io/serviceaccount/ca.crt | grep "\"${OPENSEARCH_TOPOLOGY_KEY}" | cut -d'"' -f 4)
                if [[ ! -z ${ZONE} ]]; then
                    info "Setting node.attr.zone=${ZONE} for Allocation Awareness"
                    opensearch_opt="-Enode.attr.zone=${ZONE}"
                    opensearch_opts+=("${opensearch_opt}")
                else
                    error "Failed to gather ${OPENSEARCH_TOPOLOGY_KEY} label value for node ${WORKER_NODE_NAME} to set Allocation Awareness"
                    exit 1
                fi
            fi
        fi

        debug "Parsed options : ${opensearch_opts[@]}"
        
        addCACerts
        installPlugins

        # Enable job control so we receive SIGCHLD when a child process terminates
        set -m

        # Make sure we terminate the child processes in the event of us received TERM (e.g. "docker container stop"), INT (e.g. ctrl-C), EXIT (this script terminates for an unexpected reason), or CHLD (one of the processes terminated unexpectedly)
        trap terminateProcesses TERM INT EXIT CHLD

        # Start opensearch
        "$@" "${opensearch_opts[@]}" &
        OPENSEARCH_PID=$!

        # Start performance analyzer agent
        $OPENSEARCH_HOME/bin/opensearch-performance-analyzer/performance-analyzer-agent-cli > $OPENSEARCH_HOME/logs/performance-analyzer.log 2>&1 &
        PA_PID=$!

        # Wait for the child processes to terminate
        wait $OPENSEARCH_PID
        local opensearch_exit_code=$?
        info "OpenSearch exited with code ${opensearch_exit_code}"

        wait $PA_PID
        info "Performance analyzer exited with code $?"

        # This script should exit with the same code as the opensearch command, but
        # it would be a breaking change. Next line should be uncommented for the
        # next major release.
        # exit ${opensearch_exit_code}
    }

    # Prepend "opensearch" command if no argument was provided or if the first
    # argument looks like a flag (i.e. starts with a dash).
    if [ $# -eq 0 ] || [ "${1:0:1}" = '-' ]; then
        set -- opensearch "$@"
    fi

    if [ "$1" = "opensearch" ]; then
        # Install Opensearch plugins
        installPlugins
        # If the first argument is opensearch, then run the setup script.
        runOpensearch "$@"
    else
        # Otherwise, just exec the command.
        exec "$@"
    fi

  set-s3-repository.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    curl -X PUT -H 'Content-Type: application/json' \
      --cacert /usr/share/opensearch/config/ca.crt \
      --cert /usr/share/opensearch/config/tls.crt \
      --key /usr/share/opensearch/config/tls.key \
      -d '{ "type": "s3", "settings": { "client": "default", "bucket": "opensearch", "base_path": "snapshots" }}' \
      "https://my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local:9200/_snapshot/default"
---
# Source: opensearch/templates/hooks/configmap-securityconfig.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-opensearch-securityconfig
  namespace: opensearch-3.0.8.tgz
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
data:
  internal_users.yml: |-
    ---
    # This is the internal user database
    # The hash value is a bcrypt hash and can be generated with plugin/tools/hash.sh

    _meta:
      type: "internalusers"
      config_version: 2

    admin:
      hash: "OPENSEARCH_PASSWORD_HASH"
      reserved: true
      backend_roles:
        - "admin"
      description: "Admin user"

    dashboards:
      hash: "DASHBOARDS_PASSWORD_HASH"
      reserved: false
      backend_roles:
        - "kibana_server"
        - "dashboards_server"
      description: "User for the OpenSearch Dashboards server"

    monitoring:
      hash: "MONITORING_PASSWORD_HASH"
      reserved: true
      backend_roles:
        - "monitoring"
      description: "Monitoring user"
  config.yml: |-
    ---
    _meta:
      type: "config"
      config_version: 2
    config:
      dynamic:
        authc:
          basic_internal_auth_domain:
            authentication_backend:
              type: internal
            http_authenticator:
              challenge: false
              type: basic
            http_enabled: true
            order: 0
            transport_enabled: true
          clientcert_auth_domain:
            authentication_backend:
              type: noop
            http_authenticator:
              challenge: false
              config:
                username_attribute: cn
              type: clientcert
            http_enabled: true
            order: 1
            transport_enabled: true
        kibana:
          index: .opensearch_dashboards
          multitenancy_enabled: true
          server_username: dashboards

  roles.yml: |-
    ---
    _meta:
      type: "roles"
      config_version: 2

    monitoring:
      reserved: false
      hidden: false
      cluster_permissions:
        - "cluster_monitor"
        - "cluster:monitor/nodes/info"
      index_permissions:
        - index_patterns:
            - '*'
          allowed_actions:
            - 'indices_monitor'
            - 'indices:admin/aliases/get'
            - 'indices:admin/mappings/get'

    dashboards_server:
      reserved: true
      hidden: false
      static: true
      description: "Provide the minimum permissions for the Kibana server"
      cluster_permissions:
      - "cluster_monitor"
      - "cluster_composite_ops"
      - "manage_point_in_time"
      - "indices:admin/template*"
      - "indices:data/read/scroll*"
      index_permissions:
      - index_patterns:
        - ".kibana"
        - ".opensearch_dashboards"
        allowed_actions:
        - "indices_all"
      - index_patterns:
        - ".kibana-6"
        - ".opensearch_dashboards-6"
        allowed_actions:
        - "indices_all"
      - index_patterns:
        - ".kibana_*"
        - ".opensearch_dashboards_*"
        allowed_actions:
        - "indices_all"
      - index_patterns:
        - ".tasks"
        allowed_actions:
        - "indices_all"
      - index_patterns:
        - ".management-beats*"
        allowed_actions:
        - "indices_all"
      - index_patterns:
        - "*"
        allowed_actions:
        - "indices:admin/aliases*"


  roles_mapping.yml: |-
    ---
    _meta:
      type: "rolesmapping"
      config_version: 2

    opensearch_superadmin:
      reserved: true
      hidden: false
      backend_roles:
        - "admin"
      hosts: []
      users: []
      and_backend_roles: []
      description: "Maps admin to all_access"

    all_access:
      reserved: true
      hidden: false
      backend_roles:
        - "admin"
      hosts: []
      users: []
      and_backend_roles: []
      description: "Maps admin to all_access"

    monitoring:
      reserved: true
      hidden: false
      backend_roles:
        - "monitoring"
      hosts: []
      users:
        - "monitoring"
      and_backend_roles: []
      description: "Maps admin to monitoring"

    kibana_server:
      reserved: false
      hidden: false
      hosts: []
      users:
        - "dashboards"
      and_backend_roles: []
      description: "Maps dashboard user to kibana_server role"

    dashboards_server:
      reserved: false
      hidden: false
      hosts: []
      users:
        - "dashboards"
      and_backend_roles: []
      description: "Maps dashboard user to dashboards_server role"

  tenants.yml: |-
    ---
    _meta:
      type: "tenants"
      config_version: 2
    admin_tenant:
      reserved: false
      description: "Admin tenant"
---
# Source: opensearch/templates/cluster_manager/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-opensearch-cluster-manager-hl
  namespace: "opensearch-3.0.8.tgz"
  labels: 
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: cluster_manager
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ipFamilyPolicy: PreferDualStack
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: cluster_manager
---
# Source: opensearch/templates/coordinating/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-opensearch-coordinating-hl
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: coordinating-only
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ipFamilyPolicy: PreferDualStack
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: coordinating-only
---
# Source: opensearch/templates/data/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-opensearch-data-hl
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: data
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ipFamilyPolicy: PreferDualStack
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: data
---
# Source: opensearch/templates/ingest/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-opensearch-ingest
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: ingest
  annotations:
spec:
  type: LoadBalancer
  externalTrafficPolicy: 
  ipFamilyPolicy: PreferDualStack
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: ingest
---
# Source: opensearch/templates/ingest/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-opensearch-ingest-hl
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: ingest
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ipFamilyPolicy: PreferDualStack
  ports:
    - name: tcp-rest-api
      port: 9200
      targetPort: rest-api
    - name: tcp-transport
      port: 9300
      targetPort: transport
  selector:
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: ingest
---
# Source: opensearch/templates/cluster_manager/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-opensearch-cluster-manager
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: cluster_manager
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: cluster_manager
  podManagementPolicy: Parallel
  replicas: 3
  serviceName: my-release-opensearch-cluster-manager-hl
  template:
    metadata:
      labels:
        app.kubernetes.io/name: opensearch
        helm.sh/chart: opensearch-3.0.8
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "2.13.0"
        app.kubernetes.io/component: cluster_manager
      annotations:
        checksum/tls-transport-certificates: 72ab02a440f504436f9219b4654f81b931407c6df0d4ccb839c8fa02e509ca41
        checksum/tls-http-certificates: 3a3084037f9754424891de1f9715f91427bd68902635db7b143fbfdfd014e1dd
        checksum/tls-configmap-lib-scripts: 155f7bc251e343fee4a3692504ac16ce63ff122140e4e149503463ad1c5713d6
        checksum/tls-configmap-os: 4b566a145aa577f2adc8067e669a7966e2b9e54c4a359413cf07ce6df9d3a7d0
        checksum/tls-configmap-scripts: 31af692b8eb0a3cc253acea7f74098c097ecebd7c4bb12113a710944412e3af8
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      serviceAccountName: my-release-opensearch-cluster-manager
      securityContext:
        fsGroup: 1000
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/os-shell:12-debian-12-r19
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
          resources:
            limits: {}
            requests: {}
      containers:
        - name: opensearch
          image: docker.io/opensearchproject/opensearch:2.13.0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
            
          command:
            - "/opt/opensearch/scripts/opensearch-docker-entrypoint.sh"
          env:
            - name: IMAGE_DEBUG
              value: "false"
            - name: WORKER_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OPENSEARCH_PLUGINS
              value: "repository-s3,https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.13.0.0/prometheus-exporter-2.13.0.0.zip"
            - name: cluster.initial_cluster_manager_nodes
              value: my-release-opensearch-cluster-manager-0,my-release-opensearch-cluster-manager-1,my-release-opensearch-cluster-manager-2,
            - name: discovery.seed_hosts
              value: my-release-opensearch-cluster-manager-0.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,my-release-opensearch-cluster-manager-1.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,my-release-opensearch-cluster-manager-2.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,
            - name: cluster.name
              value: "opensearch"
            - name: OPENSEARCH_JAVA_OPTS
              value: ""
            - name: node.roles
              value: "cluster_manager"
            - name: DISABLE_INSTALL_DEMO_CONFIG
              value: "true"
            - name: READINESS_PROBE_PROTOCOL
              value: https
            - name: MONITORING_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-opensearch
                  key: monitoring-password
          ports:
            - name: rest-api
              containerPort: 9200
            - name: transport
              containerPort: 9300
          readinessProbe:
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/opensearch/scripts/readiness-probe-script.sh
          resources:
            limits: {}
            requests:
              cpu: 25m
              memory: 256Mi
          volumeMounts:
            - mountPath: /usr/share/opensearch/config/opensearch.yml
              name: config
              subPath: opensearch.yml
            - mountPath: /usr/share/opensearch/config/opensearch-security/config.yml
              name: securityconfig
              subPath: config.yml
            - name: data
              mountPath: /usr/share/opensearch/data
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: scripts
              mountPath: /opt/opensearch/scripts/
              readOnly: true
            - name: lib-scripts
              mountPath: /opt/scripts/
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: my-release-opensearch
            defaultMode: 420
        - name: securityconfig
          configMap:
            name: my-release-opensearch-securityconfig
            defaultMode: 420
        - name: opensearch-transport-certificates
          secret:
            secretName: my-release-opensearch-cluster-manager-transport-crt
            defaultMode: 420
        - name: opensearch-http-certificates
          secret:
            secretName: my-release-opensearch-cluster-manager-http-crt
            defaultMode: 420
        - name: lib-scripts
          configMap:
            name: my-release-opensearch-lib-scripts
            defaultMode: 493
        - name: scripts
          configMap:
            name: my-release-opensearch-scripts
            defaultMode: 493
  volumeClaimTemplates:
    - metadata:
        name: "data"
      spec:
        accessModes:
          - ReadWriteOnce
        
        
        resources:
          requests:
            storage: "8Gi"
---
# Source: opensearch/templates/coordinating/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-opensearch-coordinating
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: coordinating
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: coordinating
  podManagementPolicy: Parallel
  replicas: 2
  serviceName: my-release-opensearch-coordinating-hl
  template:
    metadata:
      labels:
        app.kubernetes.io/name: opensearch
        helm.sh/chart: opensearch-3.0.8
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "2.13.0"
        app.kubernetes.io/component: coordinating
      annotations:
        checksum/tls-transport-certificates: 72ab02a440f504436f9219b4654f81b931407c6df0d4ccb839c8fa02e509ca41
        checksum/tls-http-certificates: 3a3084037f9754424891de1f9715f91427bd68902635db7b143fbfdfd014e1dd
        checksum/tls-configmap-lib-scripts: 155f7bc251e343fee4a3692504ac16ce63ff122140e4e149503463ad1c5713d6
        checksum/tls-configmap-os: 4b566a145aa577f2adc8067e669a7966e2b9e54c4a359413cf07ce6df9d3a7d0
        checksum/tls-configmap-scripts: 31af692b8eb0a3cc253acea7f74098c097ecebd7c4bb12113a710944412e3af8
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      serviceAccountName: my-release-opensearch-coordinating
      securityContext:
        fsGroup: 1000
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/os-shell:12-debian-12-r19
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
          resources:
            limits: {}
            requests: {}
      containers:
        - name: opensearch
          image: docker.io/opensearchproject/opensearch:2.13.0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
          command:
            - "/opt/opensearch/scripts/opensearch-docker-entrypoint.sh"
          env:
            - name: IMAGE_DEBUG
              value: "false"
            - name: WORKER_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OPENSEARCH_PLUGINS
              value: "repository-s3,https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.13.0.0/prometheus-exporter-2.13.0.0.zip"
            - name: discovery.seed_hosts
              value: my-release-opensearch-cluster-manager-0.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,my-release-opensearch-cluster-manager-1.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,my-release-opensearch-cluster-manager-2.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,
            - name: cluster.name
              value: "opensearch"
            - name: OPENSEARCH_JAVA_OPTS
              value: ""
            - name: node.roles
              value: "remote_cluster_client"
            - name: DISABLE_INSTALL_DEMO_CONFIG
              value: "true"
            - name: READINESS_PROBE_PROTOCOL
              value: https
            - name: MONITORING_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-opensearch
                  key: monitoring-password
          ports:
            - name: rest-api
              containerPort: 9200
            - name: transport
              containerPort: 9300
          readinessProbe:
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/opensearch/scripts/readiness-probe-script.sh
          resources:
            limits: {}
            requests:
              cpu: 25m
              memory: 256Mi
          volumeMounts:
            - mountPath: /usr/share/opensearch/config/opensearch.yml
              name: config
              subPath: opensearch.yml
            - mountPath: /usr/share/opensearch/config/opensearch-security/config.yml
              name: securityconfig
              subPath: config.yml
            - name: data
              mountPath: /usr/share/opensearch/data
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: scripts
              mountPath: /opt/opensearch/scripts/
              readOnly: true
            - name: lib-scripts
              mountPath: /opt/scripts/
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: my-release-opensearch
            defaultMode: 420
        - name: securityconfig
          configMap:
            name: my-release-opensearch-securityconfig
            defaultMode: 420
        - name: opensearch-transport-certificates
          secret:
            secretName: my-release-opensearch-coordinating-transport-crt
            defaultMode: 420
        - name: opensearch-http-certificates
          secret:
            secretName: my-release-opensearch-coordinating-http-crt
            defaultMode: 420
        - name: lib-scripts
          configMap:
            name: my-release-opensearch-lib-scripts
            defaultMode: 493
        - name: scripts
          configMap:
            name: my-release-opensearch-scripts
            defaultMode: 493
        - name: "data"
          emptyDir: {}
---
# Source: opensearch/templates/data/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-opensearch-data
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: data
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: data
  podManagementPolicy: Parallel
  replicas: 2
  serviceName: my-release-opensearch-data-hl
  template:
    metadata:
      labels:
        app.kubernetes.io/name: opensearch
        helm.sh/chart: opensearch-3.0.8
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "2.13.0"
        app.kubernetes.io/component: data
      annotations:
        checksum/tls-transport-certificates: 72ab02a440f504436f9219b4654f81b931407c6df0d4ccb839c8fa02e509ca41
        checksum/tls-http-certificates: 3a3084037f9754424891de1f9715f91427bd68902635db7b143fbfdfd014e1dd
        checksum/tls-configmap-lib-scripts: 155f7bc251e343fee4a3692504ac16ce63ff122140e4e149503463ad1c5713d6
        checksum/tls-configmap-os: 4b566a145aa577f2adc8067e669a7966e2b9e54c4a359413cf07ce6df9d3a7d0
        checksum/tls-configmap-scripts: 31af692b8eb0a3cc253acea7f74098c097ecebd7c4bb12113a710944412e3af8
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      serviceAccountName: my-release-opensearch-data
      securityContext:
        fsGroup: 1000
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/os-shell:12-debian-12-r19
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
          resources:
            limits: {}
            requests: {}
      containers:
        - name: opensearch
          image: docker.io/opensearchproject/opensearch:2.13.0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
          command:
            - "/opt/opensearch/scripts/opensearch-docker-entrypoint.sh"
          env:
            - name: IMAGE_DEBUG
              value: "false"
            - name: WORKER_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OPENSEARCH_PLUGINS
              value: "repository-s3,https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.13.0.0/prometheus-exporter-2.13.0.0.zip"
            - name: discovery.seed_hosts
              value: my-release-opensearch-cluster-manager-0.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,my-release-opensearch-cluster-manager-1.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,my-release-opensearch-cluster-manager-2.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,
            - name: cluster.name
              value: "opensearch"
            - name: OPENSEARCH_JAVA_OPTS
              value: ""
            - name: node.roles
              value: "data"
            - name: DISABLE_INSTALL_DEMO_CONFIG
              value: "true"
            - name: READINESS_PROBE_PROTOCOL
              value: https
            - name: MONITORING_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-opensearch
                  key: monitoring-password
          ports:
            - name: rest-api
              containerPort: 9200
            - name: transport
              containerPort: 9300
          readinessProbe:
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/opensearch/scripts/readiness-probe-script.sh
          resources:
            limits: {}
            requests:
              cpu: 25m
              memory: 2048Mi
          volumeMounts:
            - mountPath: /usr/share/opensearch/config/opensearch.yml
              name: "config"
              subPath: opensearch.yml
            - mountPath: /usr/share/opensearch/config/opensearch-security/config.yml
              name: securityconfig
              subPath: config.yml
            - name: "data"
              mountPath: "/usr/share/opensearch/data"
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: scripts
              mountPath: /opt/opensearch/scripts/
              readOnly: true
            - name: lib-scripts
              mountPath: /opt/scripts/
              readOnly: true
      volumes:
        - name: "config"
          configMap:
            name: my-release-opensearch
            defaultMode: 420
        - name: securityconfig
          configMap:
            name: my-release-opensearch-securityconfig
            defaultMode: 420
        - name: opensearch-transport-certificates
          secret:
            secretName: my-release-opensearch-data-transport-crt
            defaultMode: 420
        - name: opensearch-http-certificates
          secret:
            secretName: my-release-opensearch-data-http-crt
            defaultMode: 420
        - name: lib-scripts
          configMap:
            name: my-release-opensearch-lib-scripts
            defaultMode: 493
        - name: scripts
          configMap:
            name: my-release-opensearch-scripts
            defaultMode: 493
  volumeClaimTemplates:
    - metadata:
        name: "data"
      spec:
        accessModes:
          - ReadWriteOnce
        
        
        resources:
          requests:
            storage: "8Gi"
---
# Source: opensearch/templates/ingest/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-opensearch-ingest
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: ingest
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: ingest
  podManagementPolicy: Parallel
  replicas: 2
  serviceName: my-release-opensearch-ingest-hl
  template:
    metadata:
      labels:
        app.kubernetes.io/name: opensearch
        helm.sh/chart: opensearch-3.0.8
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "2.13.0"
        app.kubernetes.io/component: ingest
      annotations:
        checksum/tls-transport-certificates: 72ab02a440f504436f9219b4654f81b931407c6df0d4ccb839c8fa02e509ca41
        checksum/tls-http-certificates: 3a3084037f9754424891de1f9715f91427bd68902635db7b143fbfdfd014e1dd
        checksum/tls-configmap-lib-scripts: 155f7bc251e343fee4a3692504ac16ce63ff122140e4e149503463ad1c5713d6
        checksum/tls-configmap-os: 4b566a145aa577f2adc8067e669a7966e2b9e54c4a359413cf07ce6df9d3a7d0
        checksum/tls-configmap-scripts: 31af692b8eb0a3cc253acea7f74098c097ecebd7c4bb12113a710944412e3af8
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      serviceAccountName: my-release-opensearch-ingest
      securityContext:
        fsGroup: 1000
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/os-shell:12-debian-12-r19
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
          resources:
            limits: {}
            requests: {}
      containers:
        - name: opensearch
          image: docker.io/opensearchproject/opensearch:2.13.0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
          command:
            - "/opt/opensearch/scripts/opensearch-docker-entrypoint.sh"
          env:
            - name: IMAGE_DEBUG
              value: "false"
            - name: WORKER_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OPENSEARCH_PLUGINS
              value: "repository-s3,https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.13.0.0/prometheus-exporter-2.13.0.0.zip"
            - name: discovery.seed_hosts
              value: my-release-opensearch-cluster-manager-0.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,my-release-opensearch-cluster-manager-1.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,my-release-opensearch-cluster-manager-2.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local,
            - name: cluster.name
              value: "opensearch"
            - name: OPENSEARCH_JAVA_OPTS
              value: ""
            - name: node.roles
              value: "ingest"
            - name: DISABLE_INSTALL_DEMO_CONFIG
              value: "true"
            - name: READINESS_PROBE_PROTOCOL
              value: https
            - name: MONITORING_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-opensearch
                  key: monitoring-password
          ports:
            - name: rest-api
              containerPort: 9200
            - name: transport
              containerPort: 9300
          readinessProbe:
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/opensearch/scripts/readiness-probe-script.sh
          resources:
            limits: {}
            requests:
              cpu: 25m
              memory: 256Mi
          volumeMounts:
            - mountPath: /usr/share/opensearch/config/opensearch.yml
              name: config
              subPath: opensearch.yml
            - mountPath: /usr/share/opensearch/config/opensearch-security/config.yml
              name: securityconfig
              subPath: config.yml
            - name: data
              mountPath: /usr/share/opensearch/data
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-http-certificates
              mountPath: /usr/share/opensearch/config/http-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-transport-certificates
              mountPath: /usr/share/opensearch/config/transport-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: scripts
              mountPath: /opt/opensearch/scripts/
              readOnly: true
            - name: lib-scripts
              mountPath: /opt/scripts/
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: my-release-opensearch
            defaultMode: 420
        - name: securityconfig
          configMap:
            name: my-release-opensearch-securityconfig
            defaultMode: 420
        - name: opensearch-transport-certificates
          secret:
            secretName: my-release-opensearch-ingest-transport-crt
            defaultMode: 420
        - name: opensearch-http-certificates
          secret:
            secretName: my-release-opensearch-ingest-http-crt
            defaultMode: 420
        - name: lib-scripts
          configMap:
            name: my-release-opensearch-lib-scripts
            defaultMode: 493
        - name: scripts
          configMap:
            name: my-release-opensearch-scripts
            defaultMode: 493
        - name: "data"
          emptyDir: {}
---
# Source: opensearch/templates/http-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-http-ca
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: http-ca
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: http-ca
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  isCA: true
  commonName: my-release-opensearch-http-ca
  secretName: my-release-opensearch-http-ca-crt
  privateKey:
    algorithm: RSA
    size: 4096
  duration: 87600h # 10y
  issuerRef:
    name: my-release-opensearch-self-signed
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/http-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-cluster-manager-http-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: cluster_manager
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: http
  secretName: my-release-opensearch-cluster-manager-http-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "my-release-opensearch-cluster-manager"
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  dnsNames:
    - "*.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - "my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - my-release-opensearch-cluster-manager
    - "localhost"
  ipAddresses:
    - "127.0.0.1"
    - "::1"
  usages:
    - server auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-http
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/http-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-data-http-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: data
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: http
  secretName: my-release-opensearch-data-http-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "my-release-opensearch-data"
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  dnsNames:
    - "*.my-release-opensearch-data-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - "my-release-opensearch-data-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - my-release-opensearch-data
    - "localhost"
  ipAddresses:
    - "127.0.0.1"
    - "::1"
  usages:
    - server auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-http
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/http-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-coordinating-http-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: coordinating
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: http
  secretName: my-release-opensearch-coordinating-http-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "my-release-opensearch-coordinating"
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  dnsNames:
    - "*.my-release-opensearch-coordinating.opensearch-3.0.8.tgz.svc.cluster.local"
    - "my-release-opensearch-coordinating.opensearch-3.0.8.tgz.svc.cluster.local"
    - "*.my-release-opensearch-coordinating-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - "my-release-opensearch-coordinating-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - my-release-opensearch-coordinating
    - "localhost"
  ipAddresses:
    - "127.0.0.1"
    - "::1"
  usages:
    - server auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-http
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/http-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-ingest-http-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: ingest
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: http
  secretName: my-release-opensearch-ingest-http-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "my-release-opensearch-ingest"
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  dnsNames:
    - "*.my-release-opensearch-ingest.opensearch-3.0.8.tgz.svc.cluster.local"
    - "my-release-opensearch-ingest.opensearch-3.0.8.tgz.svc.cluster.local"
    - "*.my-release-opensearch-ingest-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - "my-release-opensearch-ingest-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - my-release-opensearch-ingest
    - "localhost"
  ipAddresses:
    - "127.0.0.1"
    - "::1"
  usages:
    - server auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-http
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/http-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-admin-http-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: admin
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: http
  secretName: my-release-opensearch-admin-http-crt
  duration: 24h
  renewBefore: 1h
  commonName: "admin"
  subject:
    organizationalUnits:
      - opensearchUsers
    organizations:
      - example
    countries:
      - com
  usages:
    - client auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-http
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/http-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-dashboards-http-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: dashboards
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: http
  secretName: my-release-opensearch-dashboards-http-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "dashboards"
  subject:
    organizationalUnits:
      - opensearchUsers
    organizations:
      - example
    countries:
      - com
  usages:
    - client auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-http
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/transport-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-transport-ca
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: transport-ca
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: transport-ca
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  isCA: true
  commonName: my-release-opensearch-transport-ca
  secretName: my-release-opensearch-transport-ca-crt
  privateKey:
    algorithm: RSA
    size: 4096
  duration: 87600h # 10y
  issuerRef:
    name: my-release-opensearch-self-signed
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/transport-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-cluster-manager-transport-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: cluster_manager
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: transport
  secretName: my-release-opensearch-cluster-manager-transport-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "my-release-opensearch-cluster-manager"
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  dnsNames:
    - "*.my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local
    - "localhost"
  ipAddresses:
    - "127.0.0.1"
    - "::1"
  usages:
    - client auth
    - server auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-transport
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/transport-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-data-transport-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: data
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: transport
  secretName: my-release-opensearch-data-transport-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "my-release-opensearch-data"
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  dnsNames:
    - "*.my-release-opensearch-data-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - my-release-opensearch-data-hl.opensearch-3.0.8.tgz.svc.cluster.local
    - "localhost"
  ipAddresses:
    - "127.0.0.1"
    - "::1"
  usages:
    - client auth
    - server auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-transport
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/transport-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-coordinating-transport-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: coordinating
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: transport
  secretName: my-release-opensearch-coordinating-transport-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "my-release-opensearch-coordinating"
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  dnsNames:
    - "*.my-release-opensearch-coordinating-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - my-release-opensearch-coordinating-hl.opensearch-3.0.8.tgz.svc.cluster.local
    - "localhost"
  ipAddresses:
    - "127.0.0.1"
    - "::1"
  usages:
    - client auth
    - server auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-transport
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/transport-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-opensearch-ingest-transport-crt
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: ingest
spec:
  secretTemplate:
    labels:
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: transport
  secretName: my-release-opensearch-ingest-transport-crt
  duration: 4320h # 180d
  renewBefore: 2160h # 90d
  commonName: "my-release-opensearch-ingest"
  subject:
    organizationalUnits:
      - opensearch
    organizations:
      - example
    countries:
      - com
  dnsNames:
    - "*.my-release-opensearch-ingest-hl.opensearch-3.0.8.tgz.svc.cluster.local"
    - my-release-opensearch-ingest-hl.opensearch-3.0.8.tgz.svc.cluster.local
    - "localhost"
  ipAddresses:
    - "127.0.0.1"
    - "::1"
  usages:
    - client auth
    - server auth
  privateKey:
    algorithm: RSA
    encoding: PKCS8
    size: 2048
  issuerRef:
    name: my-release-opensearch-transport
    kind: Issuer
    group: cert-manager.io
---
# Source: opensearch/templates/ca-issuer.yaml
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: my-release-opensearch-self-signed
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: self-signed-issuer
spec:
  selfSigned: {}
---
# Source: opensearch/templates/http-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: my-release-opensearch-http
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: issuer
spec:
  ca:
    secretName: my-release-opensearch-http-ca-crt
---
# Source: opensearch/templates/transport-certificates.yaml
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: my-release-opensearch-transport
  namespace: "opensearch-3.0.8.tgz"
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: transport-issuer
spec:
  ca:
    secretName: my-release-opensearch-transport-ca-crt
---
# Source: opensearch/templates/hooks/job.install.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-release-opensearch-securityadmin
  labels:
    app.kubernetes.io/name: opensearch
    helm.sh/chart: opensearch-3.0.8
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "2.13.0"
    app.kubernetes.io/component: securityadmin
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-weight": "1"
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/name: opensearch
        helm.sh/chart: opensearch-3.0.8
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "2.13.0"
        app.kubernetes.io/component: securityadmin
    spec:
      restartPolicy: Never
      serviceAccountName: my-release-opensearch-securityadmin
      securityContext:
        fsGroup: 1000
      containers:
        - name: securityadmin
          image: docker.io/opensearchproject/opensearch:2.13.0
          imagePullPolicy: "IfNotPresent"
          command: [ "/tmp/generate-internal-users.sh" ]
          resources:
            limits: {}
            requests: {}
          env:
            - name: OPENSEARCH_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-opensearch
                  key: opensearch-password
            - name: DASHBOARD_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-opensearch
                  key: dashboards-password
            - name: MONITORING_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-opensearch
                  key: monitoring-password
          volumeMounts:
            - name: securityconfig
              mountPath: /usr/share/opensearch/plugins/opensearch-security/securityconfig
            - name: scripts
              mountPath: /tmp/generate-internal-users.sh
              subPath: generate-internal-users.sh
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/ca.crt
              subPath: ca.crt
              readOnly: true
        - name: roles-mapping
          image: docker.io/opensearchproject/opensearch:2.13.0
          imagePullPolicy: "IfNotPresent"
          command: [ "/usr/share/opensearch/plugins/opensearch-security/tools/securityadmin.sh" ]
          args: 
            #- "-cd"
            - "-f"
            - "/usr/share/opensearch/plugins/opensearch-security/securityconfig/roles_mapping.yml"
            - "-icl"
            - "-nhnv"
            - "-cacert"
            - "/usr/share/opensearch/config/ca.crt"
            - "-cert"
            - "/usr/share/opensearch/config/tls.crt"
            - "-key"
            - "/usr/share/opensearch/config/tls.key"
            - "-h"
            - "my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local"
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: securityconfig
              mountPath: /usr/share/opensearch/plugins/opensearch-security/securityconfig
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/ca.crt
              subPath: ca.crt
              readOnly: true
        - name: roles
          image: docker.io/opensearchproject/opensearch:2.13.0
          imagePullPolicy: "IfNotPresent"
          command: [ "/usr/share/opensearch/plugins/opensearch-security/tools/securityadmin.sh" ]
          args: 
            #- "-cd"
            - "-f"
            - "/usr/share/opensearch/plugins/opensearch-security/securityconfig/roles.yml"
            - "-icl"
            - "-nhnv"
            - "-cacert"
            - "/usr/share/opensearch/config/ca.crt"
            - "-cert"
            - "/usr/share/opensearch/config/tls.crt"
            - "-key"
            - "/usr/share/opensearch/config/tls.key"
            - "-h"
            - "my-release-opensearch-cluster-manager-hl.opensearch-3.0.8.tgz.svc.cluster.local"
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: securityconfig
              mountPath: /usr/share/opensearch/plugins/opensearch-security/securityconfig
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/tls.key
              subPath: tls.key
              readOnly: true
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: opensearch-admin-certificates
              mountPath: /usr/share/opensearch/config/ca.crt
              subPath: ca.crt
              readOnly: true
      volumes:
        - name: securityconfig
          configMap:
            name: my-release-opensearch-securityconfig
        - name: scripts
          configMap:
            name: my-release-opensearch-scripts
            defaultMode: 493
        - name: opensearch-admin-certificates
          secret:
            secretName: my-release-opensearch-admin-http-crt
            defaultMode: 420
