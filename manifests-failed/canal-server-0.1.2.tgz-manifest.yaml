---
# Source: canal-server/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-canal-server-cm
data:
  example-instance.properties: |
    #################################################
    ## mysql serverId , v1.0.26+ will autoGen
    #canal.instance.mysql.slaveId=
    # enable gtid use true/false
    canal.instance.gtidon=false
    # position info
    canal.instance.master.address=127.0.0.1:3306
    canal.instance.master.journal.name=
    canal.instance.master.position=
    canal.instance.master.timestamp=
    canal.instance.master.gtid=
    
    # rds oss binlog
    canal.instance.rds.accesskey=
    canal.instance.rds.secretkey=
    canal.instance.rds.instanceId=
    
    # table meta tsdb info
    canal.instance.tsdb.enable=true
    #canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb?characterEncoding=utf-8&autoReconnect=true&rewriteBatchedStatements=true&serverTimezone=UTC
    #canal.instance.tsdb.dbUsername=canal
    #canal.instance.tsdb.dbPassword=canal
    
    ## Standby mysql instance
    canal.instance.standby.address = 127.0.0.1:3306
    canal.instance.standby.journal.name=
    canal.instance.standby.position=
    canal.instance.standby.timestamp=
    canal.instance.standby.gtid=
    
    ## heartbeat instance HA config
    canal.instance.detecting.enable=true
    #canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()
    canal.instance.detecting.sql=select 1
    canal.instance.detecting.interval.time=3
    canal.instance.detecting.retry.threshold=3
    canal.instance.detecting.heartbeatHaEnable=true
    
    
    # username/password
    canal.instance.dbUsername=canal
    canal.instance.dbPassword=canal
    canal.instance.connectionCharset=UTF-8
    
    # enable druid Decrypt database password
    canal.instance.enableDruid=false
    #canal.instance.pwdPublicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5/zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2/JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ==
    
    # table regex
    canal.instance.filter.regex=".*\\..*"
    
    # table black regex
    canal.instance.filter.black.regex="mysql\\.slave_.*"
    
    # table field filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)
    #canal.instance.filter.field=test1.t_product:id/subject/keywords,test2.t_company:id/name/contact/ch
    
    # table field black filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)
    #canal.instance.filter.black.field=test1.t_product:subject/product_image,test2.t_company:id/name/contact/ch
    
    # mq config
    canal.mq.topic=example
    
    # dynamic topic route by schema or table regex
    #canal.mq.dynamicTopic=mytest1.user,topic2:mytest2\\..*,.*\\..*
    canal.mq.partition=0
    
    # hash partition config
    #canal.mq.enableDynamicQueuePartition=false
    #canal.mq.partitionsNum=3
    #canal.mq.dynamicTopicPartitionNum=test.*:4,mycanal:6
    #canal.mq.partitionHash=test.table:id^name,.*\\..*
    #################################################
  canal.properties: |
    #################################################
    #########     common argument       #############
    #################################################
    # tcp bind ip
    canal.ip=
    # register ip to zookeeper
    canal.register.ip=
    canal.port=11111
    canal.metrics.pull.port=11112
    
    # canal instance user/passwd
    # canal.user = canal
    # canal.passwd = E3619321C1A937C46A0D8BD1DAC39F93B27D4458
    
    # canal admin config
    #canal.admin.manager = 127.0.0.1:8089
    canal.admin.port=11110
    canal.admin.user=${CANAL_ADMIN_USER:admin}
    canal.admin.passwd=${CANAL_ADMIN_CIPHERTEXT_PASSWORD:4ACFE3202A5FF5CF467898FC58AAB1D615029441}
    
    # admin auto register
    #canal.admin.register.auto = true
    #canal.admin.register.cluster =
    #canal.admin.register.name =
    canal.zkServers=my-release-zookeeper:2181
    
    # flush data to zk
    canal.zookeeper.flush.period=1000
    canal.withoutNetty=false
    
    # tcp, kafka, rocketMQ, rabbitMQ, pulsarMQ
    canal.serverMode=tcp
    
    # flush meta cursor/parse position to file
    canal.file.data.dir=/data
    canal.file.flush.period=1000
    
    ## memory store RingBuffer size, should be Math.pow(2,n)
    canal.instance.memory.buffer.size=16384
    ## memory store RingBuffer used memory unit size , default 1kb
    canal.instance.memory.buffer.memunit=1024
    
    ## meory store gets mode used MEMSIZE or ITEMSIZE
    canal.instance.memory.batch.mode=MEMSIZE
    canal.instance.memory.rawEntry=true
    
    ## detecing config
    canal.instance.detecting.enable=false
    #canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()
    canal.instance.detecting.sql=select 1
    canal.instance.detecting.interval.time=3
    canal.instance.detecting.retry.threshold=3
    canal.instance.detecting.heartbeatHaEnable=false
    
    # support maximum transaction size, more than the size of the transaction will be cut into multiple transactions delivery
    canal.instance.transaction.size=1024
    
    # mysql fallback connected to new master should fallback times
    canal.instance.fallbackIntervalInSeconds=60
    
    # network config
    canal.instance.network.receiveBufferSize=16384
    canal.instance.network.sendBufferSize=16384
    canal.instance.network.soTimeout=30
    
    # binlog filter config
    canal.instance.filter.druid.ddl=true
    canal.instance.filter.query.dcl=false
    canal.instance.filter.query.dml=false
    canal.instance.filter.query.ddl=false
    canal.instance.filter.table.error=false
    canal.instance.filter.rows=false
    canal.instance.filter.transaction.entry=false
    canal.instance.filter.dml.insert=false
    canal.instance.filter.dml.update=false
    canal.instance.filter.dml.delete=false
    
    # binlog format/image check
    canal.instance.binlog.format=ROW,STATEMENT,MIXED
    canal.instance.binlog.image=FULL,MINIMAL,NOBLOB
    
    # binlog ddl isolation
    canal.instance.get.ddl.isolation=false
    
    # parallel parser config
    canal.instance.parser.parallel=true
    
    ## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()
    canal.instance.parser.parallelThreadSize = 4
    
    ## disruptor ringbuffer size, must be power of 2
    canal.instance.parser.parallelBufferSize=256
    
    # table meta tsdb info
    canal.instance.tsdb.enable=true
    canal.instance.tsdb.dir=${canal.file.data.dir:../conf}/${canal.instance.destination:}
    canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb?characterEncoding=utf-8&autoReconnect=true&rewriteBatchedStatements=true&serverTimezone=UTC
    canal.instance.tsdb.dbUsername=canal
    canal.instance.tsdb.dbPassword=canal
    
    
    # dump snapshot interval, default 24 hour
    canal.instance.tsdb.snapshot.interval=24
    
    # purge snapshot expire , default 360 hour(15 days)
    canal.instance.tsdb.snapshot.expire=360
    
    #####################################################
    #############     destinations          #############
    #####################################################
    canal.destinations=example
    # conf root dir
    canal.conf.dir=../conf
    
    # auto scan instance dir add/remove and start/stop instance
    canal.auto.scan=true
    canal.auto.scan.interval=5
    
    # set this value to 'true' means that when binlog pos not found, skip to latest.
    # WARN: pls keep 'false' in production env, or if you know what you want.
    canal.auto.reset.latest.pos.mode=false
    canal.instance.tsdb.spring.xml=classpath:spring/tsdb/mysql-tsdb.xml
    canal.instance.global.mode=spring
    canal.instance.global.lazy=false
    canal.instance.global.manager.address=${canal.admin.manager}
    canal.instance.global.spring.xml = classpath:spring/default-instance.xml
    #canal.instance.global.spring.xml = classpath:spring/memory-instance.xml
    
    ##################################################
    #########         MQ Properties      #############
    ##################################################
    # aliyun ak/sk , support rds/mq
    canal.aliyun.accessKey=
    canal.aliyun.secretKey=
    canal.aliyun.uid=
    canal.mq.flatMessage=true
    canal.mq.canalBatchSize=50
    canal.mq.canalGetTimeout=100
    
    # Set this value to "cloud", if you want open message trace feature in aliyun.
    canal.mq.accessChannel=local
    canal.mq.database.hash=true
    canal.mq.send.thread.size=30
    canal.mq.build.thread.size=8
    
    ##################################################
    #########          Kafka             #############
    ##################################################
    kafka.bootstrap.servers=127.0.0.1:9092
    kafka.acks=all
    kafka.compression.type=none
    kafka.batch.size=16384
    kafka.linger.ms=1
    kafka.max.request.size=1048576
    kafka.buffer.memory=33554432
    kafka.max.in.flight.requests.per.connection=1
    kafka.retries=0
    kafka.kerberos.enable=false
    kafka.kerberos.krb5.file="../conf/kerberos/krb5.conf"
    kafka.kerberos.jaas.file="../conf/kerberos/jaas.conf"
    
    ##################################################
    #########         RocketMQ           #############
    ##################################################
    rocketmq.producer.group=test
    rocketmq.enable.message.trace=false
    rocketmq.customized.trace.topic=
    rocketmq.namespace=
    rocketmq.namesrv.addr=127.0.0.1:9876
    rocketmq.retry.times.when.send.failed=0
    rocketmq.vip.channel.enabled=false
    rocketmq.tag=
    
    ##################################################
    #########         RabbitMQ           #############
    ##################################################
    rabbitmq.host=
    rabbitmq.virtual.host=
    rabbitmq.exchange=
    rabbitmq.username=
    rabbitmq.password=
    rabbitmq.deliveryMode=
    
    ##################################################
    #########           Pulsar           #############
    ##################################################
    pulsarmq.serverUrl=
    pulsarmq.roleToken=
    pulsarmq.topicTenantPrefix=
---
# Source: canal-server/charts/zookeeper/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-zookeeper-headless
  namespace: canal-server-0.1.2.tgz
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.6.1
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    
    - name: tcp-client
      port: 2181
      targetPort: client
    
    
    - name: follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: zookeeper
---
# Source: canal-server/charts/zookeeper/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-zookeeper
  namespace: canal-server-0.1.2.tgz
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.6.1
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  ports:
    
    - name: tcp-client
      port: 2181
      targetPort: client
      nodePort: null
    
    
    - name: follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: zookeeper
---
# Source: canal-server/templates/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-canal-server-headless
  labels:
    app.kubernetes.io/name: canal-server
    helm.sh/chart: canal-server-0.1.2
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: canal-server
    helm.sh/chart: canal-server-0.1.2
    app.kubernetes.io/name: canal-server
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.6"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 11111
      targetPort: tcp-canal
      protocol: TCP
      name: tcp-canal
    - port: 11110
      targetPort: tcp-admin
      protocol: TCP
      name: tcp-admin
    - port: 11112
      targetPort: http-metrics
      protocol: TCP
      name: http-metrics
  selector:
    app.kubernetes.io/name: canal-server
    app.kubernetes.io/instance: my-release
---
# Source: canal-server/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-canal-server
  labels:
    helm.sh/chart: canal-server-0.1.2
    app.kubernetes.io/name: canal-server
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.6"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 11111
      targetPort: tcp-canal
      protocol: TCP
      name: tcp-canal
    - port: 11110
      targetPort: tcp-admin
      protocol: TCP
      name: tcp-admin
    - port: 11112
      targetPort: http-metrics
      protocol: TCP
      name: http-metrics
  selector:
    app.kubernetes.io/name: canal-server
    app.kubernetes.io/instance: my-release
---
# Source: canal-server/charts/zookeeper/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-zookeeper
  namespace: canal-server-0.1.2.tgz
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.6.1
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
    role: zookeeper
spec:
  serviceName: my-release-zookeeper-headless
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: zookeeper
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: zookeeper
  template:
    metadata:
      name: my-release-zookeeper
      labels:
        app.kubernetes.io/name: zookeeper
        helm.sh/chart: zookeeper-7.6.1
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: zookeeper
    spec:
      
      serviceAccountName: default
      securityContext:
        fsGroup: 1001
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zookeeper
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/component: zookeeper
                namespaces:
                  - "canal-server-0.1.2.tgz"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      containers:
        - name: zookeeper
          image: docker.io/bitnami/zookeeper:3.7.0-debian-10-r257
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - bash
            - -ec
            - |
                # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
                # check ZOO_SERVER_ID in persistent volume via myid
                # if not present, set based on POD hostname
                if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
                  export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
                else
                  HOSTNAME=`hostname -s`
                  if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
                    ORD=${BASH_REMATCH[2]}
                    export ZOO_SERVER_ID=$((ORD + 1 ))
                  else
                    echo "Failed to get index from hostname $HOST"
                    exit 1
                  fi
                fi
                exec /entrypoint.sh /run.sh
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: ZOO_DATA_LOG_DIR
              value: ""
            - name: ZOO_PORT_NUMBER
              value: "2181"
            - name: ZOO_TICK_TIME
              value: "2000"
            - name: ZOO_INIT_LIMIT
              value: "10"
            - name: ZOO_SYNC_LIMIT
              value: "5"
            - name: ZOO_PRE_ALLOC_SIZE
              value: "65536"
            - name: ZOO_SNAPCOUNT
              value: "100000"
            - name: ZOO_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOO_4LW_COMMANDS_WHITELIST
              value: "srvr, mntr, ruok"
            - name: ZOO_LISTEN_ALLIPS_ENABLED
              value: "no"
            - name: ZOO_AUTOPURGE_INTERVAL
              value: "0"
            - name: ZOO_AUTOPURGE_RETAIN_COUNT
              value: "3"
            - name: ZOO_MAX_SESSION_TIMEOUT
              value: "40000"
            - name: ZOO_SERVERS
              value: my-release-zookeeper-0.my-release-zookeeper-headless.canal-server-0.1.2.tgz.svc.cluster.local:2888:3888::1 
            - name: ZOO_ENABLE_AUTH
              value: "no"
            - name: ZOO_HEAP_SIZE
              value: "1024"
            - name: ZOO_LOG_LEVEL
              value: "ERROR"
            - name: ALLOW_ANONYMOUS_LOGIN
              value: "yes"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
          ports:
            - name: client
              containerPort: 2181
            - name: follower
              containerPort: 2888
            - name: election
              containerPort: 3888
          livenessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: data
              mountPath: /bitnami/zookeeper
      volumes:
  volumeClaimTemplates:
    - metadata:
        name: data
        annotations:
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: canal-server/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-canal-server
  labels:
    helm.sh/chart: canal-server-0.1.2
    app.kubernetes.io/name: canal-server
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.6"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: canal-server
      app.kubernetes.io/instance: my-release
  serviceName: my-release-canal-server-headless
  template:
    metadata:
      labels:
        app.kubernetes.io/name: canal-server
        app.kubernetes.io/instance: my-release
    spec:
      serviceAccountName: default
      initContainers:
        - name: wait-for-zookeeper
          image: docker.io/bitnami/zookeeper:3.7.0-debian-10-r257
          imagePullPolicy: Always
          command: [ "/bin/bash", "-c", 'echo "ruok" | timeout 2 nc -w 2 my-release-zookeeper 2181 | grep imok' ]
      containers:
        - name: canal-server
          securityContext:
            {}
          image: "ghcr.io/dellnoantechnp/canal-server:v1.1.6"
          imagePullPolicy: IfNotPresent
          ports:
            - name: tcp-canal
              containerPort: 11111
              protocol: TCP
            - name: tcp-admin
              containerPort: 11110
              protocol: TCP
            - name: http-metrics
              containerPort: 11112
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http-metrics
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /
              port: http-metrics
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 5
          env:
            - name: IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: CANAL_HEAP_SIZE
              value: "1024"
            - name: ENV_DESTINATIONS
              value: example
          envFrom:
          resources:
            limits: {}
            requests: {}
          volumeMounts:            
            - mountPath: /app/canal-server/conf/canal.properties
              subPath: canal.properties
              name: config            
            - mountPath: /app/canal-server/conf/example/instance.properties
              subPath: example-instance.properties
              name: config
      volumes:
        - name: config
          configMap:
            name: my-release-canal-server-cm
---
# Source: canal-server/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-canal-server-test-connection"
  labels:
    helm.sh/chart: canal-server-0.1.2
    app.kubernetes.io/name: canal-server
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.6"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['my-release-canal-server:']
      he1x1_string: my-release-zookeeper
  restartPolicy: Never
