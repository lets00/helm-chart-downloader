---
# Source: oathkeeper/charts/oathkeeper-maester/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-oathkeeper-maester-account
  namespace:  oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/name: oathkeeper-maester
    helm.sh/chart: oathkeeper-maester-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.1.8"
    app.kubernetes.io/managed-by: Helm
---
# Source: oathkeeper/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-oathkeeper
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/name: oathkeeper
    helm.sh/chart: oathkeeper-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.40.7"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: false
---
# Source: oathkeeper/templates/configmap-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-oathkeeper-config
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/name: oathkeeper
    helm.sh/chart: oathkeeper-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.40.7"
    app.kubernetes.io/managed-by: Helm
data:
  "config.yaml": |
    access_rules:
      repositories:
      - file:///etc/rules/access-rules.json
    serve:
      api:
        port: 4456
      prometheus:
        port: 9000
      proxy:
        port: 4455
---
# Source: oathkeeper/templates/configmap-rules.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-oathkeeper-rules
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/name: oathkeeper
    helm.sh/chart: oathkeeper-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.40.7"
    app.kubernetes.io/managed-by: Helm
data:
  "access-rules.json": |-
    []
---
# Source: oathkeeper/charts/oathkeeper-maester/templates/rbac.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-oathkeeper-maester-role
rules:
  - apiGroups: ["oathkeeper.ory.sh"]
    resources: ["rules"]
    verbs: ["*"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "list", "watch", "create", "patch", "update"]
    # TODO, fix controller call from all namespaces to single namespace
    # resourceNames:
    #   - ory-oathkeeper-rules
---
# Source: oathkeeper/charts/oathkeeper-maester/templates/rbac.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-oathkeeper-maester-role-binding
subjects:
  - kind: ServiceAccount
    name: my-release-oathkeeper-maester-account # Service account assigned to the controller pod.
    namespace:  oathkeeper-0.44.0.tgz
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-release-oathkeeper-maester-role
---
# Source: oathkeeper/templates/service-api.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-oathkeeper-api
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/component: api
    app.kubernetes.io/name: oathkeeper
    helm.sh/chart: oathkeeper-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.40.7"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 4456
      targetPort: http-api
      protocol: TCP
      name: http 
  selector:
    app.kubernetes.io/name: oathkeeper
    app.kubernetes.io/instance: my-release
---
# Source: oathkeeper/templates/service-metrics.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-oathkeeper-metrics
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/component: metrics
    app.kubernetes.io/name: oathkeeper
    helm.sh/chart: oathkeeper-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.40.7"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http-metrics
      protocol: TCP
      name: http 
  selector:
    app.kubernetes.io/name: oathkeeper
    app.kubernetes.io/instance: my-release
---
# Source: oathkeeper/templates/service-proxy.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-oathkeeper-proxy
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/component: proxy
    app.kubernetes.io/name: oathkeeper
    helm.sh/chart: oathkeeper-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.40.7"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 4455
      targetPort: http-proxy
      protocol: TCP
      name: http 
  selector:
    app.kubernetes.io/name: oathkeeper
    app.kubernetes.io/instance: my-release
---
# Source: oathkeeper/charts/oathkeeper-maester/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-oathkeeper-maester
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/name: oathkeeper-maester
    helm.sh/chart: oathkeeper-maester-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.1.8"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 5
  selector:
    matchLabels:
      control-plane: controller-manager
      app.kubernetes.io/name: my-release-oathkeeper-maester
      app.kubernetes.io/instance: my-release
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        control-plane: controller-manager
        app.kubernetes.io/name: my-release-oathkeeper-maester
        app.kubernetes.io/instance: my-release
      annotations:
    spec:
      terminationGracePeriodSeconds: 60
      containers:
        - name: oathkeeper-maester
          image: "oryd/oathkeeper-maester:v0.1.10-amd64"
          imagePullPolicy: IfNotPresent
          command:
            - /manager
          args:
            - --metrics-addr=0.0.0.0:8080
            - controller
            - --rulesConfigmapName=my-release-rules
            - --rulesConfigmapNamespace=oathkeeper-0.44.0.tgz
          env:
          resources:
            {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seLinuxOptions:
              level: s0:c123,c456
            seccompProfile:
              type: RuntimeDefault
      serviceAccountName: my-release-oathkeeper-maester-account
      automountServiceAccountToken: true
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      securityContext:
        fsGroup: 65534
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      nodeSelector:
---
# Source: oathkeeper/templates/deployment-controller.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-oathkeeper
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/name: oathkeeper
    helm.sh/chart: oathkeeper-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.40.7"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  replicas: 1
  revisionHistoryLimit: 5
  strategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: oathkeeper
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      labels:
        app.kubernetes.io/name: oathkeeper
        helm.sh/chart: oathkeeper-0.44.0
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/version: "v0.40.7"
        app.kubernetes.io/managed-by: Helm
      annotations:        
        checksum/oathkeeper-config: acddad1332cb24f65ba7e5a174dca592d585bc60f860675b91536ce1109c393c
        checksum/oathkeeper-rules: ffd3c5eb4024562eee47d5216926ffc3f52bd4ffef6de94fe7e2256f8a2babb5
    spec:
      volumes:
        - name: oathkeeper-config-volume
          configMap:
            name: my-release-oathkeeper-config
        - name: oathkeeper-rules-volume
          configMap:
            name: my-release-oathkeeper-rules
      serviceAccountName: my-release-oathkeeper
      automountServiceAccountToken: true
      initContainers:
      terminationGracePeriodSeconds: 60
      containers:
        - name: oathkeeper
          image: "oryd/oathkeeper:v0.40.7"
          imagePullPolicy: IfNotPresent
          command: 
            - "oathkeeper"
          args:
            - "serve"
            - "--config" 
            - "/etc/config/config.yaml"
          env:
          volumeMounts:
            - name: oathkeeper-config-volume
              mountPath: /etc/config
              readOnly: true
            - name: oathkeeper-rules-volume
              mountPath: /etc/rules
              readOnly: true
          ports:
            - name: http-api
              containerPort: 4456
              protocol: TCP
            - name: http-proxy
              containerPort: 4455
              protocol: TCP
            - name: http-metrics
              protocol: TCP
              containerPort: 9000
          lifecycle:
            {}
          livenessProbe:
            httpGet:
              path: /health/alive
              port: http-api
              httpHeaders:
                - name: Host
                  value: '127.0.0.1'
            failureThreshold: 5
            initialDelaySeconds: 5
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health/ready
              port: http-api
              httpHeaders:
                - name: Host
                  value: '127.0.0.1'
            failureThreshold: 5
            initialDelaySeconds: 5
            periodSeconds: 10
          startupProbe:
            httpGet:
              path: /health/ready
              port: http-api
              httpHeaders:
                - name: Host
                  value: '127.0.0.1'
            failureThreshold: 60
            periodSeconds: 1
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seLinuxOptions:
              level: s0:c123,c456
            seccompProfile:
              type: RuntimeDefault
      securityContext:
        fsGroup: 65534
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
---
# Source: oathkeeper/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-oathkeeper-test-connection"
  namespace: oathkeeper-0.44.0.tgz
  labels:
    app.kubernetes.io/name: oathkeeper
    helm.sh/chart: oathkeeper-0.44.0
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.40.7"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
    - name: liveness-probe
      image: "busybox:1"
      command: ['wget']
      args:  ['http://my-release-oathkeeper-api:4456/health/alive']
    - name: readiness-probe
      image: "busybox:1"
      command: ['wget']
      args:  ['http://my-release-oathkeeper-api:4456/health/ready']
  restartPolicy: Never
