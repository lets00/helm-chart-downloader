---
# Source: kubecache/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-kubecache
  labels:
    helm.sh/chart: kubecache-0.6.0
    app.kubernetes.io/name: kubecache
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.6.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: kubecache/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-kubecache
data:
  AUTOMEMLIMIT_DEBUG: "true"
  OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger-collector:14268
  OTEL_PROPAGATORS: b3multi
  OTEL_TRACES_EXPORTER: jaeger
  OTEL_TRACES_SAMPLER: parentbased_traceidratio
  OTEL_TRACES_SAMPLER_ARG: "0.01"
  OTELCONFIG_EXPORTER: jaeger
---
# Source: kubecache/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-release-kubecache
rules:
- apiGroups:
  - ""
  resources:
  - 'pods'
  verbs:
  - 'get'
  - 'list'
  - 'watch'
---
# Source: kubecache/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-release-kubecache
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-release-kubecache
subjects:
- kind: ServiceAccount
  name: my-release-kubecache
  namespace: default
---
# Source: kubecache/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-kubecache
  labels:
    helm.sh/chart: kubecache-0.6.0
    app.kubernetes.io/name: kubecache
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.6.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9000
      targetPort: 8080
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: kubecache
    app.kubernetes.io/instance: my-release
---
# Source: kubecache/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-kubecache
  labels:
    helm.sh/chart: kubecache-0.6.0
    app.kubernetes.io/name: kubecache
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.6.0"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: kubecache
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        rollme: "qaSrU"
        prometheus.io/path: /metrics
        prometheus.io/port: "3000"
        prometheus.io/scrape: "true"
        sidecar.istio.io/inject: "true"
        sidecar.istio.io/interceptionMode: TPROXY
      labels:
        app.kubernetes.io/name: kubecache
        app.kubernetes.io/instance: my-release
        app: kubecache
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: ScheduleAnyway
        labelSelector:
          matchLabels:
            app.kubernetes.io/instance: my-release
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
        labelSelector:
          matchLabels:
            app.kubernetes.io/instance: my-release
      serviceAccountName: my-release-kubecache
      securityContext:
        {}
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      containers:
        - name: my-release
          securityContext:
            {}
          image: "udhos/kubecache:0.6.0"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 9000
              protocol: TCP
          envFrom:
          - configMapRef:
              name: my-release-kubecache
          startupProbe:
            # must initialize within 3*100=300 seconds
            httpGet:
              path: /health
              port: 8888
            periodSeconds: 3
            failureThreshold: 100
          readinessProbe:
            # not ready after 10*6=60 seconds without success
            httpGet:
              path: /health
              port: 8888
              scheme: HTTP
            periodSeconds: 10
            failureThreshold: 6
            successThreshold: 1
            timeoutSeconds: 5
          livenessProbe:
            # kill after 20*6=120 seconds without success
            httpGet:
              path: /health
              port: 8888
              scheme: HTTP
            periodSeconds: 20
            failureThreshold: 6
            successThreshold: 1
            timeoutSeconds: 10            
          resources:
            limits:
              cpu: 2000m
              ephemeral-storage: 200Mi
              memory: 400Mi
            requests:
              cpu: 300m
              ephemeral-storage: 200Mi
              memory: 200Mi
---
# Source: kubecache/templates/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-release-kubecache
  labels:
    helm.sh/chart: kubecache-0.6.0
    app.kubernetes.io/name: kubecache
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.6.0"
    app.kubernetes.io/managed-by: Helm
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-release-kubecache
  minReplicas: 1
  maxReplicas: 100
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        averageUtilization: 80
        type: Utilization
---
# Source: kubecache/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-kubecache-test-connection"
  labels:
    helm.sh/chart: kubecache-0.6.0
    app.kubernetes.io/name: kubecache
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.6.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['my-release-kubecache:9000']
  restartPolicy: Never
