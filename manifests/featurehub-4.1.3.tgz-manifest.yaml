---
# Source: featurehub/charts/nats/templates/pod-disruption-budget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: nats
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nats
    app.kubernetes.io/version: 2.10.5
    helm.sh/chart: nats-1.1.5
  name: my-release-nats
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: nats
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: nats
---
# Source: featurehub/templates/dacha/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-featurehub-dacha
  annotations:
    argocd.argoproj.io/sync-wave: "22"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-dacha
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: my-release-featurehub-dacha
      app.kubernetes.io/instance: my-release
---
# Source: featurehub/templates/edge/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-featurehub-edge
  annotations:
    argocd.argoproj.io/sync-wave: "22"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-edge
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: my-release-featurehub-edge
      app.kubernetes.io/instance: my-release
---
# Source: featurehub/templates/management-repository/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-featurehub-management-repository
  annotations:
    argocd.argoproj.io/sync-wave: "22"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-management-repository
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: my-release-featurehub-management-repository
      app.kubernetes.io/instance: my-release
---
# Source: featurehub/templates/dacha/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-featurehub-dacha
  annotations:
    argocd.argoproj.io/sync-wave: "1"
---
# Source: featurehub/templates/edge/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-featurehub-edge
  annotations:
    argocd.argoproj.io/sync-wave: "1"
---
# Source: featurehub/templates/management-repository/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-featurehub-management-repository
  annotations:
    argocd.argoproj.io/sync-wave: "1"
---
# Source: featurehub/charts/nats/templates/nats-box/contexts-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: nats-box
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nats
    app.kubernetes.io/version: 2.10.5
    helm.sh/chart: nats-1.1.5
  name: my-release-nats-box-contexts
stringData:
  default.json: |
    {
      "url": "nats://my-release-nats"
    }
type: Opaque
---
# Source: featurehub/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.13
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  postgres-password: "cG9zdGdyZXNxbA=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: featurehub/charts/nats/templates/config-map.yaml
apiVersion: v1
data:
  nats.conf: |
    {
      "http_port": 8222,
      "lame_duck_duration": "30s",
      "lame_duck_grace_period": "10s",
      "pid_file": "/var/run/nats/nats.pid",
      "port": 4222,
      "server_name": $SERVER_NAME
    }
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: nats
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nats
    app.kubernetes.io/version: 2.10.5
    helm.sh/chart: nats-1.1.5
  name: my-release-nats-config
---
# Source: featurehub/charts/postgresql/templates/primary/initialization-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-postgresql-init-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.13
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
data:
  featurehub.sql: |-
    CREATE USER featurehub PASSWORD 'featurehub' LOGIN;
    CREATE DATABASE featurehub;
    GRANT ALL PRIVILEGES ON DATABASE featurehub TO featurehub;
    \connect featurehub
    GRANT ALL ON SCHEMA public TO featurehub;
---
# Source: featurehub/templates/common/configmap-global-common-config-extra.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-featurehub-global-extra-log4j2-xml
  annotations:
    argocd.argoproj.io/sync-wave: "1"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-management-repository
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
data:
  log4j2.xml:  |-
    <Configuration packages="cd.connect.logging" monitorInterval="30" verbose="true">
       <Appenders>
         <Console name="STDOUT" target="SYSTEM_OUT">
           <ConnectJsonLayout/>
         </Console>
       </Appenders>
  
       <Loggers>
         <AsyncLogger name="io.featurehub" level="debug"/>
         <!--
         <AsyncLogger name="io.ebean.SQL" level="trace"/>
         <AsyncLogger name="io.ebean.TXN" level="trace"/>
         <AsyncLogger name="io.ebean.SUM" level="trace"/>
         <AsyncLogger name="io.ebean.DDL" level="trace"/>
         <AsyncLogger name="io.ebean.cache.QUERY" level="trace"/>
         <AsyncLogger name="io.ebean.cache.BEAN" level="trace"/>
         <AsyncLogger name="io.ebean.cache.COLL" level="trace"/>
         <AsyncLogger name="io.ebean.cache.NATKEY" level="trace"/>
  
         <AsyncLogger name="jersey-logging" level="trace"/>
         <AsyncLogger name="io.featurehub.db" level="trace"/>
         -->
         <AsyncLogger name="io.featurehub.edge.features" level="debug"/>
  
       <AsyncLogger name="net.stickycode" level="warn"/>
       <AsyncLogger name="org.glassfish.jersey.server.wadl" level="error"/>
       <AsyncLogger name="io.avaje.config"  level="warn"/>
       <AsyncLogger name="org.hibernate" level="error"/>
  
  
       <AsyncRoot level="info">
           <AppenderRef ref="STDOUT"/>
         </AsyncRoot>
       </Loggers>
    </Configuration>
---
# Source: featurehub/templates/common/configmap-global-common-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-featurehub-global-common-config
  annotations:
    argocd.argoproj.io/sync-wave: "1"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-management-repository
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
data:
  common.properties: |-
    nats.urls=nats://featurehub-nats
---
# Source: featurehub/templates/dacha/configmap-app-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-featurehub-dacha-app-config
  annotations:
    argocd.argoproj.io/sync-wave: "1"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-dacha
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
data:
  application.properties: |-
    dacha1.enabled=false
    dacha2.enabled=true
    monitor.port=8701
    server.port=8600
    cache.pool-size=10
    management-repository.url=http://featurehub-management-repository:8701
---
# Source: featurehub/templates/edge/configmap-app-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-featurehub-edge-app-config
  annotations:
    argocd.argoproj.io/sync-wave: "1"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-edge
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
data:
  application.properties: |-
    dacha1.enabled=false
    dacha2.enabled=true
    monitor.port=8701
    server.port=8553
    dacha.timeout.read=12000
    dacha.url.default=http://featurehub-dacha:8600
    listen.pool-size=30
    maxSlots=30
    server.gracePeriodInSeconds=10
    update.pool-size=30
---
# Source: featurehub/templates/management-repository/configmap-app-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-featurehub-management-repository-app-config
  annotations:
    argocd.argoproj.io/sync-wave: "1"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-management-repository
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
data:
  application.properties: |-
    monitor.port=8701
    server.port=8085
    run.nginx=true
    dacha1.enabled=false
    dacha2.enabled=true
    db.connections=20
    db.password=featurehub
    db.url=jdbc:postgresql://featurehub-postgresql:5432/featurehub
    db.username=featurehub
    portfolio.admin.group.suffix=Administrators
---
# Source: featurehub/charts/nats/templates/headless-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: nats
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nats
    app.kubernetes.io/version: 2.10.5
    helm.sh/chart: nats-1.1.5
  name: my-release-nats-headless
spec:
  clusterIP: None
  ports:
  - appProtocol: tcp
    name: nats
    port: 4222
    targetPort: nats
  - appProtocol: http
    name: monitor
    port: 8222
    targetPort: monitor
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: nats
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: nats
---
# Source: featurehub/charts/nats/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: nats
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nats
    app.kubernetes.io/version: 2.10.5
    helm.sh/chart: nats-1.1.5
  name: my-release-nats
spec:
  ports:
  - appProtocol: tcp
    name: nats
    port: 4222
    targetPort: nats
  selector:
    app.kubernetes.io/component: nats
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/name: nats
---
# Source: featurehub/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.13
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: primary
---
# Source: featurehub/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.13
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: primary
---
# Source: featurehub/templates/dacha/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-featurehub-dacha
  annotations:
    argocd.argoproj.io/sync-wave: "15"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-dacha
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8600
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: my-release-featurehub-dacha
    app.kubernetes.io/instance: my-release
---
# Source: featurehub/templates/edge/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-featurehub-edge
  annotations:
    argocd.argoproj.io/sync-wave: "15"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-edge
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8553
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: my-release-featurehub-edge
    app.kubernetes.io/instance: my-release
---
# Source: featurehub/templates/management-repository/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-featurehub-management-repository
  annotations:
    argocd.argoproj.io/sync-wave: "15"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-management-repository
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8085
      targetPort: http
      protocol: TCP
      name: http
    - port: 8701
      targetPort: metrics
      protocol: TCP
      name: metrics
  selector:
    app.kubernetes.io/name: my-release-featurehub-management-repository
    app.kubernetes.io/instance: my-release
---
# Source: featurehub/charts/nats/templates/nats-box/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: nats-box
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nats
    app.kubernetes.io/version: 2.10.5
    helm.sh/chart: nats-1.1.5
  name: my-release-nats-box
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: nats-box
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: nats
  template:
    metadata:
      labels:
        app.kubernetes.io/component: nats-box
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: nats
        app.kubernetes.io/version: 2.10.5
        helm.sh/chart: nats-1.1.5
    spec:
      containers:
      - args:
        - trap true INT TERM; sleep infinity & wait
        command:
        - sh
        - -ec
        - |
          work_dir="$(pwd)"
          mkdir -p "$XDG_CONFIG_HOME/nats"
          cd "$XDG_CONFIG_HOME/nats"
          if ! [ -s context ]; then
            ln -s /etc/nats-contexts context
          fi
          if ! [ -f context.txt ]; then
            echo -n "default" > context.txt
          fi
          cd "$work_dir"
          exec sh -ec "$0"
        image: natsio/nats-box:0.14.1
        name: nats-box
        volumeMounts:
        - mountPath: /etc/nats-contexts
          name: contexts
      enableServiceLinks: false
      volumes:
      - name: contexts
        secret:
          secretName: my-release-nats-box-contexts
---
# Source: featurehub/templates/dacha/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-featurehub-dacha
  annotations:
    argocd.argoproj.io/sync-wave: "20"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-dacha
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: my-release-featurehub-dacha
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        checksum/dacha-env: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/dacha-app-config: 56fc6ac0dc5869a6716823aca5af4c881ad6c1742e245f69416c656e6316106c
        checksum/global-common-env: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/global-common-config: f853f866df16969d97cd5892cebac9f127175d7950e9a931d8921b6db1d66dbd
        checksum/global-common-config-extra: a1fc03eb93370931d8f33c73e22b1875738fe105510c2824912d9049d6194e02
      labels:
        app.kubernetes.io/name: my-release-featurehub-dacha
        app.kubernetes.io/instance: my-release
        
        
    spec:
      serviceAccountName: my-release-featurehub-dacha
      securityContext:
        fsGroup: 999
      containers:
        - name: my-release-featurehub-dacha
          securityContext:
            runAsNonRoot: true
            runAsUser: 999
          image: "featurehub/dacha2:1.7.1"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8600
              protocol: TCP
            - name: metrics
              containerPort: 8701
              protocol: TCP
          livenessProbe:
            failureThreshold: 1
            httpGet:
              path: /health/liveness
              port: metrics
            initialDelaySeconds: 20
            periodSeconds: 20
            timeoutSeconds: 3
          readinessProbe:
            failureThreshold: 1
            httpGet:
              path: /health/readiness
              port: metrics
            initialDelaySeconds: 20
            periodSeconds: 20
            successThreshold: 2
            timeoutSeconds: 3
          volumeMounts:
            - name: log4j2-xml
              mountPath: "/etc/common-config/log4j2.xml"
              subPath: "log4j2.xml"
            - mountPath: /etc/common-config/common.properties
              name: common-config
              subPath: common.properties
            - mountPath: /etc/app-config/application.properties
              name: app-config
              subPath: application.properties
          resources:
            {}
      volumes:
        - name: log4j2-xml
          configMap:
            name: my-release-featurehub-global-extra-log4j2-xml
        - name: common-config
          configMap:
            name: my-release-featurehub-global-common-config
            items:
              - key: common.properties
                path: common.properties
        - name: app-config
          configMap:
            name: my-release-featurehub-dacha-app-config
            items:
              - key: application.properties
                path: application.properties
---
# Source: featurehub/templates/edge/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-featurehub-edge
  annotations:
    argocd.argoproj.io/sync-wave: "20"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-edge
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: my-release-featurehub-edge
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        checksum/edge-env: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/edge-app-config: 25138931f776ff0662cfa4cb7773acacb51fa072315c908210e9986e079650ea
        checksum/global-common-env: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/global-common-config: f853f866df16969d97cd5892cebac9f127175d7950e9a931d8921b6db1d66dbd
        checksum/global-common-config-extra: a1fc03eb93370931d8f33c73e22b1875738fe105510c2824912d9049d6194e02
      labels:
        app.kubernetes.io/name: my-release-featurehub-edge
        app.kubernetes.io/instance: my-release
        
        
    spec:
      serviceAccountName: my-release-featurehub-edge
      securityContext:
        null
      containers:
        - name: my-release-featurehub-edge
          securityContext:
            null
          image: "featurehub/edge:1.7.1"
          imagePullPolicy: 
          ports:
            - name: http
              containerPort: 8553
              protocol: TCP
            - name: metrics
              containerPort: 8701
              protocol: TCP
          livenessProbe:
            failureThreshold: 2
            httpGet:
              path: /health/liveness
              port: metrics
            initialDelaySeconds: 20
            periodSeconds: 20
            timeoutSeconds: 3
          readinessProbe:
            failureThreshold: 2
            httpGet:
              path: /health/readiness
              port: metrics
            initialDelaySeconds: 20
            periodSeconds: 20
            successThreshold: 2
            timeoutSeconds: 3
          volumeMounts:
            - name: log4j2-xml
              mountPath: "/etc/common-config/log4j2.xml"
              subPath: "log4j2.xml"
            - mountPath: /etc/common-config/common.properties
              name: common-config
              subPath: common.properties
            - mountPath: /etc/app-config/application.properties
              name: app-config
              subPath: application.properties
          resources:
            {}
      volumes:
        - name: log4j2-xml
          configMap:
            name: my-release-featurehub-global-extra-log4j2-xml
        - name: common-config
          configMap:
            name: my-release-featurehub-global-common-config
            items:
              - key: common.properties
                path: common.properties
        - name: app-config
          configMap:
            name: my-release-featurehub-edge-app-config
            items:
              - key: application.properties
                path: application.properties
---
# Source: featurehub/templates/management-repository/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-featurehub-management-repository
  annotations:
    argocd.argoproj.io/sync-wave: "20"
  labels:
    helm.sh/chart: featurehub-4.1.3
    app.kubernetes.io/name: my-release-featurehub-management-repository
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: my-release-featurehub-management-repository
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        checksum/management-repository-env: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/management-repository-app-config: 51025ace2ad8b7f90b3dd78e9a28eaa22b69773e37a1dc36747f3e60ed8024d7
        checksum/global-common-env: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/global-common-config: f853f866df16969d97cd5892cebac9f127175d7950e9a931d8921b6db1d66dbd
        checksum/global-common-config-extra: a1fc03eb93370931d8f33c73e22b1875738fe105510c2824912d9049d6194e02
      labels:
        app.kubernetes.io/name: my-release-featurehub-management-repository
        app.kubernetes.io/instance: my-release
        
        
    spec:
      serviceAccountName: my-release-featurehub-management-repository
      containers:
        - name: my-release-featurehub-management-repository
          image: "featurehub/mr:1.7.1"
          imagePullPolicy: 
          ports:
            - name: http
              containerPort: 8085
              protocol: TCP
            - name: metrics
              containerPort: 8701
              protocol: TCP
          livenessProbe:
            failureThreshold: 2
            httpGet:
              path: /health/liveness
              port: metrics
            initialDelaySeconds: 20
            periodSeconds: 20
            timeoutSeconds: 3
          readinessProbe:
            failureThreshold: 2
            httpGet:
              path: /health/readiness
              port: metrics
            initialDelaySeconds: 20
            periodSeconds: 20
            successThreshold: 2
            timeoutSeconds: 3
          volumeMounts:
            - name: log4j2-xml
              mountPath: "/etc/common-config/log4j2.xml"
              subPath: "log4j2.xml"
            - mountPath: /etc/common-config/common.properties
              name: common-config
              subPath: common.properties
            - mountPath: /etc/app-config/application.properties
              name: app-config
              subPath: application.properties
          resources:
            {}
      volumes:
        - name: log4j2-xml
          configMap:
            name: my-release-featurehub-global-extra-log4j2-xml
        - name: common-config
          configMap:
            name: my-release-featurehub-global-common-config
            items:
              - key: common.properties
                path: common.properties
        - name: app-config
          configMap:
            name: my-release-featurehub-management-repository-app-config
            items:
              - key: application.properties
                path: application.properties
---
# Source: featurehub/charts/nats/templates/stateful-set.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: nats
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nats
    app.kubernetes.io/version: 2.10.5
    helm.sh/chart: nats-1.1.5
  name: my-release-nats
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: nats
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/name: nats
  serviceName: my-release-nats-headless
  template:
    metadata:
      annotations:
        checksum/config: 8f89406c4aeab9995368f6435ab9cb17b5bc66d9fb6b6d18397d0bc8183b98f3
      labels:
        app.kubernetes.io/component: nats
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: nats
        app.kubernetes.io/version: 2.10.5
        helm.sh/chart: nats-1.1.5
    spec:
      containers:
      - args:
        - --config
        - /etc/nats-config/nats.conf
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: SERVER_NAME
          value: $(POD_NAME)
        image: nats:2.10.5-alpine
        lifecycle:
          preStop:
            exec:
              command:
              - nats-server
              - -sl=ldm=/var/run/nats/nats.pid
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz?js-enabled-only=true
            port: monitor
          initialDelaySeconds: 10
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 5
        name: nats
        ports:
        - containerPort: 4222
          name: nats
        - containerPort: 8222
          name: monitor
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz?js-server-only=true
            port: monitor
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        startupProbe:
          failureThreshold: 90
          httpGet:
            path: /healthz
            port: monitor
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        volumeMounts:
        - mountPath: /etc/nats-config
          name: config
        - mountPath: /var/run/nats
          name: pid
      - args:
        - -pid
        - /var/run/nats/nats.pid
        - -config
        - /etc/nats-config/nats.conf
        image: natsio/nats-server-config-reloader:0.13.0
        name: reloader
        volumeMounts:
        - mountPath: /var/run/nats
          name: pid
        - mountPath: /etc/nats-config
          name: config
      enableServiceLinks: false
      shareProcessNamespace: true
      volumes:
      - configMap:
          name: my-release-nats-config
        name: config
      - emptyDir: {}
        name: pid
  volumeClaimTemplates: null
---
# Source: featurehub/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.13
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: my-release-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: my-release-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-12.1.13
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: my-release
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:15.1.0-debian-11-r30
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-release-postgresql
                  key: postgres-password
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                
                - |
                  exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: custom-init-scripts
              mountPath: /docker-entrypoint-initdb.d/
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: custom-init-scripts
          configMap:
            name: my-release-postgresql-init-scripts
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "128Mi"
---
# Source: featurehub/templates/global-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: featurehub
  namespace: default
  labels:
spec:
  rules:
    - http:
        paths:
          - path: /features
            pathType: Prefix
            backend:
              service:
                name: "featurehub-edge"
                port:
                  name: http
          - path: /
            pathType: Prefix
            backend:
              service:
                name: "featurehub-management-repository"
                port:
                  name: http
---
# Source: featurehub/charts/nats/templates/tests/request-reply.yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    helm.sh/hook: test
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app.kubernetes.io/component: test-request-reply
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nats
    app.kubernetes.io/version: 2.10.5
    helm.sh/chart: nats-1.1.5
  name: my-release-nats-test-request-reply
spec:
  containers:
  - args:
    - nats reply --echo echo & pid="$!"; sleep 1; nats request echo hi > /tmp/resp;
      kill "$pid"; wait; grep -qF hi /tmp/resp
    command:
    - sh
    - -ec
    - |
      work_dir="$(pwd)"
      mkdir -p "$XDG_CONFIG_HOME/nats"
      cd "$XDG_CONFIG_HOME/nats"
      if ! [ -s context ]; then
        ln -s /etc/nats-contexts context
      fi
      if ! [ -f context.txt ]; then
        echo -n "default" > context.txt
      fi
      cd "$work_dir"
      exec sh -ec "$0"
    image: natsio/nats-box:0.14.1
    name: nats-box
    volumeMounts:
    - mountPath: /etc/nats-contexts
      name: contexts
  enableServiceLinks: false
  restartPolicy: Never
  volumes:
  - name: contexts
    secret:
      secretName: my-release-nats-box-contexts
