---
# Source: prometheus-cachethq/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-prometheus-cachethq
  labels:
    app.kubernetes.io/name: prometheus-cachethq
    helm.sh/chart: prometheus-cachethq-1.1.1
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: prometheus-cachethq/templates/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-prometheus-cachethq-config
  labels:
    app.kubernetes.io/name: prometheus-cachethq
    helm.sh/chart: prometheus-cachethq-1.1.1
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  config.yaml: "#\n# See configuration of project: https://oxyno-zeta.github.io/prometheus-cachethq/\n#\n# Log configuration\n# log:\n#   # Log level\n#   level: info\n#   # Log format\n#   format: json\n# Cachet configuration\ncachet:\n  url: http://localhost\n  apiKey: API_KEY\n# Targets\ntargets:\n  - component:\n      name: COMPONENT_NAME\n      status: PARTIAL_OUTAGE\n    alerts:\n      - name: SERVICE_OFFLINE\n    #   - labels:\n    #       label1: value1\n    # incident:\n    #   name: \"\"\n    #   content: \"\"\n    #   status: INVESTIGATING\n    #   public: true"
---
# Source: prometheus-cachethq/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-prometheus-cachethq
  labels:
    app.kubernetes.io/name: prometheus-cachethq
    helm.sh/chart: prometheus-cachethq-1.1.1
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
    - port: 9090
      targetPort: internal
      protocol: TCP
      name: metrics
  selector:
    app.kubernetes.io/name: prometheus-cachethq
    app.kubernetes.io/instance: my-release
---
# Source: prometheus-cachethq/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-prometheus-cachethq
  labels:
    app.kubernetes.io/name: prometheus-cachethq
    helm.sh/chart: prometheus-cachethq-1.1.1
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus-cachethq
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        checksum/config: 0bd1080c7934e65f44855360165003a133b9b3881c65aa1022cf79f039bb0882
      labels:
        app.kubernetes.io/name: prometheus-cachethq
        app.kubernetes.io/instance: my-release
    spec:
      serviceAccountName: my-release-prometheus-cachethq
      securityContext:
        {}
      containers:
        - name: prometheus-cachethq
          securityContext:
            {}
          image: "oxynozeta/prometheus-cachethq:1.1.1"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: internal
              containerPort: 9090
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health
              port: internal
          readinessProbe:
            httpGet:
              path: /health
              port: internal
          resources:
            {}
          volumeMounts:
          - name: config-volume
            mountPath: /conf
      volumes:
        - name: config-volume
          configMap:
            name: my-release-prometheus-cachethq-config
