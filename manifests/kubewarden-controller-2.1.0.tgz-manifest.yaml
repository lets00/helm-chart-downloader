---
# Source: kubewarden-controller/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-kubewarden-controller
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
---
# Source: kubewarden-controller/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: audit-scanner
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
---
# Source: kubewarden-controller/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubewarden-controller-manager-config
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
data:
  controller_manager_config.yaml: |
    apiVersion: controller-runtime.sigs.k8s.io/v1alpha1
    kind: ControllerManagerConfig
    health:
      healthProbeBindAddress: :8081
    metrics:
      bindAddress: 127.0.0.1:8080
    webhook:
      port: 9443
    leaderElection:
      leaderElect: true
      resourceName: a4ddbf36.kubewarden.io
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kubewarden-controller-manager-cluster-role
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
rules:
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  - validatingwebhookconfigurations
  verbs:
  - create
  - delete
  - list
  - patch
  - watch
- apiGroups:
  - policies.kubewarden.io
  resources:
  - clusteradmissionpolicies
  - admissionpolicies
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - policies.kubewarden.io
  resources:
  - clusteradmissionpolicies/finalizers
  - admissionpolicies/finalizers
  verbs:
  - update
- apiGroups:
  - policies.kubewarden.io
  resources:
  - clusteradmissionpolicies/status
  - admissionpolicies/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
    - policies.kubewarden.io
  resources:
    - policyservers
  verbs:
    - create
    - delete
    - get
    - list
    - patch
    - update
    - watch
- apiGroups:
    - policies.kubewarden.io
  resources:
    - policyservers/finalizers
  verbs:
    - update
- apiGroups:
    - policies.kubewarden.io
  resources:
    - policyservers/status
  verbs:
    - get
    - patch
    - update
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kubewarden-controller-metrics-reader
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
rules:
- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kubewarden-controller-proxy-role
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
rules:
- apiGroups:
  - authentication.k8s.io
  resources:
  - tokenreviews
  verbs:
  - create
- apiGroups:
  - authorization.k8s.io
  resources:
  - subjectaccessreviews
  verbs:
  - create
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: audit-scanner-cluster-role
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
rules:
- apiGroups:
  - policies.kubewarden.io
  resources:
  - clusteradmissionpolicies
  - admissionpolicies
  - clusteradmissionpolicies/status
  - admissionpolicies/status
  - policyservers
  - policyservers/status
  verbs:
  - get
  - list
  - watch
- apiGroups:
    - wgpolicyk8s.io
  resources:
    - policyreports
    - clusterpolicyreports
  verbs:
    - create
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kubewarden-controller-manager-cluster-role
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubewarden-controller-manager-cluster-role
subjects:
- kind: ServiceAccount
  name: my-release-kubewarden-controller
  namespace: default
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kubewarden-controller-proxy-rolebinding
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubewarden-controller-proxy-role
subjects:
- kind: ServiceAccount
  name: my-release-kubewarden-controller
  namespace: default
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: audit-scanner-cluster-role-viewer
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- kind: ServiceAccount
  name: audit-scanner
  namespace: default
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: audit-scanner-cluster-role
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: audit-scanner-cluster-role
subjects:
- kind: ServiceAccount
  name: audit-scanner
  namespace: default
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: kubewarden-controller-leader-election-role
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - patch
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: kubewarden-controller-manager-namespaced-role
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
rules:
- apiGroups:
  - ""
  resources:
  - secrets
  - services
  - configmaps
  verbs:
  - get
  - create
  - patch
  - update
  - delete
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - deployments
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - replicasets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - create
  - delete
  - get
  - list
  - update
  - watch
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: kubewarden-controller-leader-election-rolebinding
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kubewarden-controller-leader-election-role
subjects:
- kind: ServiceAccount
  name: my-release-kubewarden-controller
  namespace: default
---
# Source: kubewarden-controller/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: kubewarden-controller-manager-namespaced-rolebinding
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kubewarden-controller-manager-namespaced-role
subjects:
- kind: ServiceAccount
  name: my-release-kubewarden-controller
  namespace: default
---
# Source: kubewarden-controller/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-kubewarden-controller-metrics-service
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
spec:
  ports:
  - name: https
    port: 8443
    targetPort: https
  selector:
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
---
# Source: kubewarden-controller/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-kubewarden-controller-webhook-service
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
spec:
  ports:
  - port: 443
    targetPort: 9443
  selector:
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
---
# Source: kubewarden-controller/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-kubewarden-controller
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kubewarden-controller
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        
      labels:
        helm.sh/chart: kubewarden-controller-2.1.0
        app.kubernetes.io/name: kubewarden-controller
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/version: "v1.13.0"
        app.kubernetes.io/component: controller
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: kubewarden
    spec:
      serviceAccountName: my-release-kubewarden-controller
      containers:
      - name: manager
        args:
        - --leader-elect
        - --deployments-namespace=default
        - --default-policy-server=default
        - --always-accept-admission-reviews-on-deployments-namespace
        - --zap-log-level=info
        command:
        - /manager
        image: 'ghcr.io/kubewarden/kubewarden-controller:v1.13.0'
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 15
          periodSeconds: 20
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8081
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          limits:
            cpu: 500m
            memory: 200Mi
          requests:
            cpu: 250m
            memory: 70Mi
        securityContext:
          allowPrivilegeEscalation: false
        volumeMounts:
        - mountPath: /tmp/k8s-webhook-server/serving-certs
          name: cert
          readOnly: true
        ports:
        - containerPort: 9443
          name: webhook-server
          protocol: TCP
      volumes:
      - name: cert
        secret:
          defaultMode: 420
          secretName: webhook-server-cert
      securityContext:
        runAsNonRoot: true
      terminationGracePeriodSeconds: 10
---
# Source: kubewarden-controller/templates/audit-scanner.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: audit-scanner
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
spec:
  schedule: "*/60 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 5
  successfulJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: audit-scanner
          securityContext:
            runAsNonRoot: true
          restartPolicy: Never
          volumes:
          - name: policyservers-ca-cert
            secret:
              defaultMode: 420
              secretName: policy-server-root-ca
              items:
              - key: policy-server-root-ca-pem
                path: "policy-server-root-ca-pem"
          containers:
          - name: audit-scanner
            image: 'ghcr.io/kubewarden/audit-scanner:v1.13.0'
            imagePullPolicy: IfNotPresent
            command:
              - /audit-scanner
              - --kubewarden-namespace
              - default
              - --loglevel
              - info
              - --parallel-namespaces
              - "1"
              - --parallel-resources
              - "100"
              - --parallel-policies
              - "5"
              - --page-size
              - "100"
              - --extra-ca
              - "/pki/policy-server-root-ca-pem"
              - -i
              - calico-apiserver
              - -i
              - calico-system
              - -i
              - cattle-alerting
              - -i
              - cattle-csp-adapter-system
              - -i
              - cattle-elemental-system
              - -i
              - cattle-epinio-system
              - -i
              - cattle-externalip-system
              - -i
              - cattle-fleet-local-system
              - -i
              - cattle-fleet-system
              - -i
              - cattle-gatekeeper-system
              - -i
              - cattle-global-data
              - -i
              - cattle-global-nt
              - -i
              - cattle-impersonation-system
              - -i
              - cattle-istio
              - -i
              - cattle-istio-system
              - -i
              - cattle-logging
              - -i
              - cattle-logging-system
              - -i
              - cattle-monitoring-system
              - -i
              - cattle-neuvector-system
              - -i
              - cattle-prometheus
              - -i
              - cattle-provisioning-capi-system
              - -i
              - cattle-resources-system
              - -i
              - cattle-sriov-system
              - -i
              - cattle-system
              - -i
              - cattle-ui-plugin-system
              - -i
              - cattle-windows-gmsa-system
              - -i
              - cert-manager
              - -i
              - cis-operator-system
              - -i
              - fleet-default
              - -i
              - ingress-nginx
              - -i
              - istio-system
              - -i
              - kube-node-lease
              - -i
              - kube-public
              - -i
              - kube-system
              - -i
              - longhorn-system
              - -i
              - rancher-alerting-drivers
              - -i
              - security-scan
              - -i
              - tigera-operator
            volumeMounts:
            - mountPath: "/pki"
              name: policyservers-ca-cert
              readOnly: true
            securityContext:
              allowPrivilegeEscalation: false
            resources:
              limits:
                cpu: 500m
                memory: 1Gi
              requests:
                cpu: 250m
                memory: 300Mi
---
# Source: kubewarden-controller/templates/cert-tls.yaml
# cert-manager resources
---
# Source: kubewarden-controller/templates/post-install-hook.yaml
# In some scenarios when telemetry is enabled, due some concurrency issues,
# when the OTEL operator try to inject the collector container in the controller
# pod, it cannot find a valid collector configuration. Therefore, it is necessary
# to recreate the controller pod after the installation. This ensures that the
# controller pod will have the OTEL collector container.
---
# Source: kubewarden-controller/templates/cert-tls.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-release-kubewarden-controller-serving-cert
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
  annotations:
    
spec:
  dnsNames:
  - my-release-kubewarden-controller-webhook-service.default.svc
  - my-release-kubewarden-controller-webhook-service.default.svc.cluster.local
  issuerRef:
    kind: Issuer
    name: my-release-kubewarden-controller-selfsigned-issuer
  secretName: webhook-server-cert
---
# Source: kubewarden-controller/templates/cert-tls.yaml
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: my-release-kubewarden-controller-selfsigned-issuer
  namespace: default
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
spec:
  selfSigned: {}
---
# Source: kubewarden-controller/templates/webhooks.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: default/my-release-kubewarden-controller-serving-cert
    
  name: kubewarden-controller-mutating-webhook-configuration
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: my-release-kubewarden-controller-webhook-service
      namespace: default
      path: /mutate-policies-kubewarden-io-v1-clusteradmissionpolicy
  failurePolicy: Fail
  name: mclusteradmissionpolicy.kb.io
  rules:
  - apiGroups:
    - policies.kubewarden.io
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - clusteradmissionpolicies
  sideEffects: None
- admissionReviewVersions:
    - v1
    - v1beta1
  clientConfig:
    service:
      name: my-release-kubewarden-controller-webhook-service
      namespace: default
      path: /mutate-policies-kubewarden-io-v1-policyserver
  failurePolicy: Fail
  name: mpolicyserver.kb.io
  rules:
    - apiGroups:
        - policies.kubewarden.io
      apiVersions:
        - v1
      operations:
        - CREATE
        - UPDATE
      resources:
        - policyservers
  sideEffects: None
- admissionReviewVersions:
    - v1
    - v1beta1
  clientConfig:
    service:
      name: my-release-kubewarden-controller-webhook-service
      namespace: default
      path: /mutate-policies-kubewarden-io-v1-admissionpolicy
  failurePolicy: Fail
  name: madmissionpolicy.kb.io
  rules:
    - apiGroups:
        - policies.kubewarden.io
      apiVersions:
        - v1
      operations:
        - CREATE
        - UPDATE
      resources:
        - admissionpolicies
  sideEffects: None
---
# Source: kubewarden-controller/templates/webhooks.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: default/my-release-kubewarden-controller-serving-cert
    
  name: kubewarden-controller-validating-webhook-configuration
  labels:
    helm.sh/chart: kubewarden-controller-2.1.0
    app.kubernetes.io/name: kubewarden-controller
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v1.13.0"
    app.kubernetes.io/component: controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kubewarden
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: my-release-kubewarden-controller-webhook-service
      namespace: default
      path: /validate-policies-kubewarden-io-v1-clusteradmissionpolicy
  failurePolicy: Fail
  name: vclusteradmissionpolicy.kb.io
  rules:
  - apiGroups:
    - policies.kubewarden.io
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - clusteradmissionpolicies
  sideEffects: None
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: my-release-kubewarden-controller-webhook-service
      namespace: default
      path: /validate-policies-kubewarden-io-v1-admissionpolicy
  failurePolicy: Fail
  name: vadmissionpolicy.kb.io
  rules:
  - apiGroups:
    - policies.kubewarden.io
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - admissionpolicies
  sideEffects: None
- admissionReviewVersions:
  - v1
  clientConfig:
    service:
      name: my-release-kubewarden-controller-webhook-service
      namespace: default
      path: /validate-policies-kubewarden-io-v1-policyserver
  failurePolicy: Fail
  name: vpolicyserver.kb.io
  rules:
  - apiGroups:
    - policies.kubewarden.io
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - policyservers
  sideEffects: None
---
# Source: kubewarden-controller/templates/post-install-hook.yaml
# Delete pre 1.11 policy reports, as downstream consumers (Rancher UI
# extension, Policy Reporter UI) may get confused with them.
#
# Pre 1.11, (Cluster)PolicyReports where created as follows:
# - 1 ClusterPolicyReport named `polr-clusterwide`
# - 1 PolicyReport per namespace, named `polr-ns-<namespace name>`.
# From 1.11 onwards, (Cluster)PolicyReports are created as follows:
# - Per each resource, create a (Cluster)PolicyReport with metadata.name that
#   equals the resource uid.
apiVersion: batch/v1
kind: Job
metadata:
  name: "my-release-delete-pre-1-11-policyreports-job"
  namespace: default
  labels:
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    helm.sh/chart: "kubewarden-controller-2.1.0"
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
    
spec:
  template:
    metadata:
      name: "my-release-delete-pre-1-11-policyreports-job"
      labels:
        app.kubernetes.io/managed-by: "Helm"
        app.kubernetes.io/instance: "my-release"
        helm.sh/chart: "kubewarden-controller-2.1.0"
      annotations:
        
    spec:
      restartPolicy: OnFailure
      serviceAccountName: audit-scanner
      securityContext:
        runAsNonRoot: true
      containers:
        - name: delete-pre-1-11-policyreports-job
          image: 'ghcr.io/kubewarden/kubectl:v1.27.14'
          command: ["kubectl", "delete", "clusterpolicyreport,policyreport", "-l", "app.kubernetes.io/managed-by=kubewarden",  "-l", "!kubewarden.io/policyreport-version", "-A"]
          securityContext:
            allowPrivilegeEscalation: false
---
# Source: kubewarden-controller/templates/pre-delete-hook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "my-release"
  namespace: default
  labels:
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    helm.sh/chart: "kubewarden-controller-2.1.0"
  annotations:
    "helm.sh/hook": pre-delete
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded
    
spec:
  template:
    metadata:
      name: "my-release"
      labels:
        app.kubernetes.io/managed-by: "Helm"
        app.kubernetes.io/instance: "my-release"
        helm.sh/chart: "kubewarden-controller-2.1.0"
      annotations:
        
    spec:
      restartPolicy: OnFailure
      serviceAccountName: my-release-kubewarden-controller
      securityContext:
        runAsNonRoot: true
      containers:
        - name: pre-delete-job
          image: 'ghcr.io/kubewarden/kubectl:v1.27.14'
          command: ["kubectl", "delete", "--all", "policyservers.policies.kubewarden.io"]
          securityContext:
            allowPrivilegeEscalation: false
