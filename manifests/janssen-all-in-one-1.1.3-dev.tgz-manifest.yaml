---
# Source: janssen-all-in-one/templates/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-release-janssen-all-in-one
spec:
  maxUnavailable: 90%
  selector:
    matchLabels:
      app: my-release-janssen-all-in-one-aio
---
# Source: janssen-all-in-one/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-janssen-all-in-one-gen-json-file
  namespace: default
  labels:
    app: my-release-janssen-all-in-one-aio
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  generate.json: |-
    {
      "hostname": "demoexample.jans.io",
      "country_code": "US",
      "state": "TX",
      "city": "Austin",
      "admin_pw": "Test1234#",
      "ldap_pw": "Test1234#",
      "redis_pw": "P@assw0rd",
      "email": "support@jans.io",
      "org_name": "Janssen",
      
      "sql_pw": "Test1234#",
      
      "auth_sig_keys": "RS256 RS384 RS512 ES256 ES384 ES512 PS256 PS384 PS512",
      "auth_enc_keys": "RSA1_5 RSA-OAEP",
      "optional_scopes": ["sql","fido2","casa","scim"],
      "salt": "",
      "init_keys_exp": 48
    }
---
# Source: janssen-all-in-one/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-sql-pass
  labels:
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
data:
  sql_password: VGVzdDEyMzQj
---
# Source: janssen-all-in-one/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-config-cm
  namespace: default
  labels:
    app: my-release-janssen-all-in-one-aio
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
data:
  # Jetty header size in bytes in the auth server
  CN_JETTY_REQUEST_HEADER_SIZE: "8192"
  # Port used by Prometheus JMX agent
  CN_PROMETHEUS_PORT: ""
  
  
  
  
  # [vault_envs] Envs related to Hashicorp vault
  
  CN_SQL_DB_SCHEMA: ""
  CN_SQL_DB_DIALECT: mysql
  CN_SQL_DB_HOST: my-release-mysql.default.svc.cluster.local
  CN_SQL_DB_PORT: "3306"
  CN_SQL_DB_NAME: jans
  CN_SQL_DB_USER: jans
  CN_SQL_DB_TIMEZONE: UTC
  CN_CONFIG_ADAPTER: kubernetes
  CN_SECRET_ADAPTER: kubernetes
  CN_CONFIG_KUBERNETES_NAMESPACE: "default"
  CN_SECRET_KUBERNETES_NAMESPACE: "default"
  CN_CONFIG_KUBERNETES_CONFIGMAP: cn
  CN_SECRET_KUBERNETES_SECRET: cn
  CN_CONTAINER_METADATA: "kubernetes"
  CN_MAX_RAM_PERCENTAGE: "75.0"
  CN_CACHE_TYPE: "NATIVE_PERSISTENCE"
  CN_DOCUMENT_STORE_TYPE: "DB"
  DOMAIN: "demoexample.jans.io"
  CN_AUTH_SERVER_BACKEND: ":8080"
  CN_AUTH_APP_LOGGERS: '{"audit_log_level":"INFO","audit_log_target":"FILE","auth_log_level":"INFO","auth_log_target":"STDOUT","enable_stdout_log_prefix":"true","http_log_level":"INFO","http_log_target":"FILE","ldap_stats_log_level":"INFO","ldap_stats_log_target":"FILE","persistence_duration_log_level":"INFO","persistence_duration_log_target":"FILE","persistence_log_level":"INFO","persistence_log_target":"FILE","script_log_level":"INFO","script_log_target":"FILE"}'
  CN_CONFIG_API_APP_LOGGERS: '{"config_api_log_level":"INFO","config_api_log_target":"STDOUT","enable_stdout_log_prefix":"true","ldap_stats_log_level":"INFO","ldap_stats_log_target":"FILE","persistence_duration_log_level":"INFO","persistence_duration_log_target":"FILE","persistence_log_level":"INFO","persistence_log_target":"FILE","script_log_level":"INFO","script_log_target":"FILE"}'
  LB_ADDR: 
  CN_PERSISTENCE_TYPE: sql
  CN_KEY_ROTATION_FORCE: "false"
  CN_KEY_ROTATION_CHECK: "3600"
  CN_KEY_ROTATION_INTERVAL: "48"
  CN_SSL_CERT_FROM_SECRETS: "true"
  CN_CONTAINER_MAIN_NAME: my-release-auth-server
  # Auto enable installation of some services
  
  
  CN_SCIM_ENABLED: "true"
  CN_SCIM_PROTECTION_MODE: "OAUTH"
  CN_SCIM_APP_LOGGERS: '{"enable_stdout_log_prefix":"true","ldap_stats_log_level":"INFO","ldap_stats_log_target":"FILE","persistence_duration_log_level":"INFO","persistence_duration_log_target":"FILE","persistence_log_level":"INFO","persistence_log_target":"FILE","scim_log_level":"INFO","scim_log_target":"STDOUT","script_log_level":"INFO","script_log_target":"FILE"}'
  CN_FIDO2_APP_LOGGERS: '{"enable_stdout_log_prefix":"true","fido2_log_level":"INFO","fido2_log_target":"STDOUT","persistence_duration_log_level":"INFO","persistence_duration_log_target":"FILE","persistence_log_level":"INFO","persistence_log_target":"FILE","script_log_level":"INFO","script_log_target":"FILE"}'  # CASA
  CN_CASA_APP_LOGGERS: '{"casa_log_level":"INFO","casa_log_target":"STDOUT","enable_stdout_log_prefix":"true","timer_log_level":"INFO","timer_log_target":"FILE"}'
  CN_SQL_PASSWORD_FILE: /etc/jans/conf/sql_password
  CN_COUCHBASE_PASSWORD_FILE: /etc/jans/conf/couchbase_password
  CN_COUCHBASE_SUPERUSER_PASSWORD_FILE: /etc/jans/conf/couchbase_superuser_password
  CN_LDAP_PASSWORD_FILE: 
  CN_LDAP_TRUSTSTORE_PASSWORD_FILE: 
  CN_LDAP_CERT_FILE: 
  CN_LDAP_KEY_FILE: 
  CN_LDAP_CACERT_FILE: 
  CN_LDAP_TRUSTSTORE_FILE: 
  CN_CONFIG_API_PLUGINS: "admin-ui,fido2,scim,user-mgt"
  CN_AIO_COMPONENTS: "configurator,persistence-loader,jans-auth,jans-config-api,jans-fido2,jans-casa,jans-scim"
  CN_LOCK_ENABLED: "false"
  CN_OPA_URL: "http://opa.opa.svc.cluster.cluster.local:8181/v1"
  CN_MESSAGE_TYPE: "DISABLED"
---
# Source: janssen-all-in-one/templates/configmap.yaml
apiVersion: v1
data:
  tls_generator.py: |-
    from kubernetes import config, client
    import logging
    import base64

    from jans.pycloudlib import get_manager
    from jans.pycloudlib.wait import wait_for

    log_format = '%(asctime)s - %(name)8s - %(levelname)5s - %(message)s'
    logging.basicConfig(format=log_format, level=logging.INFO)
    logger = logging.getLogger("tls-generator")

    # use the serviceAccount k8s gives to pods
    config.load_incluster_config()
    core_cli = client.CoreV1Api()

    def patch_or_create_namespaced_secret(name, literal, value_of_literal, namespace="default",
                                          secret_type="Opaque", second_literal=None, value_of_second_literal=None,
                                          data=None):
        """Patch secret and if not exist create
        :param name:
        :param literal:
        :param value_of_literal:
        :param namespace:
        :param secret_type:
        :param second_literal:
        :param value_of_second_literal:
        :param data:
        :return:
        """
        # Instantiate the Secret object
        body = client.V1Secret()
        metadata = client.V1ObjectMeta(name=name)
        body.data = data
        if not data:
            body.data = {literal: value_of_literal}
        body.metadata = metadata
        body.type = secret_type
        if second_literal:
            body.data = {literal: value_of_literal, second_literal: value_of_second_literal}
        try:
            core_cli.patch_namespaced_secret(name, namespace, body)
            logger.info('Secret  {} in namespace {} has been patched'.format(name, namespace))
            return
        except client.rest.ApiException as e:
            if e.status == 404 or not e.status:
                try:
                    core_cli.create_namespaced_secret(namespace=namespace, body=body)
                    logger.info('Created secret {} of type {} in namespace {}'.format(name, secret_type, namespace))
                    return True
                except client.rest.ApiException as e:
                    logger.exception(e)
                    return False
            logger.exception(e)
            return False

    # check if janssen secret exists
    def get_certs(secret_name, namespace):
        """

        :param namespace:
        :return:  ssl cert and key from janssen secrets
        """
        def b64encode(value):
            return base64.b64encode(value.encode()).decode()

        manager = get_manager()

        # returns empty string if not found
        ssl_cert = manager.secret.get("ssl_cert")
        if ssl_cert:
            ssl_cert = b64encode(ssl_cert)

        # returns empty string if not found
        ssl_key = manager.secret.get("ssl_key")
        if ssl_key:
            ssl_key = b64encode(ssl_key)
        return ssl_cert, ssl_key


    def main():
        namespace = "default"
        secret_name = "cn"
        cert, key = get_certs(secret_name, namespace)
        # global vars
        name = "tls-certificate"

        # if istio is enabled

        if cert or key:
            patch_or_create_namespaced_secret(name=name,
                                              namespace=namespace,
                                              literal="tls.crt",
                                              value_of_literal=cert,
                                              secret_type="kubernetes.io/tls",
                                              second_literal="tls.key",
                                              value_of_second_literal=key)
        else:
            logger.error(
                "No certificate or key was found in secrets."
                "This can happen when the ssl certificate for the domain is able to be pulled."
                "In that scenario the ssl_cert will be pulled from the domain provided"
            )

    if __name__ == "__main__":
        wait_for(get_manager(), deps=["secret"])
        main()

kind: ConfigMap
metadata:
  name: my-release-janssen-all-in-one-tls-script
  namespace: default
  labels:
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
---
# Source: janssen-all-in-one/templates/configmap.yaml
apiVersion: v1
data:
  updatelbip.py: |-
    #!/usr/bin/env python3
    # -*- coding: utf-8 -*-

    # Update the IP of the load balancer automatically

    """
     License terms and conditions for Janssen Cloud Native Edition:
     https://www.apache.org/licenses/LICENSE-2.0
    """

    import socket
    import os
    import logging
    import time

    logger = logging.getLogger("update-lb-ip")
    logger.setLevel(logging.INFO)
    ch = logging.StreamHandler()
    fmt = logging.Formatter('%(levelname)s - %(asctime)s - %(message)s')
    ch.setFormatter(fmt)
    logger.addHandler(ch)


    def backup(hosts):
        timenow = time.strftime("%c")
        timestamp = "Backup occurred %s \n" % timenow
        logger.info("Backing up hosts file to /etc/hosts.back ...")
        with open('/etc/hosts.back', 'a+') as f:
            f.write(timestamp)
            for line in hosts:
                f.write(line)


    def get_hosts(lb_addr, domain):
        ip_list = []
        hosts_list = []
        ais = socket.getaddrinfo(lb_addr, 0, 0, 0, 0)
        for result in ais:
            ip_list.append(result[-1][0])
        ip_list = list(set(ip_list))
        for ip in ip_list:
            add_host = ip + " " + domain
            hosts_list.append(add_host)

        return hosts_list


    def main():
        try:
            while True:
                lb_addr = os.environ.get("LB_ADDR", "")
                domain = os.environ.get("DOMAIN", "demoexample.jans.io")
                host_file = open('/etc/hosts', 'r').readlines()
                hosts = get_hosts(lb_addr, domain)
                stop = []
                for host in hosts:
                    for i in host_file:
                        if host.replace(" ", "") in i.replace(" ", ""):
                            stop.append("found")
                if len(stop) != len(hosts):
                    backup(host_file)
                    logger.info("Writing new hosts file")
                    with open('/etc/hosts', 'w') as f:
                        for line in host_file:
                            if domain not in line:
                                f.write(line)
                        for host in hosts:
                            f.write(host)
                            f.write("\n")
                        f.write("\n")
                time.sleep(300)
        except KeyboardInterrupt:
            logger.warning("Canceled by user; exiting ...")


    if __name__ == "__main__":
        main()

kind: ConfigMap
metadata:
  name: my-release-updatelbip
  namespace: default
  labels:
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
---
# Source: janssen-all-in-one/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-release-default-cluster-admin-binding
  labels:
    app: my-release-janssen-all-in-one-aio
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: User
    # change it to your actual account; the email can be fetched using
    # the following command: `gcloud info | grep Account`
    name: "ACCOUNT"
    apiGroup: rbac.authorization.k8s.io
---
# Source: janssen-all-in-one/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: my-release-janssen-all-in-one-aio
  name: my-release-default-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: edit
subjects:
- kind: ServiceAccount
  name: default
  namespace: default
---
# Source: janssen-all-in-one/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-default-cn-role
  namespace: default
  labels:
    app: my-release-janssen-all-in-one-aio
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""] # "" refers to the core API group
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
# Source: janssen-all-in-one/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-default-rolebinding
  namespace: default
  labels:
    app: my-release-janssen-all-in-one-aio
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
subjects:
- kind: User
  name: system:serviceaccount:default:default # Name is case sensitive
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role # this must be Role or ClusterRole
  name: my-release-default-cn-role # this must match the name of the Role or ClusterRole you wish to bind to
  apiGroup: rbac.authorization.k8s.io
---
# Source: janssen-all-in-one/templates/service.yml
apiVersion: v1
kind: Service
metadata:
  name: http-aio
  namespace: default
  labels:
    app: my-release-janssen-all-in-one-aio
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
spec:
  ports:
  - port: 8080
    name: http-aio
  selector:
    app: my-release-janssen-all-in-one-aio
  sessionAffinity: None
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
---
# Source: janssen-all-in-one/templates/deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-janssen-all-in-one
  namespace: default
  labels:
    APP_NAME: auth-server
    app: my-release-janssen-all-in-one-aio
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-release-janssen-all-in-one-aio
  template:
    metadata:
      labels:
        APP_NAME: auth-server
        app: my-release-janssen-all-in-one-aio
    spec:
      dnsPolicy: ""
      containers:
      - name: janssen-all-in-one
        imagePullPolicy: IfNotPresent
        image: ghcr.io/janssenproject/jans/all-in-one:1.1.3_dev
        env:                        
        securityContext:
          runAsUser: 1000
          runAsNonRoot: true
        command:
          - /bin/sh
          - -c
          - |
              python3 /scripts/tls_generator.py &
              /app/bin/entrypoint.sh
        ports:
        - name: http-aio
          containerPort: 8080
        
        envFrom:
        - configMapRef:
            name: my-release-config-cm
        
        
        lifecycle:
          {}
        volumeMounts:
        
        
        
          - mountPath: /opt/jans/configurator/db/generate.json
            name: janssen-all-in-one-mount-gen-file
            subPath: generate.json
          - mountPath: /scripts/tls_generator.py
            name: janssen-all-in-one-tls-script
            subPath: tls_generator.py
          - name: my-release-janssen-all-in-one-updatelbip
            mountPath: /scripts/updatelbip.py
            subPath: updatelbip.py
          - name: sql-pass
            mountPath: /etc/jans/conf/sql_password
            subPath: sql_password
        livenessProbe:
          exec:
            command:
            - python3
            - /app/jans_aio/jans_auth/healthcheck.py
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
        readinessProbe:
          exec:
            command:
            - python3
            - /app/jans_aio/jans_auth/healthcheck.py
          initialDelaySeconds: 25
          periodSeconds: 25
          timeoutSeconds: 5
        resources:
          limits:
            cpu: 16000m
            memory: 16000Mi
          requests:
            cpu: 2500m
            memory: 2500Mi
      hostAliases:
      - ip: 22.22.22.22
        hostnames:
        - demoexample.jans.io
      volumes:
      
      
      
        - name: janssen-all-in-one-mount-gen-file
          secret:
            secretName: my-release-janssen-all-in-one-gen-json-file
        - name: janssen-all-in-one-tls-script
          configMap:
            name: my-release-janssen-all-in-one-tls-script
        - name: my-release-janssen-all-in-one-updatelbip
          configMap:
            name: my-release-updatelbip
        - name: sql-pass
          secret:
            secretName: my-release-sql-pass
---
# Source: janssen-all-in-one/templates/hpa.yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: my-release-janssen-all-in-one
  labels:
    app: my-release-janssen-all-in-one-aio
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-release-janssen-all-in-one
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 50
---
# Source: janssen-all-in-one/templates/cronjobs.yaml
kind: CronJob
apiVersion: batch/v1
metadata:
  name: my-release-janssen-all-in-one-as-key-rotation
  namespace: default
  labels:
    app: my-release-janssen-all-in-one-as-key-rotation
    app: my-release-janssen-all-in-one-aio
    helm.sh/chart: janssen-all-in-one-1.1.3-dev
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.1.3-dev"
    app.kubernetes.io/managed-by: Helm
spec:
  schedule: "@every 48h"
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          dnsPolicy: ""
          containers:
            - name: janssen-all-in-one-as-key-rotation
              image: "ghcr.io/janssenproject/jans/certmanager:1.1.3_dev"
              env:                                
              imagePullPolicy: IfNotPresent
              lifecycle:
                {}
              volumeMounts:
              
              
                
                - name: sql-pass
                  mountPath: /etc/jans/conf/sql_password
                  subPath: sql_password
              envFrom:
                - configMapRef:
                    name: my-release-config-cm
                
                
              resources:
                limits:
                  cpu: 300m
                  memory: 300Mi
                requests:
                  cpu: 300m
                  memory: 300Mi
              args: ["patch", "auth", "--opts", "interval:48", "--opts", "key-strategy:NEWER", "--opts", "privkey-push-delay:0", "--opts", "privkey-push-strategy:NEWER"]
          volumes:
          
          
          
            - name: sql-pass
              secret:
                secretName: my-release-sql-pass
          restartPolicy: Never
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-openid-config
  labels:
    app: my-release-janssen-all-in-one-openid-config
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /jans-auth/.well-known/openid-configuration
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /.well-known/openid-configuration
            pathType: Exact
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-device-code
  labels:
    app: my-release-janssen-all-in-one-device-code
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /jans-auth/device_authorization.htm
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /device-code
            pathType: Exact
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-firebase-messaging
  labels:
    app: my-release-janssen-all-in-one-firebase-messaging
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /jans-auth/firebase-messaging-sw.js
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /firebase-messaging-sw.js
            pathType: Exact
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-uma2-config
  labels:
    app: my-release-janssen-all-in-one-uma2-config
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /jans-auth/restv1/uma2-configuration
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /.well-known/uma2-configuration
            pathType: Exact
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-webfinger
  labels:
    app: my-release-janssen-all-in-one-webfinger
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /jans-auth/.well-known/webfinger
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /.well-known/webfinger
            pathType: Exact
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-webdiscovery
  labels:
    app: my-release-janssen-all-in-one-webdiscovery
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /jans-auth/.well-known/simple-web-discovery
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /.well-known/simple-web-discovery
            pathType: Exact
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-config-api
  labels:
    app: my-release-janssen-all-in-one-config-api
  annotations:
    nginx.org/ssl-services: "configapi"
    nginx.ingress.kubernetes.io/proxy-next-upstream: "error timeout invalid_header http_500 http_502 http_503 http_504"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /jans-config-api
            pathType: Prefix
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-u2f-config
  labels:
    app: my-release-janssen-all-in-one-u2f-config
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /jans-auth/restv1/fido-configuration
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /.well-known/fido-configuration
            pathType: Exact
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-janssen-all-in-one-auth-server
  labels:
    app: my-release-janssen-all-in-one-auth-server
  annotations:
    nginx.org/ssl-services: "auth-server"
    nginx.ingress.kubernetes.io/proxy-next-upstream: "error timeout invalid_header http_500 http_502 http_503 http_504"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "demoexample.jans.io"
      secretName: tls-certificate
  rules:
    - host: "demoexample.jans.io"
      http:
        paths:
          - path: /jans-auth
            pathType: Prefix
            backend:
              service:
                name: http-aio
                port:
                  number: 8080
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
---
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
---
---
# Source: janssen-all-in-one/templates/nginx-ingress.yaml
---
