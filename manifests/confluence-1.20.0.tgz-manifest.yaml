---
# Source: confluence/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-confluence
  labels:
    helm.sh/chart: confluence-1.20.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "8.5.9"
    app.kubernetes.io/managed-by: Helm
---
# Source: confluence/templates/config-jvm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-confluence-jvm-config
  labels:
    helm.sh/chart: confluence-1.20.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "8.5.9"
    app.kubernetes.io/managed-by: Helm
    
data:
  additional_jvm_args: >-
    -Dconfluence.cluster.hazelcast.listenPort=5701
    -Dsynchrony.btf.disabled=true
    -Dsynchrony.by.default.enable.collab.editing.if.manually.managed=true
    -Dconfluence.clusterNodeName.useHostname=true
    -Datlassian.logging.cloud.enabled=false
    -XX:ActiveProcessorCount=2        
  max_heap: 1g
  min_heap: 1g
  reserved_code_cache: 256m
---
# Source: confluence/templates/configmap-values-analytics.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-confluence-helm-values
  labels:
    helm.sh/chart: confluence-1.20.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "8.5.9"
    app.kubernetes.io/managed-by: Helm
    
data:
  values.yaml: |
    additionalConfigMaps: []
    additionalContainers: []
    additionalFiles: []
    additionalHosts: []
    additionalInitContainers: []
    additionalLabels: {}
    affinity: {}
    atlassianAnalyticsAndSupport:
      analytics:
        enabled: true
      helmValues:
        enabled: true
    common:
      global: {}
    confluence:
      accessLog:
        enabled: true
        localHomeSubPath: logs
        mountPath: /opt/atlassian/confluence/logs
      additionalBundledPlugins: []
      additionalCertificates:
        customCmd: null
        secretName: null
      additionalEnvironmentVariables: []
      additionalJvmArgs: []
      additionalLibraries: []
      additionalPorts: []
      additionalVolumeClaimTemplates: []
      additionalVolumeMounts: []
      clustering:
        enabled: false
        usePodNameAsClusterNodeName: true
      containerSecurityContext: {}
      forceConfigUpdate: false
      hazelcastService:
        annotations: {}
        enabled: false
        port: 5701
        type: ClusterIP
      jvmDebug:
        enabled: false
      license:
        secretKey: license-key
        secretName: null
      livenessProbe:
        customProbe: {}
        enabled: false
        failureThreshold: 12
        initialDelaySeconds: 60
        periodSeconds: 5
        timeoutSeconds: 1
      ports:
        hazelcast: 5701
        http: 8090
      postStart:
        command: null
      readinessProbe:
        customProbe: {}
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 10
        periodSeconds: 5
        timeoutSeconds: 1
      resources:
        container:
          requests:
            cpu: "2"
            memory: 2G
        jvm:
          maxHeap: 1g
          minHeap: 1g
          reservedCodeCache: 256m
      s3AttachmentsStorage:
        bucketName: null
        bucketRegion: null
        endpointOverride: null
      securityContext:
        fsGroup: 2002
      securityContextEnabled: true
      seraphConfig:
        autoLoginCookieAge: "1209600"
        generateByHelm: false
      service:
        annotations: {}
        contextPath: null
        loadBalancerIP: null
        port: 80
        sessionAffinity: None
        sessionAffinityConfig:
          clientIP:
            timeoutSeconds: null
        type: ClusterIP
      setPermissions: true
      shutdown:
        command: /shutdown-wait.sh
        terminationGracePeriodSeconds: 25
      startupProbe:
        enabled: false
        failureThreshold: 120
        initialDelaySeconds: 60
        periodSeconds: 5
      tomcatConfig:
        acceptCount: "10"
        connectionTimeout: "20000"
        customServerXml: ""
        debug: "0"
        enableLookups: "false"
        generateByHelm: false
        maxHttpHeaderSize: "8192"
        maxThreads: "100"
        mgmtPort: "8000"
        minSpareThreads: "10"
        port: "8090"
        protocol: org.apache.coyote.http11.Http11NioProtocol
        proxyInternalIps: null
        proxyName: null
        proxyPort: null
        redirectPort: "8443"
        scheme: null
        secure: null
        trustedProxies: null
        uriEncoding: UTF-8
      topologySpreadConstraints: []
      umask: "0022"
      useHelmReleaseNameAsContainerName: false
    database:
      credentials:
        passwordSecretKey: password
        secretName: null
        usernameSecretKey: username
      type: null
      url: null
    fluentd:
      command: null
      customConfigFile: false
      elasticsearch:
        enabled: true
        hostname: elasticsearch
        indexNamePrefix: confluence
      enabled: false
      extraVolumes: []
      fluentdCustomConfig: {}
      httpPort: 9880
      imageRepo: fluent/fluentd-kubernetes-daemonset
      imageTag: v1.11.5-debian-elasticsearch7-1.2
      resources: {}
    image:
      pullPolicy: IfNotPresent
      repository: atlassian/confluence
      tag: ""
    ingress:
      annotations: {}
      className: nginx
      create: false
      host: null
      https: true
      maxBodySize: 250m
      nginx: true
      openShiftRoute: false
      path: null
      proxyConnectTimeout: 60
      proxyReadTimeout: 60
      proxySendTimeout: 60
      routeHttpHeaders: {}
      tlsSecretName: null
    monitoring:
      exposeJmxMetrics: false
      fetchJmxExporterJar: true
      grafana:
        createDashboards: false
        dashboardAnnotations: {}
        dashboardLabels: {}
      jmxExporterCustomConfig: {}
      jmxExporterCustomJarLocation: null
      jmxExporterImageRepo: bitnami/jmx-exporter
      jmxExporterImageTag: 0.18.0
      jmxExporterInitContainer:
        customSecurityContext: {}
        resources: {}
        runAsRoot: true
      jmxExporterPort: 9999
      jmxExporterPortType: ClusterIP
      jmxServiceAnnotations: {}
      serviceMonitor:
        create: false
        prometheusLabelSelector: {}
        scrapeIntervalSeconds: 30
    nodeSelector: {}
    opensearch:
      credentials:
        createSecret: true
        existingSecretRef:
          name: null
      enabled: false
      envFrom:
      - secretRef:
          name: opensearch-initial-password
      extraEnvs:
      - name: plugins.security.ssl.http.enabled
        value: "false"
      persistence:
        size: 10Gi
      resources:
        requests:
          cpu: 1
          memory: 1Gi
      singleNode: true
    openshift:
      runWithRestrictedSCC: false
    ordinals:
      enabled: false
      start: 0
    podAnnotations: {}
    podDisruptionBudget:
      annotations: {}
      enabled: false
      labels: {}
      maxUnavailable: null
      minAvailable: null
    podLabels: {}
    replicaCount: 1
    serviceAccount:
      annotations: {}
      clusterRole:
        create: false
        name: null
      clusterRoleBinding:
        create: false
        name: null
      create: true
      eksIrsa:
        roleArn: null
      imagePullSecrets: []
      name: null
      role:
        create: true
      roleBinding:
        create: true
    synchrony:
      additionalCertificates:
        customCmd: null
        secretName: null
      additionalJvmArgs: []
      additionalLibraries: []
      additionalPorts: []
      additionalVolumeMounts: []
      containerSecurityContext: {}
      enabled: false
      podAnnotations: {}
      ports:
        hazelcast: 5701
        http: 8091
      readinessProbe:
        failureThreshold: 10
        healthcheckPath: /synchrony/heartbeat
        initialDelaySeconds: 5
        periodSeconds: 1
      replicaCount: 1
      resources:
        container:
          requests:
            cpu: "2"
            memory: 2.5G
        jvm:
          maxHeap: 2g
          minHeap: 1g
          stackSize: 2048k
      securityContext:
        fsGroup: 2002
      securityContextEnabled: true
      service:
        annotations: {}
        loadBalancerIP: null
        port: 80
        type: ClusterIP
      setPermissions: true
      shutdown:
        terminationGracePeriodSeconds: 25
      topologySpreadConstraints: []
    testPods:
      affinity: {}
      annotations: {}
      image:
        permissionsTestContainer: debian:stable-slim
        statusTestContainer: alpine:latest
      labels: {}
      nodeSelector: {}
      resources: {}
      schedulerName: null
      tolerations: []
    tolerations: []
    volumes:
      additional: []
      additionalSynchrony: []
      defaultPermissionsMode: 484
      localHome:
        customVolume: {}
        mountPath: /var/atlassian/application-data/confluence
        persistentVolumeClaim:
          create: false
          resources:
            requests:
              storage: 1Gi
          storageClassName: null
        persistentVolumeClaimRetentionPolicy:
          whenDeleted: null
          whenScaled: null
      sharedHome:
        customVolume: {}
        mountPath: /var/atlassian/application-data/shared-home
        nfsPermissionFixer:
          command: null
          enabled: true
          imageRepo: alpine
          imageTag: latest
          mountPath: /shared-home
          resources: {}
        persistentVolumeClaim:
          create: false
          resources:
            requests:
              storage: 1Gi
          storageClassName: null
        subPath: null
      synchronyHome:
        customVolume: {}
        mountPath: /var/atlassian/application-data/confluence
        persistentVolumeClaim:
          create: false
          resources:
            requests:
              storage: 1Gi
          storageClassName: null
        persistentVolumeClaimRetentionPolicy:
          whenDeleted: null
          whenScaled: null
  analytics.json: |
    
    {
      "imageTag": "8.5.9",
      "replicas": 1,
      "isJmxEnabled": false,
      "ingressType": "NONE",
      "k8sVersion": "1.30",
      "serviceType": "CLUSTER_IP",
      "dbType": "UNKNOWN",
      "isS3AttachmentsStorageEnabled":false,
      "isClusteringEnabled": false,
      "isSharedHomePVCCreated": false,
      "isServiceMonitorCreated": false,
      "isGrafanaDashboardsCreated": false,
      "isRunOnOpenshift": false,
      "isRunWithRestrictedSCC": false,
      "isOpenshiftRouteCreated": false
    }
---
# Source: confluence/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-confluence
  labels:
    helm.sh/chart: confluence-1.20.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "8.5.9"
    app.kubernetes.io/managed-by: Helm
    
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
    - port: 5701
      targetPort: hazelcast
      protocol: TCP
      name: hazelcast
  selector:
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: my-release
---
# Source: confluence/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-confluence
  labels:
    helm.sh/chart: confluence-1.20.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "8.5.9"
    app.kubernetes.io/managed-by: Helm
    
spec:
  
  replicas: 1
  serviceName: my-release-confluence
  selector:
    matchLabels:
      app.kubernetes.io/name: confluence
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        checksum/config-jvm: 40102b24b2d8ce02420573d3dc0a92e38736e2e9a1e30a25d1afbda9465258bd
        
      labels:
        app.kubernetes.io/name: confluence
        app.kubernetes.io/instance: my-release
        
    spec:
      serviceAccountName: my-release-confluence
      terminationGracePeriodSeconds: 25
      securityContext:
        
        
        fsGroup: 2002
      hostAliases:
        
      initContainers:
        
        - name: nfs-permission-fixer
          image: alpine:latest
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 0 # make sure we run as root so we get the ability to change the volume permissions
          volumeMounts:
            - name: shared-home
              mountPath: "/shared-home"
          command: ["sh", "-c", "(chgrp 2002 /shared-home; chmod g+w /shared-home)"]
        
      containers:
        - name: confluence
          image: "atlassian/confluence:8.5.9"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8090
              protocol: TCP
            - name: hazelcast
              containerPort: 5701
              protocol: TCP
            
            
          readinessProbe:
            httpGet:
              port: 8090
              path: /status
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            failureThreshold: 6
          resources:
            requests:
              cpu: "2"
              memory: 2G
          volumeMounts:
            
            - name: local-home
              mountPath: "/var/atlassian/application-data/confluence"
            - name: local-home
              mountPath: "/opt/atlassian/confluence/logs"
              subPath: "logs"
            - name: shared-home
              mountPath: "/var/atlassian/application-data/shared-home"
            - name: helm-values
              mountPath: /opt/atlassian/helm
            
            
            
            
            
          env:
            
            - name: ATL_TOMCAT_SCHEME
              value: "https"
            - name: ATL_TOMCAT_SECURE
              value: "true"
            
            
            - name: ATL_TOMCAT_PORT
              value: "8090"
            
            - name: ATL_TOMCAT_ACCESS_LOG
              value: "true"
            - name: UMASK
              value: "0022"
            - name: SET_PERMISSIONS
              value: "true"
            - name: ATL_PRODUCT_HOME_SHARED
              value: "/var/atlassian/application-data/shared-home"
            - name: JVM_SUPPORT_RECOMMENDED_ARGS
              valueFrom:
                configMapKeyRef:
                  key: additional_jvm_args
                  name: my-release-confluence-jvm-config
            
            
            
            
            
            
            
            
            - name: JVM_MINIMUM_MEMORY
              valueFrom:
                configMapKeyRef:
                  key: min_heap
                  name: my-release-confluence-jvm-config
            - name: JVM_MAXIMUM_MEMORY
              valueFrom:
                configMapKeyRef:
                  key: max_heap
                  name: my-release-confluence-jvm-config
            - name: JVM_RESERVED_CODE_CACHE_SIZE
              valueFrom:
                configMapKeyRef:
                  key: reserved_code_cache
                  name: my-release-confluence-jvm-config
            
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "/shutdown-wait.sh"]
        
        
        
      volumes:
        
        
        
        - name: local-home
        
          emptyDir: {}
        - name: shared-home
        
          emptyDir: {}
        - name: helm-values
          configMap:
            name: my-release-confluence-helm-values
---
# Source: confluence/templates/tests/test-application-status.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-confluence-application-status-test"
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
    
  labels:
    helm.sh/chart: confluence-1.20.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "8.5.9"
    app.kubernetes.io/managed-by: Helm
    
spec:
  containers:
    - name: test
      image: alpine:latest
      env:
        - name: STATUS_URL
          value: "http://my-release-confluence:80/status"
      command:
        - /bin/sh
        - -ec
        - |
          apk add -q jq curl
          STATUS=$(curl -s "$STATUS_URL")
          echo "Verifying application state is RUNNING or FIRST_RUN: $STATUS"
          echo $STATUS | jq -e '.state|test("RUNNING|FIRST_RUN")'
  restartPolicy: Never
---
# Source: confluence/templates/tests/test-shared-home-permissions.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-confluence-shared-home-permissions-test"
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
    
  labels:
    helm.sh/chart: confluence-1.20.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "8.5.9"
    app.kubernetes.io/managed-by: Helm
    
spec:
  containers:
    - name: test
      image: debian:stable-slim
      imagePullPolicy: IfNotPresent
      securityContext:
        # We assume that the UID and GID used by the product images are the same, which in practice they are
        runAsUser: 2002
        runAsGroup: 2002
      volumeMounts:
        - name: shared-home
          mountPath: /shared-home
      command:
        - /bin/sh
        - -ec
        - |
          ls -ld /shared-home
          echo "Creating temporary file in shared home as user $(id -u):$(id -g)"
          touch /shared-home/permissions-test
          ls -l /shared-home/permissions-test
          rm /shared-home/permissions-test
  volumes:
    
    - name: shared-home
    
      emptyDir: {}
  restartPolicy: Never
