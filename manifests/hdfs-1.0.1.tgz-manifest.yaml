---
# Source: hdfs/templates/hdfs-dn-pdb.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: my-release-hdfs-datanode
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: datanode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: datanode
      app.kubernetes.io/instance: my-release
  minAvailable: 3
---
# Source: hdfs/templates/hdfs-nn-pdb.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: my-release-hdfs-namenode
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: namenode
      app.kubernetes.io/instance: my-release
  minAvailable: 1
---
# Source: hdfs/templates/hadoop-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-hdfs-hadoop
  labels:
    app.kubernetes.io/name: hdfs
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
data:
  bootstrap.sh: |-
    #!/bin/bash
    
    : ${HADOOP_HOME:=/usr/local/hadoop}
    
    . $HADOOP_HOME/etc/hadoop/hadoop-env.sh
    
    # Directory to find config artifacts
    CONFIG_DIR="/tmp/hadoop-config"
    
    # Copy config files from volume mount
    
    for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
        if [[ -e ${CONFIG_DIR}/$f ]]; then
        cp ${CONFIG_DIR}/$f $HADOOP_HOME/etc/hadoop/$f
        else
        echo "ERROR: Could not find $f in $CONFIG_DIR"
        exit 1
        fi
    done
    
    # installing libraries if any - (resource urls added comma separated to the ACP system variable)
    cd $HADOOP_HOME/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -
    if [[ $2 == "namenode" ]]; then
        if [ ! -d "/dfs/name" ]; then
        mkdir -p /dfs/name
        $HADOOP_HOME/bin/hdfs namenode -format -force -nonInteractive
        fi
        $HADOOP_HOME/sbin/hadoop-daemon.sh start namenode
    fi
    if [[ $2 == "datanode" ]]; then
        if [ ! -d "/dfs/data" ]; then
        mkdir -p /dfs/data
        fi
        #  wait up to 30 seconds for namenode
        (while [[ $count -lt 15 && -z $(curl -sf http://my-release-hdfs-namenode:9870) && -z $(curl -sf http://my-release-hdfs-namenode:50070) ]]; do ((count=count+1)) ; echo "Waiting for my-release-hdfs-namenode" ; sleep 2; done && [[ $count -lt 15 ]])
        [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs namenode, exiting." && exit 1
    
        $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode
    fi
    if [[ $1 == "-d" ]]; then
        until find ${HADOOP_HOME}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
        tail -F ${HADOOP_HOME}/logs/* &
        while true; do sleep 1000; done
    fi
    
    if [[ $1 == "-bash" ]]; then
        /bin/bash
    fi
  core-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property><name>fs.defaultFS</name><value>hdfs://my-release-hdfs-namenode:9820/</value></property>
        <property><name>hadoop.proxyuser.hdfs.hosts</name>
                <value>*</value>
        </property>
        <property>
            <name>hadoop.proxyuser.hdfs.groups</name>
            <value>*</value>
        </property>
    </configuration>
  hdfs-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property><name>dfs.datanode.use.datanode.hostname</name><value>false</value></property>
        <property><name>dfs.client.use.datanode.hostname</name><value>false</value></property>
        <property><name>dfs.datanode.data.dir</name><value>file:///dfs/data</value>
        <description>DataNode directory</description>
        </property>
    
        <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///dfs/name</value>
        <description>NameNode directory for namespace and transaction logs storage.</description>
        </property>
    
        <property>
        <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
        <value>false</value>
        </property>
    
        <!-- Bind to all interfaces -->
        <property>
        <name>dfs.namenode.rpc-bind-host</name>
        <value>0.0.0.0</value>
        </property>
        <property>
        <name>dfs.namenode.servicerpc-bind-host</name>
        <value>0.0.0.0</value>
        </property>
        <!-- /Bind to all interfaces -->
        <property><name>dfs.replication</name><value>3</value></property>
    
    </configuration>
  mapred-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
    </configuration>
  yarn-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
    </configuration>
  httpfs-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
    </configuration>
  httpfs-signature.secret: |-
    hadoop httpfs secret
  slaves: |
    localhost
---
# Source: hdfs/templates/hdfs-nn-exporter-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-hdfs-namenode-exporter
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
data:
  config-exporter.yml: |-
    fsImagePath : '/dfs/name/current'
    skipPreviouslyParsed : true
    skipFileDistributionForGroupStats : false
    skipFileDistributionForUserStats : false
    skipFileDistributionForPathStats : false
    skipFileDistributionForPathSetStats : false
    fileSizeDistributionBuckets: ['0','1MiB', '32MiB', '64MiB', '128MiB', '1GiB', '10GiB']
---
# Source: hdfs/templates/hdfs-dn-svc-headless.yaml
# A headless service to create DNS records
apiVersion: v1
kind: Service
metadata:
  name: my-release-hdfs-datanode
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: datanode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  ports:
  - name: webhdfs
    port: 9864
  - name: webshdfs
    port: 9865
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: datanode
    app.kubernetes.io/instance: my-release
---
# Source: hdfs/templates/hdfs-nn-exporter-service.yml
kind: Service
apiVersion: v1
metadata:
  name: my-release-hdfs-namenode-exporter
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec: 
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    app.kubernetes.io/instance: my-release
  ports:
  - port: 5556
    name: metrics
    targetPort: 5556
---
# Source: hdfs/templates/hdfs-nn-svc-headless.yaml
# A headless service to create DNS records
apiVersion: v1
kind: Service
metadata:
  name: my-release-hdfs-namenode
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  ports:
  - name: dfs
    port: 9820
    protocol: TCP
  - name: webhdfs
    port: 9870
  - name: webshdfs
    port: 9871
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    app.kubernetes.io/instance: my-release
---
# Source: hdfs/templates/hdfs-nn-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-hdfs
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  ports:
  - name: dfs
    port: 9820
    protocol: TCP
  - name: webhdfs
    port: 9870
  - name: webshdfs
    port: 9871
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    app.kubernetes.io/instance: my-release
---
# Source: hdfs/templates/httpfs-svc.yaml
# A headless service to create DNS records
apiVersion: v1
kind: Service
metadata:
  name: my-release-hdfs-httpfs
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: httpfs
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  ports:
  - name: httpfs
    port: 14000
    protocol: TCP
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: httpfs
    app.kubernetes.io/instance: my-release
---
# Source: hdfs/templates/httpfs-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-hdfs-httpfs
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: httpfs
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: httpfs
      app.kubernetes.io/instance: "my-release"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hdfs
        app.kubernetes.io/component: httpfs
        app.kubernetes.io/instance: "my-release"
    spec:
      containers:
      - name: httpfs
        image: "gradiant/hdfs:3.2.2"
        imagePullPolicy: "IfNotPresent"
        env:
          - name: HTTPFS_HTTP_PORT
            value: "14000"
          - name: HTTPFS_ADMIN_PORT
            value: "14001"
          - name: CATALINA_OPTS
            value: -Dhttpfs.admin.hostname=0.0.0.0
        command:
        - "/opt/hadoop/sbin/httpfs.sh"
        - "run"
        resources:
          limits:
            cpu: 1000m
            memory: 2048Mi
          requests:
            cpu: 10m
            memory: 256Mi
        #livenessProbe:
        #  httpGet:
        #    path: /
        #    port: 9870
        #  initialDelaySeconds: 10
        #  timeoutSeconds: 2
        volumeMounts:
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop
      volumes:
      - name: hadoop-config
        configMap:
          name: my-release-hdfs-hadoop
---
# Source: hdfs/templates/hdfs-dn-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-hdfs-datanode
  annotations:
    checksum/config: 912225c5dc07e16d6d4897023f493c2172a0c4e27e13b4e0782615e0ff510e06
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: datanode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: datanode
      app.kubernetes.io/instance: "my-release"
  serviceName: my-release-hdfs-datanode
  replicas: 3
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hdfs
        app.kubernetes.io/component: datanode
        app.kubernetes.io/instance: "my-release"
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 5
            podAffinityTerm:
              topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: hdfs
                  app.kubernetes.io/component: datanode
                  helm.sh/chart: hdfs-1.0.1
                  app.kubernetes.io/managed-by: "Helm"
                  app.kubernetes.io/instance: "my-release"
                  app.kubernetes.io/version: "3.2.2"
                  app.kubernetes.io/part-of: hdfs
      securityContext:
        fsGroup: 114
      initContainers:
      - name: "chown"
        image: "gradiant/hdfs:3.2.2"
        imagePullPolicy: "IfNotPresent"
        command:
        - /bin/bash
        - -c
        - chown -R hdfs:hadoop /dfs &&
          chmod g+s /dfs
        securityContext:
          runAsUser: 0
        volumeMounts:
        - mountPath: /dfs
          name: dfs
      containers:
      - name: datanode
        image: "gradiant/hdfs:3.2.2"
        imagePullPolicy: "IfNotPresent"
        command:
           - "/bin/bash"
           - "/tmp/hadoop-config/bootstrap.sh"
           - "-d"
           - "datanode"
        resources:
          limits:
            cpu: 1000m
            memory: 2048Mi
          requests:
            cpu: 10m
            memory: 256Mi
        readinessProbe:
          httpGet:
            path: /
            port: 9864
          initialDelaySeconds: 5
          timeoutSeconds: 2
        livenessProbe:
          httpGet:
            path: /
            port: 9864
          initialDelaySeconds: 10
          timeoutSeconds: 2
        volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
        - name: dfs
          mountPath: /dfs
      volumes:
      - name: hadoop-config
        configMap:
          name: my-release-hdfs-hadoop
      - name: dfs
        emptyDir: {}
---
# Source: hdfs/templates/hdfs-nn-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-hdfs-namenode
  annotations:
    checksum/config: 912225c5dc07e16d6d4897023f493c2172a0c4e27e13b4e0782615e0ff510e06
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-1.0.1
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-release"
    app.kubernetes.io/version: "3.2.2"
    app.kubernetes.io/part-of: hdfs
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: namenode
      app.kubernetes.io/instance: "my-release"
  serviceName: my-release-hdfs-namenode  
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hdfs
        app.kubernetes.io/component: namenode
        app.kubernetes.io/instance: "my-release"
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 5
            podAffinityTerm:
              topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: hdfs
                  app.kubernetes.io/component: namenode
                  helm.sh/chart: hdfs-1.0.1
                  app.kubernetes.io/managed-by: "Helm"
                  app.kubernetes.io/instance: "my-release"
                  app.kubernetes.io/version: "3.2.2"
                  app.kubernetes.io/part-of: hdfs
      initContainers:
      - name: "chown"
        image: "gradiant/hdfs:3.2.2"
        imagePullPolicy: "IfNotPresent"
        command:
        - /bin/bash
        - -c
        - chown -R hdfs:hadoop /dfs &&
          chmod g+s /dfs
        securityContext:
          runAsUser: 0
        volumeMounts:
        - mountPath: /dfs
          name: dfs
      containers:
      - name: namenode
        image: "gradiant/hdfs:3.2.2"
        imagePullPolicy: "IfNotPresent"
        command:
        - "/bin/bash"
        - "/tmp/hadoop-config/bootstrap.sh"
        - "-d"
        - "namenode"
        resources:
          limits:
            cpu: 1000m
            memory: 2048Mi
          requests:
            cpu: 10m
            memory: 256Mi
        readinessProbe:
          httpGet:
            path: /
            port: 9870
          initialDelaySeconds: 5
          timeoutSeconds: 2
        livenessProbe:
          httpGet:
            path: /
            port: 9870
          initialDelaySeconds: 10
          timeoutSeconds: 2
        volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
        - name: dfs
          mountPath: /dfs
      - name: namenode-exporter
        image: "marcelmay/hadoop-hdfs-fsimage-exporter:1.2"
        command:
        - /bin/sh
        - -c
        - java $JAVA_OPTS -jar /opt/fsimage-exporter/fsimage-exporter.jar 0.0.0.0 "5556" /exporter/config-exporter.yml
        ports:
        - containerPort: 5556
        resources:
                    null
        volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
        - name: config-exporter
          mountPath: /exporter
        - name: dfs
          mountPath: /dfs
      volumes:
      - name: hadoop-config
        configMap:
          name: my-release-hdfs-hadoop
      - name: config-exporter
        configMap:
          name: my-release-hdfs-namenode-exporter
      - name: dfs
        emptyDir: {}
---
# Source: hdfs/templates/tests/canary-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-canary"
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
spec:
  containers:
  - name: my-release-canary
    image: "gradiant/hdfs:3.2.2"
    imagePullPolicy: "IfNotPresent"
    env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
    command:
    - bash
    - -c
    - |
      # configure data for hadoop container
      . /tmp/hadoop-config/bootstrap.sh || exit 1
      # try to create a folder in hdfs
      hdfs dfs -mkdir -p /test || exit 1
      hdfs dfs -mkdir /test/$MY_POD_NAME || exit 1
      hdfs fsck /test/$MY_POD_NAME | grep 'is HEALTHY' || exit 1
      hdfs dfs -rm -r -R -f /test/$MY_POD_NAME || exit 1
    volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
  volumes:
  - name: hadoop-config
    configMap:
          name: my-release-hdfs-hadoop      
  restartPolicy: Never
