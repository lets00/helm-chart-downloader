---
# Source: kubechat/templates/django-service.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f compose.yml -c -o deploy/kubechat
    kompose.version: 1.26.0 (40646f47)
  labels:
    helm.sh/chart: kubechat-0.5.0-yunjia.1
    app.kubernetes.io/name: kubechat
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubechat.io/component: django
  name: kubechat
spec:
  ports:
    - name: "api"
      port: 8000
      targetPort: 8000
  type: ClusterIP
  selector:
    app.kubernetes.io/name: kubechat
    app.kubernetes.io/instance: my-release
    app.kubechat.io/component: django
---
# Source: kubechat/templates/frontend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kubechat-website
  namespace: kubechat
spec:
  ports:
  - port: 8001
    protocol: TCP
    targetPort: 80
  selector:
    app: kubechat-website
  type: ClusterIP
---
# Source: kubechat/templates/frontend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kubechat-console
  namespace: kubechat
spec:
  ports:
  - port: 8002
    protocol: TCP
    targetPort: 80
  selector:
    app: kubechat-console
  type: ClusterIP
---
# Source: kubechat/templates/ocr-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: paddleocr-hubserving-service
spec:
  selector:
    app: paddleocr-hubserving
  ports:
    - protocol: TCP
      port: 8866
      targetPort: 8866
  type: ClusterIP
---
# Source: kubechat/templates/whisper-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: openai-whisper-asr-service
spec:
  selector:
    app: openai-whisper-asr
  ports:
    - protocol: TCP
      port: 9000
      targetPort: 9000
  type: ClusterIP
---
# Source: kubechat/templates/celerybeat-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f compose.yml -c -o deploy/kubechat
    kompose.version: 1.26.0 (40646f47)
  labels:
    helm.sh/chart: kubechat-0.5.0-yunjia.1
    app.kubernetes.io/name: kubechat
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
  name: celerybeat
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kubechat
      app.kubernetes.io/instance: my-release
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kubechat
        app.kubernetes.io/instance: my-release
    spec:
      containers:
        - args:
            - /bin/sh
            - -c
            - |
              /app/scripts/entrypoint.sh /app/scripts/start-celery-beat.sh
          env:
            - name: REDIS_HOST
              value: "redis-redis-redis"
            - name: REDIS_PORT
              value: "6379"
            - name: REDIS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: redis-redis-account-default
                  key: username
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-redis-account-default
                  key: password
            - name: DJANGO_LOG_LEVEL
              value: "INFO"
            - name: POSTGRES_DB
              value: "kubechat"
            - name: POSTGRES_HOST
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: host
            - name: POSTGRES_PORT
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: port
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: username
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: password
          image: registry.cn-hangzhou.aliyuncs.com/apecloud/kubechat:v0.1.2
          name: kubechat-celerybeat
          imagePullPolicy: IfNotPresent
          resources:
            {}
      restartPolicy: Always
status: {}
---
# Source: kubechat/templates/celeryworker-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f compose.yml -c -o deploy/kubechat
    kompose.version: 1.26.0 (40646f47)
  labels:
    helm.sh/chart: kubechat-0.5.0-yunjia.1
    app.kubernetes.io/name: kubechat
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
  name: celeryworker
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kubechat
      app.kubernetes.io/instance: my-release
      app.kubechat.io/component: celery-worker
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kubechat
        app.kubernetes.io/instance: my-release
        app.kubechat.io/component: celery-worker
    spec:
      containers:
        - command:
            - /bin/sh
            - -c
            - |
              mkdir -p /data/.cache
              mkdir -p /root/.cache
              ln -s /data/.cache/huggingface /root/.cache/
              ln -s /data/.cache/torch /root/.cache/
              /app/scripts/entrypoint.sh /app/scripts/start-celery-worker.sh
          env:
            - name: REDIS_HOST
              value: "redis-redis-redis"
            - name: REDIS_PORT
              value: "6379"
            - name: REDIS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: redis-redis-account-default
                  key: username
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-redis-account-default
                  key: password
            - name: DJANGO_LOG_LEVEL
              value: "INFO"
            - name: POSTGRES_DB
              value: "kubechat"
            - name: POSTGRES_HOST
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: host
            - name: POSTGRES_PORT
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: port
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: username
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: password

            - name: VECTOR_DB_CONTEXT
              value: "{\"url\":\"http://qdrant-qdrant\", \"port\":6333, \"distance\":\"Cosine\", \"timeout\": 1000}"
            - name: VECTOR_DB_TYPE
              value: "qdrant"
            - name: MEDIA_ROOT
              value: /data/media
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: EMBEDDING_MODEL
              value: "bge"
            - name: EMBEDDING_DEVICE
              value: "cpu"
            - name: EMBEDDING_BACKEND
              value: "local"
            - name: EMBEDDING_SERVICE_URL
              value: "http://xinference-xinference:9997"
            - name: EMBEDDING_SERVICE_MODEL
              value: "bge-large-zh-v1.5"
            - name: EMBEDDING_SERVICE_MODEL_UID
              value: ""
            - name: WHISPER_HOST
              value: "http://openai-whisper-asr-service:9000"
            - name: PADDLEOCR_HOST
              value: "http://paddleocr-hubserving-service:8866"
            - name: MODEL_FAMILIES
              value: "[{\"enabled\":\"true\",\"label\":\"QianWen\",\"models\":[{\"context_window\":8096,\"enabled\":\"true\",\"label\":\"QianWen Turbo\",\"memory\":\"enabled\",\"name\":\"qwen-turbo\"},{\"context_window\":8096,\"enabled\":\"true\",\"label\":\"QianWen Plus\",\"memory\":\"enabled\",\"name\":\"qwen-plus\"},{\"context_window\":8096,\"enabled\":\"true\",\"label\":\"QianWen Max\",\"memory\":\"enabled\",\"name\":\"qwen-max\"}],\"name\":\"qianwen\",\"temperature\":0.01},{\"enabled\":\"true\",\"label\":\"ChatGLM\",\"models\":[{\"enabled\":\"true\",\"label\":\"ChatGLM Turbo\",\"memory\":\"enabled\",\"name\":\"chatglm-turbo\"},{\"enabled\":\"true\",\"label\":\"ChatGLM Std\",\"memory\":\"enabled\",\"name\":\"chatglm-std\"},{\"enabled\":\"true\",\"label\":\"ChatGLM Lite\",\"memory\":\"enabled\",\"name\":\"chatglm-lite\"},{\"enabled\":\"true\",\"label\":\"ChatGLM Pro\",\"memory\":\"enabled\",\"name\":\"chatglm-pro\"},{\"context_window\":32384,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-chatglm2-6b:8000\",\"label\":\"ChatGLM2 6b\",\"memory\":\"disabled\",\"name\":\"chatglm2-6b\"}],\"name\":\"chatglm\",\"temperature\":0.01},{\"enabled\":\"true\",\"label\":\"BaiChuan\",\"models\":[{\"context_window\":4096,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-baichuan-13b:8000\",\"label\":\"BaiChuan 13b\",\"memory\":\"disabled\",\"name\":\"baichuan-13b\"},{\"enabled\":\"true\",\"label\":\"BaiChuan 53b\",\"memory\":\"disabled\",\"name\":\"baichuan-53b\"}],\"name\":\"baichuan\",\"temperature\":0.01},{\"enabled\":\"true\",\"label\":\"Azure OpenAI\",\"models\":[{\"context_window\":4096,\"enabled\":\"true\",\"label\":\"Azure OpenAI\",\"memory\":\"enabled\",\"name\":\"azure-openai\"}],\"name\":\"azure-openai\",\"temperature\":0},{\"enabled\":\"true\",\"label\":\"ChatGPT\",\"models\":[{\"context_window\":128000,\"enabled\":\"true\",\"label\":\"ChatGPT-4 Turbo\",\"memory\":\"enabled\",\"name\":\"gpt-4-1106-preview\",\"similarity_topk\":10},{\"context_window\":8192,\"enabled\":\"true\",\"label\":\"ChatGPT-4\",\"memory\":\"enabled\",\"name\":\"gpt-4\"},{\"context_window\":8192,\"enabled\":\"true\",\"label\":\"ChatGPT-4-0613\",\"memory\":\"enabled\",\"name\":\"gpt-4-0613\"},{\"context_window\":16385,\"enabled\":\"true\",\"label\":\"ChatGPT 3.5 Turbo 1106\",\"memory\":\"enabled\",\"name\":\"gpt-3.5-turbo-1106\",\"similarity_topk\":5},{\"context_window\":4096,\"enabled\":\"true\",\"label\":\"ChatGPT-3.5 Turbo\",\"memory\":\"enabled\",\"name\":\"gpt-3.5-turbo\"},{\"context_window\":16384,\"enabled\":\"true\",\"label\":\"ChatGPT-3.5 Turbo 16k\",\"memory\":\"enabled\",\"name\":\"gpt-3.5-turbo-16k\",\"similarity_topk\":5}],\"name\":\"chatgpt\",\"temperature\":0},{\"enabled\":\"true\",\"label\":\"Wen Xin Yi Yan\",\"models\":[{\"enabled\":\"true\",\"label\":\"Wen Xin Yi Yan\",\"memory\":\"disabled\",\"name\":\"ernie-bot-turbo\"}],\"name\":\"wenxinyiyan\"},{\"enabled\":\"false\",\"label\":\"Vicuna\",\"models\":[{\"context_window\":2048,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-vicuna-13b:8000\",\"label\":\"Vicuna 13b\",\"memory\":\"disabled\",\"name\":\"vicuna-13b\"}],\"name\":\"vicuna\"},{\"enabled\":\"false\",\"label\":\"Guanaco\",\"models\":[{\"context_window\":2048,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-guanaco-33b:8000\",\"label\":\"Guanaco 33b\",\"memory\":\"disabled\",\"name\":\"guanaco-33b\"}],\"name\":\"guanaco\"},{\"enabled\":\"false\",\"label\":\"Falcon\",\"models\":[{\"context_window\":2048,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-falcon-40b:8000\",\"label\":\"Falcon 40b\",\"memory\":\"disabled\",\"name\":\"falcon-40b\"}],\"name\":\"falcon\"},{\"enabled\":\"false\",\"label\":\"Gorilla\",\"models\":[{\"context_window\":2048,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-gurilla-7b:8000\",\"label\":\"Gorilla 7b\",\"memory\":\"disabled\",\"name\":\"gorilla-7b\"}],\"name\":\"gorilla\"}]"
            - name: ES_HOST
              value: "http://elasticsearch-elasticsearch:9200"
          image: registry.cn-hangzhou.aliyuncs.com/apecloud/kubechat:v0.1.2
          name: kubechat-celeryworker
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - mountPath: /data
              name: data
      restartPolicy: Always
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubechat.io/component: celery-worker
              topologyKey: kubernetes.io/hostname
            weight: 100
      volumes:
        # shared uploaded files between django and celery
        - name: data
          hostPath:
            path: /data/kubechat
---
# Source: kubechat/templates/django-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f compose.yml -c -o deploy/kubechat
    kompose.version: 1.26.0 (40646f47)
  labels:
    helm.sh/chart: kubechat-0.5.0-yunjia.1
    app.kubernetes.io/name: kubechat
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
  name: django
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kubechat
      app.kubernetes.io/instance: my-release
      app.kubechat.io/component: django
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kubechat
        app.kubernetes.io/instance: my-release
        app.kubechat.io/component: django
    spec:
      initContainers:
        - name: prepare-models
          image: curlimages/curl:8.4.0
          securityContext:
            runAsUser: 0
            privileged: true
          command:
            - /bin/sh
            - -c
            - |
              # fail fast
              set -e
              mkdir -p /root/.cache
              mkdir -p /data/.cache/huggingface
              ln -s /data/.cache/huggingface /root/.cache/
              mkdir -p /data/.cache/torch
              ln -s /data/.cache/torch /root/.cache/

              # prepare rerank model
              if [ "$RERANK_BACKEND" = "local" ] && [ ! -d /data/models/bge-reranker-large ]; then
                echo "downloading rerank model"
                curl --progress-bar -OL https://llm-store.oss-cn-beijing.aliyuncs.com/bge-reranker-large.tar
                tar -xvf bge-reranker-large.tar
                mkdir -p /data/models
                mv bge-reranker-large /data/models/
                echo "successfully downloaded rerank model"
              else
                echo "rerank model exists, skip downloading"
              fi

              # prepare bge model
              if [ "$EMBEDDING_BACKEND" = "local" ] && [ ! -d /data/.cache/torch/sentence_transformers ]; then
                echo "downloading bge model"
                curl --progress-bar -OL https://llm-store.oss-cn-beijing.aliyuncs.com/BAAI_bge-large-zh.tar
                tar -xvf BAAI_bge-large-zh.tar
                mkdir -p /data/.cache/torch/sentence_transformers
                mv BAAI_bge-large-zh/ /data/.cache/torch/sentence_transformers/
                echo "successfully downloaded bge model"
              else
                echo "bge model exists, skip downloading"
              fi
          env:
            - name: EMBEDDING_BACKEND
              value: "local"
            - name: RERANK_BACKEND
              value: "local"
          volumeMounts:
            - mountPath: /data
              name: data
      containers:
        - command:
            - /bin/sh
            - -c
            - |
              mkdir -p /data/.cache
              mkdir -p /root/.cache
              ln -s /data/.cache/huggingface /root/.cache/
              ln -s /data/.cache/torch /root/.cache/
              /app/scripts/entrypoint.sh /app/scripts/start-django.sh
          env:
            - name: AUTH_TYPE
              value: "none"
            
            - name: REDIS_HOST
              value: "redis-redis-redis"
            - name: REDIS_PORT
              value: "6379"
            - name: REDIS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: redis-redis-account-default
                  key: username
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-redis-account-default
                  key: password
            - name: CELERY_FLOWER_PASSWORD
              value: "admin"
            - name: CELERY_FLOWER_USER
              value: "admin"
            - name: DJANGO_LOG_LEVEL
              value: "INFO"
            - name: MODEL_FAMILIES
              value: "[{\"enabled\":\"true\",\"label\":\"QianWen\",\"models\":[{\"context_window\":8096,\"enabled\":\"true\",\"label\":\"QianWen Turbo\",\"memory\":\"enabled\",\"name\":\"qwen-turbo\"},{\"context_window\":8096,\"enabled\":\"true\",\"label\":\"QianWen Plus\",\"memory\":\"enabled\",\"name\":\"qwen-plus\"},{\"context_window\":8096,\"enabled\":\"true\",\"label\":\"QianWen Max\",\"memory\":\"enabled\",\"name\":\"qwen-max\"}],\"name\":\"qianwen\",\"temperature\":0.01},{\"enabled\":\"true\",\"label\":\"ChatGLM\",\"models\":[{\"enabled\":\"true\",\"label\":\"ChatGLM Turbo\",\"memory\":\"enabled\",\"name\":\"chatglm-turbo\"},{\"enabled\":\"true\",\"label\":\"ChatGLM Std\",\"memory\":\"enabled\",\"name\":\"chatglm-std\"},{\"enabled\":\"true\",\"label\":\"ChatGLM Lite\",\"memory\":\"enabled\",\"name\":\"chatglm-lite\"},{\"enabled\":\"true\",\"label\":\"ChatGLM Pro\",\"memory\":\"enabled\",\"name\":\"chatglm-pro\"},{\"context_window\":32384,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-chatglm2-6b:8000\",\"label\":\"ChatGLM2 6b\",\"memory\":\"disabled\",\"name\":\"chatglm2-6b\"}],\"name\":\"chatglm\",\"temperature\":0.01},{\"enabled\":\"true\",\"label\":\"BaiChuan\",\"models\":[{\"context_window\":4096,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-baichuan-13b:8000\",\"label\":\"BaiChuan 13b\",\"memory\":\"disabled\",\"name\":\"baichuan-13b\"},{\"enabled\":\"true\",\"label\":\"BaiChuan 53b\",\"memory\":\"disabled\",\"name\":\"baichuan-53b\"}],\"name\":\"baichuan\",\"temperature\":0.01},{\"enabled\":\"true\",\"label\":\"Azure OpenAI\",\"models\":[{\"context_window\":4096,\"enabled\":\"true\",\"label\":\"Azure OpenAI\",\"memory\":\"enabled\",\"name\":\"azure-openai\"}],\"name\":\"azure-openai\",\"temperature\":0},{\"enabled\":\"true\",\"label\":\"ChatGPT\",\"models\":[{\"context_window\":128000,\"enabled\":\"true\",\"label\":\"ChatGPT-4 Turbo\",\"memory\":\"enabled\",\"name\":\"gpt-4-1106-preview\",\"similarity_topk\":10},{\"context_window\":8192,\"enabled\":\"true\",\"label\":\"ChatGPT-4\",\"memory\":\"enabled\",\"name\":\"gpt-4\"},{\"context_window\":8192,\"enabled\":\"true\",\"label\":\"ChatGPT-4-0613\",\"memory\":\"enabled\",\"name\":\"gpt-4-0613\"},{\"context_window\":16385,\"enabled\":\"true\",\"label\":\"ChatGPT 3.5 Turbo 1106\",\"memory\":\"enabled\",\"name\":\"gpt-3.5-turbo-1106\",\"similarity_topk\":5},{\"context_window\":4096,\"enabled\":\"true\",\"label\":\"ChatGPT-3.5 Turbo\",\"memory\":\"enabled\",\"name\":\"gpt-3.5-turbo\"},{\"context_window\":16384,\"enabled\":\"true\",\"label\":\"ChatGPT-3.5 Turbo 16k\",\"memory\":\"enabled\",\"name\":\"gpt-3.5-turbo-16k\",\"similarity_topk\":5}],\"name\":\"chatgpt\",\"temperature\":0},{\"enabled\":\"true\",\"label\":\"Wen Xin Yi Yan\",\"models\":[{\"enabled\":\"true\",\"label\":\"Wen Xin Yi Yan\",\"memory\":\"disabled\",\"name\":\"ernie-bot-turbo\"}],\"name\":\"wenxinyiyan\"},{\"enabled\":\"false\",\"label\":\"Vicuna\",\"models\":[{\"context_window\":2048,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-vicuna-13b:8000\",\"label\":\"Vicuna 13b\",\"memory\":\"disabled\",\"name\":\"vicuna-13b\"}],\"name\":\"vicuna\"},{\"enabled\":\"false\",\"label\":\"Guanaco\",\"models\":[{\"context_window\":2048,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-guanaco-33b:8000\",\"label\":\"Guanaco 33b\",\"memory\":\"disabled\",\"name\":\"guanaco-33b\"}],\"name\":\"guanaco\"},{\"enabled\":\"false\",\"label\":\"Falcon\",\"models\":[{\"context_window\":2048,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-falcon-40b:8000\",\"label\":\"Falcon 40b\",\"memory\":\"disabled\",\"name\":\"falcon-40b\"}],\"name\":\"falcon\"},{\"enabled\":\"false\",\"label\":\"Gorilla\",\"models\":[{\"context_window\":2048,\"enabled\":\"false\",\"endpoint\":\"http://llmserver-gurilla-7b:8000\",\"label\":\"Gorilla 7b\",\"memory\":\"disabled\",\"name\":\"gorilla-7b\"}],\"name\":\"gorilla\"}]"
            - name: POSTGRES_DB
              value: "kubechat"
            - name: POSTGRES_HOST
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: host
            - name: POSTGRES_PORT
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: port
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: username
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: password
            - name: VECTOR_DB_CONTEXT
              value: "{\"url\":\"http://qdrant-qdrant\", \"port\":6333, \"distance\":\"Cosine\", \"timeout\": 1000}"
            - name: VECTOR_DB_TYPE
              value: "qdrant"
            - name: MEDIA_ROOT
              value: /data/media
            - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
              value: python
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: FEISHU_APP_ID
              value: ""
            - name: FEISHU_APP_SECRET
              value: ""
            - name: FEISHU_ENCRIPT_KEY
              value: ""
            - name: MAX_BOT_COUNT
              value: "10"
            - name: MAX_COLLECTION_COUNT
              value: "50"
            - name: MAX_DOCUMENT_COUNT
              value: "1000"
            - name: MAX_CONVERSATION_COUNT
              value: "100"
            - name: EMBEDDING_MODEL
              value: "bge"
            - name: EMBEDDING_DEVICE
              value: "cpu"
            - name: EMBEDDING_BACKEND
              value: "local"
            - name: EMBEDDING_SERVICE_URL
              value: "http://xinference-xinference:9997"
            - name: EMBEDDING_SERVICE_MODEL
              value: "bge-large-zh-v1.5"
            - name: EMBEDDING_SERVICE_MODEL_UID
              value: ""
            - name: RERANK_BACKEND
              value: "local"
            - name: RERANK_SERVICE_URL
              value: "http://xinference-xinference:9997"
            - name: RERANK_SERVICE_MODEL_UID
              value: ""
            - name: ES_HOST
              value: "http://elasticsearch-elasticsearch:9200"
            - name: ADMIN_USER
              value: ""
            - name: ADMIN_TOKEN
              value: ""
          image: registry.cn-hangzhou.aliyuncs.com/apecloud/kubechat:v0.1.2
          name: kubechat-django
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8000
          volumeMounts:
            - mountPath: /data
              name: data
      restartPolicy: Always
      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubechat.io/component: celery-worker
            topologyKey: kubernetes.io/hostname
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubechat.io/component: django
              topologyKey: kubernetes.io/hostname
            weight: 100
      volumes:
        # shared uploaded files between django and celery
        - name: data
          hostPath:
            path: /data/kubechat
---
# Source: kubechat/templates/flower-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f compose.yml -c -o deploy/kubechat
    kompose.version: 1.26.0 (40646f47)
  labels:
    helm.sh/chart: kubechat-0.5.0-yunjia.1
    app.kubernetes.io/name: kubechat
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
  name: flower
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kubechat
      app.kubernetes.io/instance: my-release
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kubechat
        app.kubernetes.io/instance: my-release
    spec:
      containers:
        - args:
            - /bin/sh
            - -c
            - |
              /app/scripts/entrypoint.sh /app/scripts/start-celery-flower.sh
          env:
            - name: REDIS_HOST
              value: "redis-redis-redis"
            - name: REDIS_PORT
              value: "6379"
            - name: REDIS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: redis-redis-account-default
                  key: username
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-redis-account-default
                  key: password
            - name: CELERY_FLOWER_PASSWORD
              value: "admin"
            - name: CELERY_FLOWER_USER
              value: "admin"
            - name: DJANGO_LOG_LEVEL
              value: "INFO"
            - name: POSTGRES_DB
              value: "kubechat"
            - name: POSTGRES_HOST
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: host
            - name: POSTGRES_PORT
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: port
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: username
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-conn-credential
                  key: password
          image: registry.cn-hangzhou.aliyuncs.com/apecloud/kubechat:v0.1.2
          name: kubechat-flower
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 5555
          resources:
            {}
      restartPolicy: Always
status: {}
---
# Source: kubechat/templates/frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubechat-website
  namespace: kubechat
  labels:
    app: kubechat-website
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kubechat-website
  template:
    metadata:
      labels:
        app: kubechat-website
    spec:
      containers:
      - image: docker.io/apecloud/kubechat-website:latest
        imagePullPolicy: IfNotPresent
        name: kubechat-website
        ports:
        - containerPort: 80
          protocol: TCP
      imagePullSecrets:
      - name: docker-hub-secret
---
# Source: kubechat/templates/frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubechat-console
  namespace: kubechat
  labels:
    app: kubechat-console
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kubechat-console
  template:
    metadata:
      labels:
        app: kubechat-console
    spec:
      containers:
      - image: docker.io/apecloud/kubechat-console:latest
        imagePullPolicy: IfNotPresent
        name: kubechat-console
        ports:
        - containerPort: 80
          protocol: TCP
---
# Source: kubechat/templates/ocr-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: paddleocr-hubserving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: paddleocr-hubserving
  template:
    metadata:
      labels:
        app: paddleocr-hubserving
    spec:
      containers:
        - name: paddleocr-hubserving
          image: docker.io/gswyhq/paddleocr:hubserving
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8866
          resources:
            limits:
              nvidia.com/gpu: "1"
---
# Source: kubechat/templates/whisper-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: openai-whisper-asr
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openai-whisper-asr
  template:
    metadata:
      labels:
        app: openai-whisper-asr
    spec:
      containers:
        - name: openai-whisper-asr
          image: docker.io/onerahmet/openai-whisper-asr-webservice:latest-gpu
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9000
          env:
            - name: ASR_MODEL
              value: large-v2
            - name: ASR_ENGINE
              value: faster_whisper
          resources:
            limits:
              nvidia.com/gpu: "1"
---
# Source: kubechat/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: kubechat-ingress
spec:
  ingressClassName: 
  rules:
  - http:
      paths:
      - pathType: Prefix
        path: "/api"
        backend:
          service:
            name: kubechat
            port:
              number: 8000
      - pathType: Prefix
        path: "/web"
        backend:
          service:
            name: kubechat-console
            port:
              number: 8002
      - pathType: Prefix
        path: "/"
        backend:
          service:
            name: kubechat-website
            port:
              number: 8001
---
# Source: kubechat/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-kubechat-test-connection"
  labels:
    helm.sh/chart: kubechat-0.5.0-yunjia.1
    app.kubernetes.io/name: kubechat
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['my-release-kubechat:']
  restartPolicy: Never
