---
# Source: direktiv/templates/fn-namespace.yaml
kind: Namespace
apiVersion: v1
metadata:
  name: direktiv-services-direktiv
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
  annotations:
    linkerd.io/inject: enabled
---
# Source: direktiv/charts/fluent-bit/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-fluent-bit
  namespace: default
  labels:
    helm.sh/chart: fluent-bit-0.46.7
    app.kubernetes.io/name: fluent-bit
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "3.0.4"
    app.kubernetes.io/managed-by: Helm
---
# Source: direktiv/charts/ingress-nginx/templates/controller-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: my-release-ingress-nginx
  namespace: default
automountServiceAccountToken: true
---
# Source: direktiv/charts/prometheus/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: v2.48.1
    helm.sh/chart: prometheus-25.8.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: my-release-prometheus-server
  namespace: default
  annotations:
    {}
---
# Source: direktiv/templates/flow/flow-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-direktiv
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
---
# Source: direktiv/templates/functions/functions-sa-pod.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-direktiv-functions-pod
  namespace: direktiv-services-direktiv
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
---
# Source: direktiv/templates/functions/functions-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-direktiv-functions
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
---
# Source: direktiv/templates/flow/flow-secrets-fluentbit.yaml
apiVersion: v1
kind: Secret
metadata:
  name: direktiv-fluentbit
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
   PG_USER: "ZGlyZWt0aXY="
   PG_PASSWORD: "ZGlyZWt0aXZkaXJla3Rpdg==" 
   PG_HOST: "cG9zdGdyZXMtcG9zdGdyZXNxbC1oYS1wZ3Bvb2wucG9zdGdyZXM="
   PG_DB_NAME: "ZGlyZWt0aXY="
   PG_PORT: "NTQzMg=="
---
# Source: direktiv/templates/flow/flow-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-direktiv
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:

   db: "aG9zdD1wb3N0Z3Jlcy1wb3N0Z3Jlc3FsLWhhLXBncG9vbC5wb3N0Z3JlcyBwb3J0PTU0MzIgdXNlcj1kaXJla3RpdiBkYm5hbWU9ZGlyZWt0aXYgcGFzc3dvcmQ9ZGlyZWt0aXZkaXJla3RpdiBzc2xtb2RlPXJlcXVpcmUg"
   key: "SFFXbjFoVU5paktPRFpuTVBLdlVuSnFWZ0xXa04ydVU="
---
# Source: direktiv/templates/functions/functions-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-release-direktiv-secrets-functions
  namespace: direktiv-services-direktiv
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  db: "aG9zdD1teS1yZWxlYXNlLWRpcmVrdGl2LXN1cHBvcnQuZGVmYXVsdCBwb3J0PTU0MzIgdXNlcj1kaXJla3RpdiBkYm5hbWU9ZGlyZWt0aXYgcGFzc3dvcmQ9ZGlyZWt0aXZkaXJla3RpdiBzc2xtb2RlPWRpc2FibGU="
---
# Source: direktiv/charts/fluent-bit/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-fluent-bit
  namespace: default
  labels:
    helm.sh/chart: fluent-bit-0.46.7
    app.kubernetes.io/name: fluent-bit
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "3.0.4"
    app.kubernetes.io/managed-by: Helm
data:
  custom_parsers.conf: |
    [PARSER]
        Name docker_no_time
        Format json
        Time_Keep Off
        Time_Key time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
    
  fluent-bit.conf: |
    [SERVICE]
        Daemon Off
        Flush 1
        Log_Level info
        Parsers_File /fluent-bit/etc/parsers.conf
        Parsers_File /fluent-bit/etc/conf/custom_parsers.conf
        HTTP_Server On
        HTTP_Listen 0.0.0.0
        HTTP_Port 2020
        Health_Check On
    
    [INPUT]
        Name                    tail
        Path                    /var/log/containers/*flow*.log,/var/log/containers/*direktiv-sidecar*.log
        Mem_Buf_Limit           5MB
        Skip_Long_Lines         Off
        Tag                     input
        multiline.parser        cri, docker
        Refresh_Interval        1
        Buffer_Max_Size         64k
    
    [FILTER]
        Name                    rewrite_tag
        Match                   input
        Rule                    $log ^.*"track":"([^"]*).*$ flow.$1 true
    [FILTER]
        Name parser
        Match *
        Parser json
        Key_Name log
        Reserve_Data on
    
    [OUTPUT]
        name                    pgsql
        match                   flow.*
        port                    ${PG_PORT}
        table                   fluentbit
        user                    ${PG_USER}
        database                ${PG_DB_NAME}
        host                    ${PG_HOST}
        password                ${PG_PASSWORD}
---
# Source: direktiv/charts/ingress-nginx/templates/controller-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: my-release-ingress-nginx-controller
  namespace: default
data:
  allow-snippet-annotations: "false"
  proxy-buffer-size: "16k"
---
# Source: direktiv/charts/prometheus/templates/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: v2.48.1
    helm.sh/chart: prometheus-25.8.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: my-release-prometheus-server
  namespace: default
data:
  allow-snippet-annotations: "false"
  alerting_rules.yml: |
    {}
  alerts: |
    {}
  prometheus.yml: |
    global:
      evaluation_interval: 1m
      scrape_interval: 1m
      scrape_timeout: 10s
    rule_files:
    - /etc/config/recording_rules.yml
    - /etc/config/alerting_rules.yml
    - /etc/config/rules
    - /etc/config/alerts
    scrape_configs:
    - job_name: prometheus
      static_configs:
      - targets:
        - localhost:9090
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-apiservers
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: default;kubernetes;https
        source_labels:
        - __meta_kubernetes_namespace
        - __meta_kubernetes_service_name
        - __meta_kubernetes_endpoint_port_name
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes-cadvisor
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - honor_labels: true
      job_name: kubernetes-service-endpoints
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape
      - action: drop
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: (.+?)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
        replacement: __param_$1
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: service
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: node
    - honor_labels: true
      job_name: kubernetes-service-endpoints-slow
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: (.+?)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
        replacement: __param_$1
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: service
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: node
      scrape_interval: 5m
      scrape_timeout: 30s
    - honor_labels: true
      job_name: prometheus-pushgateway
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - action: keep
        regex: pushgateway
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
    - honor_labels: true
      job_name: kubernetes-services
      kubernetes_sd_configs:
      - role: service
      metrics_path: /probe
      params:
        module:
        - http_2xx
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
      - source_labels:
        - __address__
        target_label: __param_target
      - replacement: blackbox
        target_label: __address__
      - source_labels:
        - __param_target
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - source_labels:
        - __meta_kubernetes_service_name
        target_label: service
    - honor_labels: true
      job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape
      - action: drop
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
        replacement: '[$2]:$1'
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        - __meta_kubernetes_pod_ip
        target_label: __address__
      - action: replace
        regex: (\d+);((([0-9]+?)(\.|$)){4})
        replacement: $2:$1
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        - __meta_kubernetes_pod_ip
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
        replacement: __param_$1
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: pod
      - action: drop
        regex: Pending|Succeeded|Failed|Completed
        source_labels:
        - __meta_kubernetes_pod_phase
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: node
    - honor_labels: true
      job_name: kubernetes-pods-slow
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
        replacement: '[$2]:$1'
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        - __meta_kubernetes_pod_ip
        target_label: __address__
      - action: replace
        regex: (\d+);((([0-9]+?)(\.|$)){4})
        replacement: $2:$1
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        - __meta_kubernetes_pod_ip
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
        replacement: __param_$1
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: pod
      - action: drop
        regex: Pending|Succeeded|Failed|Completed
        source_labels:
        - __meta_kubernetes_pod_phase
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: node
      scrape_interval: 5m
      scrape_timeout: 30s
  recording_rules.yml: |
    {}
  rules: |
    {}
---
# Source: direktiv/templates/functions/functions-cm-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-direktiv-config-functions
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
data:
  functions-config.yaml: |
      # logging format json/console
      logging: json

      # ingress class for knative functions
      ingress-class: contour.ingress.networking.knative.dev

      # address of flow engine
      flow-service: my-release-direktiv-flow.default

      # address of opentelemetry backend
      opentelemetry-backend: ""

      # name of the service account to run the pods
      service-account: my-release-direktiv-functions-pod

      # name of the namespace to use for the services/functions
      namespace: direktiv-services-direktiv

      # pod sidecar name
      sidecar: docker.io/:v0.8.7

      # max number of pods per service
      max-scale: 3

      # shaping network traffic if supported by network plugin
      net-shape: 

      # runtime for services, e.g. gvisor
      runtime: default

      # max memory/cpu value defined for different service sizes
      # Memory in Megabyte, 0 is no limit
      memory:
        small: 512
        medium: 1024
        large: 2048
      cpu:
        small: 250m
        medium: 500m
        large: 1

      # disk size can not be large than the max configuration
      # in Knative which is 4GB by default
      disk:
        small: 256
        medium: 1024
        large: 4096

      # proxy values
      proxy:
        no: ""
        https: ""
        http: ""

      # additional volumes
      extraVolumes:

      # additional sidecar containers
      extraContainers:

      ######### Deprecated #########
      # default concurrency level
      concurrency: 100

      # maximum timeout, needs to be in below knative max
      request-timeout: 7200

      # max ephemeral storage in MB
      storage: 100

      # rollout seconds for knative services
      rollout-duration: 10
      
      # init pod name
      init-pod: docker.io/:v0.8.7
---
# Source: direktiv/charts/fluent-bit/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: my-release-fluent-bit
  labels:
    helm.sh/chart: fluent-bit-0.46.7
    app.kubernetes.io/name: fluent-bit
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "3.0.4"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - namespaces
      - pods
    verbs:
      - get
      - list
      - watch
---
# Source: direktiv/charts/ingress-nginx/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
  name: my-release-ingress-nginx
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - endpoints
      - nodes
      - pods
      - secrets
      - namespaces
    verbs:
      - list
      - watch
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - discovery.k8s.io
    resources:
      - endpointslices
    verbs:
      - list
      - watch
      - get
---
# Source: direktiv/charts/prometheus/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: v2.48.1
    helm.sh/chart: prometheus-25.8.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: my-release-prometheus-server
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
      - nodes/proxy
      - nodes/metrics
      - services
      - endpoints
      - pods
      - ingresses
      - configmaps
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - "extensions"
      - "networking.k8s.io"
    resources:
      - ingresses/status
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - "discovery.k8s.io"
    resources:
      - endpointslices
    verbs:
      - get
      - list
      - watch
  - nonResourceURLs:
      - "/metrics"
    verbs:
      - get
---
# Source: direktiv/templates/functions/functions-role-cluster.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
 name: my-release-direktiv-role-cluster
 labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: ["serving.knative.dev"]
  resources: ["*"]
  verbs: ["*"]
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list", "update", "delete", "create", "deletecollection"]
- apiGroups: ["batch"]
  resources: ["jobs"]
  verbs: ["get", "list", "create", "delete", "deletecollection", "watch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["list", "watch", "log", "delete"]
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["list", "watch", "get"]
---
# Source: direktiv/charts/fluent-bit/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-release-fluent-bit
  labels:
    helm.sh/chart: fluent-bit-0.46.7
    app.kubernetes.io/name: fluent-bit
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "3.0.4"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-release-fluent-bit
subjects:
  - kind: ServiceAccount
    name: my-release-fluent-bit
    namespace: default
---
# Source: direktiv/charts/ingress-nginx/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
  name: my-release-ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-release-ingress-nginx
subjects:
  - kind: ServiceAccount
    name: my-release-ingress-nginx
    namespace: default
---
# Source: direktiv/charts/prometheus/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: v2.48.1
    helm.sh/chart: prometheus-25.8.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: my-release-prometheus-server
subjects:
  - kind: ServiceAccount
    name: my-release-prometheus-server
    namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-release-prometheus-server
---
# Source: direktiv/templates/functions/functions-rolebind-cluster.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
 name: my-release-direktiv-functions-binding
subjects:
- kind: ServiceAccount
  name: my-release-direktiv-functions
  namespace: default
roleRef:
 kind: ClusterRole
 name: my-release-direktiv-role-cluster
 apiGroup: rbac.authorization.k8s.io
---
# Source: direktiv/charts/ingress-nginx/templates/controller-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: my-release-ingress-nginx
  namespace: default
rules:
  - apiGroups:
      - ""
    resources:
      - namespaces
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - configmaps
      - pods
      - secrets
      - endpoints
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  # Omit Ingress status permissions if `--update-status` is disabled.
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    resourceNames:
      - my-release-ingress-nginx-leader
    verbs:
      - get
      - update
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - create
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      - discovery.k8s.io
    resources:
      - endpointslices
    verbs:
      - list
      - watch
      - get
---
# Source: direktiv/templates/flow/flow-role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
 name: my-release-direktiv-flow-role
 labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["list", "get", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get"]
---
# Source: direktiv/templates/functions/functions-role-ns.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
 name: my-release-direktiv-functions-role
 labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list", "update", "watch"]
---
# Source: direktiv/charts/ingress-nginx/templates/controller-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: my-release-ingress-nginx
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-release-ingress-nginx
subjects:
  - kind: ServiceAccount
    name: my-release-ingress-nginx
    namespace: default
---
# Source: direktiv/templates/flow/flow-role-bind.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
 name: my-release-direktiv-flow-role-bind
subjects:
- kind: ServiceAccount
  name: my-release-direktiv
  namespace: default
roleRef:
 kind: Role
 name: my-release-direktiv-flow-role
 apiGroup: rbac.authorization.k8s.io
---
# Source: direktiv/templates/functions/functions-rolebind-ns.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
 name: my-release-direktiv-functions-binding-lock
subjects:
- kind: ServiceAccount
  name: my-release-direktiv-functions
  namespace: default
roleRef:
 kind: Role
 name: my-release-direktiv-functions-role
 apiGroup: rbac.authorization.k8s.io
---
# Source: direktiv/charts/fluent-bit/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-fluent-bit
  namespace: default
  labels:
    helm.sh/chart: fluent-bit-0.46.7
    app.kubernetes.io/name: fluent-bit
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "3.0.4"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 2020
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: fluent-bit
    app.kubernetes.io/instance: my-release
---
# Source: direktiv/charts/ingress-nginx/templates/controller-service-webhook.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: my-release-ingress-nginx-controller-admission
  namespace: default
spec:
  type: ClusterIP
  ports:
    - name: https-webhook
      port: 443
      targetPort: webhook
      appProtocol: https
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: controller
---
# Source: direktiv/charts/ingress-nginx/templates/controller-service.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: my-release-ingress-nginx-controller
  namespace: default
spec:
  type: LoadBalancer
  ipFamilyPolicy: SingleStack
  ipFamilies: 
    - IPv4
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
      appProtocol: http
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
      appProtocol: https
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: controller
---
# Source: direktiv/charts/prometheus/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: v2.48.1
    helm.sh/chart: prometheus-25.8.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: my-release-prometheus-server
  namespace: default
spec:
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 9090
  selector:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: my-release
  sessionAffinity: None
  type: "ClusterIP"
---
# Source: direktiv/templates/flow/flow-service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-direktiv-headless
  annotations:
    kubernetes.io/ingress.class: nginx
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
spec:
  clusterIP: None
  ports:
    - port: 6666
      name: flow
      protocol: TCP
  selector:
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
---
# Source: direktiv/templates/flow/flow-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-direktiv-flow
  annotations:
    kubernetes.io/ingress.class: nginx
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 6665
      name: flow-v1
      protocol: TCP
    - port: 6666
      name: flow
      protocol: TCP
    - port: 6667
      name: flow-v2
      protocol: TCP
    - port: 7777
      name: internal
      protocol: TCP
    - port: 9999
      name: vars
      protocol: TCP
    - port: 9998
      name: metrics
      protocol: TCP
  selector:
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
---
# Source: direktiv/templates/frontend/frontend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-direktiv-frontend
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv-frontend
    app.kubernetes.io/instance: my-release-frontend
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  ports:
    - port: 2304
      targetPort: 2304
      protocol: TCP
      name: frontend
  selector:
    app.kubernetes.io/name: direktiv-frontend
    app.kubernetes.io/instance: my-release-frontend
---
# Source: direktiv/templates/functions/functions-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-direktiv-functions
  annotations:
    kubernetes.io/ingress.class: nginx
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 5555
      name: grpc
      protocol: TCP
  selector:
    app.kubernetes.io/name: direktiv-functions
    app.kubernetes.io/instance: my-release-functions
---
# Source: direktiv/charts/fluent-bit/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: my-release-fluent-bit
  namespace: default
  labels:
    helm.sh/chart: fluent-bit-0.46.7
    app.kubernetes.io/name: fluent-bit
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "3.0.4"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: fluent-bit
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      labels:
        app.kubernetes.io/name: fluent-bit
        app.kubernetes.io/instance: my-release
      annotations:
        checksum/config: 48d5f6911aec33612a779c071c89f090e92390ab59dd6416197c7ed5ba4dd4bb
    spec:
      serviceAccountName: my-release-fluent-bit
      hostNetwork: false
      dnsPolicy: ClusterFirst
      containers:
        - name: fluent-bit
          image: "cr.fluentbit.io/fluent/fluent-bit:3.0.4"
          imagePullPolicy: IfNotPresent
          envFrom:
            - secretRef:
                name: direktiv-fluentbit
          command:
            - /fluent-bit/bin/fluent-bit
          args:
            - --workdir=/fluent-bit/etc
            - --config=/fluent-bit/etc/conf/fluent-bit.conf
          ports:
            - name: http
              containerPort: 2020
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /api/v1/health
              port: http
          volumeMounts:
            - name: config
              mountPath: /fluent-bit/etc/conf
            - mountPath: /var/log
              name: varlog
            - mountPath: /var/lib/docker/containers
              name: varlibdockercontainers
              readOnly: true
            - mountPath: /etc/machine-id
              name: etcmachineid
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: my-release-fluent-bit
        - hostPath:
            path: /var/log
          name: varlog
        - hostPath:
            path: /var/lib/docker/containers
          name: varlibdockercontainers
        - hostPath:
            path: /etc/machine-id
            type: File
          name: etcmachineid
---
# Source: direktiv/charts/ingress-nginx/templates/controller-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: my-release-ingress-nginx-controller
  namespace: default
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: controller
  replicas: 1
  revisionHistoryLimit: 10
  minReadySeconds: 0
  template:
    metadata:
      annotations:
        linkerd.io/inject: "disabled"
      labels:
        helm.sh/chart: ingress-nginx-4.9.0
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/version: "1.9.5"
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: controller
    spec:
      dnsPolicy: ClusterFirst
      containers:
        - name: controller
          image: registry.k8s.io/ingress-nginx/controller:v1.9.5@sha256:b3aba22b1da80e7acfc52b115cae1d4c687172cbf2b742d5b502419c25ff340e
          imagePullPolicy: IfNotPresent
          lifecycle: 
            preStop:
              exec:
                command:
                - /wait-shutdown
          args: 
            - /nginx-ingress-controller
            - --publish-service=$(POD_NAMESPACE)/my-release-ingress-nginx-controller
            - --election-id=my-release-ingress-nginx-leader
            - --controller-class=k8s.io/ingress-nginx
            - --ingress-class=nginx
            - --configmap=$(POD_NAMESPACE)/my-release-ingress-nginx-controller
            - --validating-webhook=:8443
            - --validating-webhook-certificate=/usr/local/certificates/cert
            - --validating-webhook-key=/usr/local/certificates/key
          securityContext: 
            runAsNonRoot: true
            runAsUser: 101
            allowPrivilegeEscalation: false
            seccompProfile: 
              type: RuntimeDefault
            capabilities:
              drop:
              - ALL
              add:
              - NET_BIND_SERVICE
            readOnlyRootFilesystem: false
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LD_PRELOAD
              value: /usr/local/lib/libmimalloc.so
          livenessProbe: 
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe: 
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
            - name: https
              containerPort: 443
              protocol: TCP
            - name: webhook
              containerPort: 8443
              protocol: TCP
          volumeMounts:
            - name: webhook-cert
              mountPath: /usr/local/certificates/
              readOnly: true
          resources: 
            requests:
              cpu: 100m
              memory: 90Mi
      nodeSelector: 
        kubernetes.io/os: linux
      serviceAccountName: my-release-ingress-nginx
      terminationGracePeriodSeconds: 300
      volumes:
        - name: webhook-cert
          secret:
            secretName: my-release-ingress-nginx-admission
---
# Source: direktiv/charts/prometheus/templates/deploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: v2.48.1
    helm.sh/chart: prometheus-25.8.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: my-release-prometheus-server
  namespace: default
spec:
  selector:
    matchLabels:
      app.kubernetes.io/component: server
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/instance: my-release
  replicas: 1
  revisionHistoryLimit: 10
  strategy:
    type: Recreate
    rollingUpdate: null
  template:
    metadata:
      labels:
        app.kubernetes.io/component: server
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/version: v2.48.1
        helm.sh/chart: prometheus-25.8.2
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: prometheus
    spec:
      enableServiceLinks: true
      serviceAccountName: my-release-prometheus-server
      containers:
        - name: prometheus-server-configmap-reload
          image: "quay.io/prometheus-operator/prometheus-config-reloader:v0.70.0"
          imagePullPolicy: "IfNotPresent"
          args:
            - --watched-dir=/etc/config
            - --reload-url=http://127.0.0.1:9090/-/reload
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
              readOnly: true

        - name: prometheus-server
          image: "quay.io/prometheus/prometheus:v2.48.1"
          imagePullPolicy: "IfNotPresent"
          args:
            - --storage.tsdb.retention.time=96h
            - --config.file=/etc/config/prometheus.yml
            - --storage.tsdb.path=/data
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --web.console.templates=/etc/prometheus/consoles
            - --web.enable-lifecycle
          ports:
            - containerPort: 9090
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 5
            timeoutSeconds: 4
            failureThreshold: 3
            successThreshold: 1
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 15
            timeoutSeconds: 10
            failureThreshold: 3
            successThreshold: 1
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: storage-volume
              mountPath: /data
              subPath: ""
      dnsPolicy: ClusterFirst
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      terminationGracePeriodSeconds: 300
      volumes:
        - name: config-volume
          configMap:
            name: my-release-prometheus-server
        - name: storage-volume
          emptyDir:
            {}
---
# Source: direktiv/templates/flow/flow-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-direktiv-flow
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: direktiv
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      annotations:
        prometheus.io/port: "2112"
        prometheus.io/path: "/metrics"
        prometheus.io/scrape: "true"
        prometheus.io/scheme: "http"
      labels:
        app.kubernetes.io/name: direktiv
        app.kubernetes.io/instance: my-release
        app: my-release-direktiv-flow
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 65532
        runAsGroup: 65532
      serviceAccountName: my-release-direktiv-functions
      containers:
        - name: flow
          securityContext:
            readOnlyRootFilesystem: false
            allowPrivilegeEscalation: false
          resources:
            requests:
              memory: "128Mi"
            limits:
              memory: "2048Mi"
          image: "docker.io/direktiv/direktiv:v0.8.7"
          imagePullPolicy: Always
          command: ["/bin/direktiv", "server"]
          volumeMounts:
          ports:
            - name: flow-v1
              containerPort: 6665
              protocol: TCP
            - name: flow
              containerPort: 6666
              protocol: TCP
            - name: flow-v2
              containerPort: 6667
              protocol: TCP
            - name: internal
              containerPort: 7777
              protocol: TCP
          env:
          - name: DIREKTIV_DEBUG
            value: "false"
          - name: DIREKTIV_API_V1_PORT
            value: "6665"
          - name: DIREKTIV_API_V2_PORT
            value: "6667"
          - name: DIREKTIV_GRPC_PORT
            value: "6666"
          - name: DIREKTIV_SECRET_KEY
            valueFrom:
              secretKeyRef:
                name: my-release-direktiv
                key: key
          - name: DIREKTIV_DB
            valueFrom:
              secretKeyRef:
                name: my-release-direktiv
                key: db
          - name: DIREKTIV_FUNCTIONS_TIMEOUT
            value: "7200"
          - name: DIREKTIV_PROMETHEUS_BACKEND
            value: my-release-direktiv-prometheus-server.default
          - name: DIREKTIV_OPEN_TELEMETRY_BACKEND
            value: ""
          - name: DIREKTIV_KNATIVE_SERVICE_ACCOUNT
            value: "my-release-direktiv-functions-pod"
          - name: DIREKTIV_KNATIVE_NAMESPACE
            value: "direktiv-services-direktiv"
          - name: DIREKTIV_KNATIVE_INGRESS_CLASS
            value: "contour.ingress.networking.knative.dev"
          - name: DIREKTIV_KNATIVE_SIDECAR
            value: "docker.io/direktiv/direktiv:v0.8.7"
          - name: DIREKTIV_KNATIVE_MAX_SCALE
            value: "5"
          - name: DIREKTIV_SERVICE_NAMESPACE
            value: direktiv-services-direktiv
          - name: DIREKTIV_DEPLOYMENT_NAME
            value: "my-release-direktiv"
          - name: DIREKTIV_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace

          - name: DIREKTIV_KNATIVE_SIZE_MEMORY_SMALL
            value: "512"
          - name: DIREKTIV_KNATIVE_SIZE_CPU_SMALL
            value: "250m"
          - name: DIREKTIV_KNATIVE_SIZE_DISK_SMALL
            value: "256"
          - name: DIREKTIV_KNATIVE_SIZE_MEMORY_MEDIUM
            value: "1024"
          - name: DIREKTIV_KNATIVE_SIZE_CPU_MEDIUM
            value: "500m"
          - name: DIREKTIV_KNATIVE_SIZE_DISK_MEDIUM
            value: "1024"
          - name: DIREKTIV_KNATIVE_SIZE_MEMORY_LARGE
            value: "2048"
          - name: DIREKTIV_KNATIVE_SIZE_CPU_LARGE
            value: "1"
          - name: DIREKTIV_KNATIVE_SIZE_DISK_LARGE
            value: "4096"

      volumes:
---
# Source: direktiv/templates/frontend/frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-direktiv-frontend
  labels:
    
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv-frontend
    app.kubernetes.io/instance: my-release-frontend
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm-frontend
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: direktiv-frontend
      app.kubernetes.io/instance: my-release-frontend
  template:
    metadata:
      annotations:
      labels:
        app.kubernetes.io/name: direktiv-frontend
        app.kubernetes.io/instance: my-release-frontend
    spec:
      serviceAccountName: my-release-direktiv
      containers:
        - name: frontend
          securityContext:
            readOnlyRootFilesystem: false
            allowPrivilegeEscalation: false
          resources:
            requests:
              memory: 128Mi
            limits:
              memory: 512Mi
          image: "docker.io/direktiv/frontend:v0.8.7"
          imagePullPolicy: Always
          env:
          ports:
            - name: frontend
              containerPort: 2304
              protocol: TCP
          volumeMounts:
      volumes:
---
# Source: direktiv/charts/ingress-nginx/templates/controller-ingressclass.yaml
# We don't support namespaced ingressClass yet
# So a ClusterRole and a ClusterRoleBinding is required
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: nginx
spec:
  controller: k8s.io/ingress-nginx
---
# Source: direktiv/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-release-direktiv-ingress-frontend
  labels:
    helm.sh/chart: direktiv-0.1.27
    app.kubernetes.io/name: direktiv
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "v0.8.7"
    app.kubernetes.io/managed-by: Helm
  annotations:
    nginx.ingress.kubernetes.io/service-upstream: "true"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "7200"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "7200"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "7200"
    nginx.ingress.kubernetes.io/proxy-body-size: 128m
spec:
  ingressClassName: nginx
  rules:
  - host: 
    http:
      paths:
        - path: /
          pathType: Prefix
          backend:
            service:
              name: my-release-direktiv-frontend
              port:
                number: 2304
        - path: /api/
          pathType: Prefix
          backend:
            service:
              name: my-release-direktiv-flow
              port:
                number: 6665
        - path: /ns/
          pathType: Prefix
          backend:
            service:
              name: my-release-direktiv-flow
              port:
                number: 6665
---
# Source: direktiv/charts/ingress-nginx/templates/admission-webhooks/validating-webhook.yaml
# before changing this value, check the required kubernetes version
# https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
  name: my-release-ingress-nginx-admission
webhooks:
  - name: validate.nginx.ingress.kubernetes.io
    matchPolicy: Equivalent
    rules:
      - apiGroups:
          - networking.k8s.io
        apiVersions:
          - v1
        operations:
          - CREATE
          - UPDATE
        resources:
          - ingresses
    failurePolicy: Fail
    sideEffects: None
    admissionReviewVersions:
      - v1
    clientConfig:
      service:
        name: my-release-ingress-nginx-controller-admission
        namespace: default
        path: /networking/v1/ingresses
---
# Source: direktiv/charts/ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-ingress-nginx-admission
  namespace: default
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
---
# Source: direktiv/charts/ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: my-release-ingress-nginx-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
rules:
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - validatingwebhookconfigurations
    verbs:
      - get
      - update
---
# Source: direktiv/charts/ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-release-ingress-nginx-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-release-ingress-nginx-admission
subjects:
  - kind: ServiceAccount
    name: my-release-ingress-nginx-admission
    namespace: default
---
# Source: direktiv/charts/ingress-nginx/templates/admission-webhooks/job-patch/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-release-ingress-nginx-admission
  namespace: default
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
---
# Source: direktiv/charts/ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-release-ingress-nginx-admission
  namespace: default
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-release-ingress-nginx-admission
subjects:
  - kind: ServiceAccount
    name: my-release-ingress-nginx-admission
    namespace: default
---
# Source: direktiv/charts/fluent-bit/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-fluent-bit-test-connection"
  namespace: default
  labels:
    helm.sh/chart: fluent-bit-0.46.7
    app.kubernetes.io/version: "3.0.4"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/hook: test
    helm.sh/hook-delete-policy: hook-succeeded
spec:
  containers:
    - name: wget
      image: "busybox:latest"
      imagePullPolicy: Always
      command: ["sh"]
      args: ["-c", "wget -O- my-release-fluent-bit:2020"]
  restartPolicy: Never
---
# Source: direktiv/charts/ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-release-ingress-nginx-admission-create
  namespace: default
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
spec:
  template:
    metadata:
      name: my-release-ingress-nginx-admission-create
      annotations: 
        linkerd.io/inject: disabled
      labels:
        helm.sh/chart: ingress-nginx-4.9.0
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/version: "1.9.5"
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: admission-webhook
    spec:
      containers:
        - name: create
          image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0@sha256:a7943503b45d552785aa3b5e457f169a5661fb94d82b8a3373bcd9ebaf9aac80
          imagePullPolicy: IfNotPresent
          args:
            - create
            - --host=my-release-ingress-nginx-controller-admission,my-release-ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
            - --namespace=$(POD_NAMESPACE)
            - --secret-name=my-release-ingress-nginx-admission
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 65532
            seccompProfile:
              type: RuntimeDefault
      restartPolicy: OnFailure
      serviceAccountName: my-release-ingress-nginx-admission
      nodeSelector: 
        kubernetes.io/os: linux
---
# Source: direktiv/charts/ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-release-ingress-nginx-admission-patch
  namespace: default
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.9.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.9.5"
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
spec:
  template:
    metadata:
      name: my-release-ingress-nginx-admission-patch
      annotations: 
        linkerd.io/inject: disabled
      labels:
        helm.sh/chart: ingress-nginx-4.9.0
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/version: "1.9.5"
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: admission-webhook
    spec:
      containers:
        - name: patch
          image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0@sha256:a7943503b45d552785aa3b5e457f169a5661fb94d82b8a3373bcd9ebaf9aac80
          imagePullPolicy: IfNotPresent
          args:
            - patch
            - --webhook-name=my-release-ingress-nginx-admission
            - --namespace=$(POD_NAMESPACE)
            - --patch-mutating=false
            - --secret-name=my-release-ingress-nginx-admission
            - --patch-failure-policy=Fail
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 65532
            seccompProfile:
              type: RuntimeDefault
      restartPolicy: OnFailure
      serviceAccountName: my-release-ingress-nginx-admission
      nodeSelector: 
        kubernetes.io/os: linux
