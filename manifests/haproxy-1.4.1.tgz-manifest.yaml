---
# Source: haproxy/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-haproxy
  labels:
    helm.sh/chart: haproxy-1.4.1
    app.kubernetes.io/name: haproxy
    app.kubernetes.io/instance: my-release
    app: haproxy
    app.kubernetes.io/version: "2.5-alpine"
    app.kubernetes.io/managed-by: Helm
---
# Source: haproxy/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-release-haproxy-configmap
  labels:
    helm.sh/chart: haproxy-1.4.1
    app.kubernetes.io/name: haproxy
    app.kubernetes.io/instance: my-release
    app: haproxy
    app.kubernetes.io/version: "2.5-alpine"
    app.kubernetes.io/managed-by: Helm
data:
  000-global.cfg: |
    global
      maxconn 10000
      log 127.0.0.1 local0
      nbproc 1
      nbthread 1
  001-defaults.cfg: |
    defaults
      backlog           2000
      timeout connect   10s
      timeout client    30s
      timeout server    30s
      timeout check     10s
      log global
      mode tcp
      option httplog
      maxconn 3000
  002-metrics.cfg: |
    frontend metrics
      mode http
      log global
      maxconn 10
      bind *:8404
      http-request use-service prometheus-exporter if { path /metrics }
      stats enable
      stats uri /
      stats refresh 10s
      stats admin if LOCALHOST
---
# Source: haproxy/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-haproxy
  labels:
    helm.sh/chart: haproxy-1.4.1
    app.kubernetes.io/name: haproxy
    app.kubernetes.io/instance: my-release
    app: haproxy
    app.kubernetes.io/version: "2.5-alpine"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
  - name: metrics
    protocol: TCP
    port: 8404
    targetPort: metrics
  selector:
    app.kubernetes.io/name: haproxy
    app.kubernetes.io/instance: my-release
---
# Source: haproxy/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-haproxy
  labels:
    helm.sh/chart: haproxy-1.4.1
    app.kubernetes.io/name: haproxy
    app.kubernetes.io/instance: my-release
    app: haproxy
    app.kubernetes.io/version: "2.5-alpine"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: haproxy
      app.kubernetes.io/instance: my-release
  template:
    metadata:
      labels:
        app.kubernetes.io/name: haproxy
        app.kubernetes.io/instance: my-release
      annotations:
        checksum/environment: 18ae101e5a6d9a9a819b65e86093f662d72271445fb1ef99d0944c964c33461a          
    spec:
      serviceAccountName: my-release-haproxy
      securityContext:
        {}
      volumes:
        - name: haproxy-config
          configMap:
            name: my-release-haproxy-configmap
      containers:
        - name: haproxy
          securityContext:
            {}
          image: "haproxy:2.2-alpine"
          imagePullPolicy: IfNotPresent
          args:
            - -f
            - /usr/local/etc/haproxy
          ports:
            - name: metrics
              containerPort: 8404
              protocol: TCP
          volumeMounts:
            - name: haproxy-config
              mountPath: /usr/local/etc/haproxy/
---
# Source: haproxy/templates/test/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-release-haproxy-test-metrics-connection"
  labels:
    helm.sh/chart: haproxy-1.4.1
    app.kubernetes.io/name: haproxy
    app.kubernetes.io/instance: my-release
    app: haproxy
    app.kubernetes.io/version: "2.5-alpine"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wait-connection-to-start
      image: willwill/wait-for-it
      args: ['my-release-haproxy:8404']
  restartPolicy: Never
