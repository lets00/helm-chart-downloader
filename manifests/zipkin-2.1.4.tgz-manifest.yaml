---
# Source: zipkin/charts/elasticsearch/templates/coordinating-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-elasticsearch-coordinating-only
  labels:
    app.kubernetes.io/name: elasticsearch
    helm.sh/chart: elasticsearch-17.9.29
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinating-only
  annotations: 
    {}
spec:
  type: "ClusterIP"
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 9200
      targetPort: http
      nodePort: null
    - name: tcp-transport
      port: 9300
  selector:
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: coordinating-only
---
# Source: zipkin/charts/elasticsearch/templates/data-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-elasticsearch-data
  labels:
    app.kubernetes.io/name: elasticsearch
    helm.sh/chart: elasticsearch-17.9.29
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: data
  annotations: 
    {}
spec:
  type: ClusterIP
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 9200
      targetPort: http
    - name: tcp-transport
      port: 9300
      targetPort: transport
      nodePort: null
  selector:
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: data
---
# Source: zipkin/charts/elasticsearch/templates/master-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-elasticsearch-master
  labels:
    app.kubernetes.io/name: elasticsearch
    helm.sh/chart: elasticsearch-17.9.29
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
  annotations: 
    {}
spec:
  type: "ClusterIP"
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 9200
      targetPort: http
    - name: tcp-transport
      port: 9300
      targetPort: transport
      nodePort: null
  selector:
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/component: master
---
# Source: zipkin/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-zipkin
  namespace: default
  labels:
    app.kubernetes.io/name: zipkin
    helm.sh/chart: zipkin-2.1.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      targetPort: http
      port: 9411
      protocol: TCP
    - name: scribe
      targetPort: scribe
      port: 9410
      protocol: TCP
  selector:
    app.kubernetes.io/name: zipkin
    app.kubernetes.io/instance: my-release
---
# Source: zipkin/templates/deployment-statefulset.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-zipkin
  namespace: default
  labels:
    app.kubernetes.io/name: zipkin
    helm.sh/chart: zipkin-2.1.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: zipkin
      app.kubernetes.io/instance: my-release
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: zipkin
        helm.sh/chart: zipkin-2.1.4
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
      annotations:
    spec:
      automountServiceAccountToken: false
      shareProcessNamespace: false
      serviceAccountName: default
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zipkin
                    app.kubernetes.io/instance: my-release
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      hostNetwork: false
      hostIPC: false      
      containers:
        - name: zipkin
          image: docker.io/openzipkin/zipkin:2.24
          imagePullPolicy: "IfNotPresent"
          env:
            - name: STORAGE_TYPE
              value: elasticsearch
            - name : ES_HOSTS
              value: my-release-elasticsearch:9200
          envFrom:
          ports:
            - name: http
              containerPort: 9411
              protocol: TCP
            - name: scribe
              containerPort: 9410
              protocol: TCP
          livenessProbe:
            tcpSocket:
              port: http
            initialDelaySeconds: 45
            periodSeconds: 20
            timeoutSeconds: 
            successThreshold: 
            failureThreshold: 
          volumeMounts:
      volumes:
        - name: data-storage
          emptyDir: {}
---
# Source: zipkin/charts/elasticsearch/templates/coordinating-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-elasticsearch-coordinating-only
  labels:
    app.kubernetes.io/name: elasticsearch
    helm.sh/chart: elasticsearch-17.9.29
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinating-only
    ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
    app: coordinating-only
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: coordinating-only
  podManagementPolicy: Parallel
  replicas: 2
  serviceName: my-release-elasticsearch-coordinating-only
  template:
    metadata:
      labels:
        app.kubernetes.io/name: elasticsearch
        helm.sh/chart: elasticsearch-17.9.29
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: coordinating-only
        ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
        app: coordinating-only
      annotations:
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      serviceAccountName: default
      securityContext:
        fsGroup: 1001
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/bitnami-shell:10-debian-10-r403
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
          resources:
            limits: {}
            requests: {}
      containers:
        - name: elasticsearch
          image: docker.io/bitnami/elasticsearch:7.17.3-debian-10-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: BITNAMI_DEBUG
              value: "false"
            - name: ELASTICSEARCH_CLUSTER_NAME
              value: "elastic"
            - name: ELASTICSEARCH_CLUSTER_HOSTS
              value: "my-release-elasticsearch-master.default.svc.cluster.local,my-release-elasticsearch-coordinating-only.default.svc.cluster.local,my-release-elasticsearch-data.default.svc.cluster.local,"
            - name: ELASTICSEARCH_TOTAL_NODES
              value: "5"
            - name: ELASTICSEARCH_CLUSTER_MASTER_HOSTS
              value: my-release-elasticsearch-master-0 my-release-elasticsearch-master-1 my-release-elasticsearch-master-2 
            - name: ELASTICSEARCH_MINIMUM_MASTER_NODES
              value: "2"
            - name: ELASTICSEARCH_ADVERTISED_HOSTNAME
              value: "$(MY_POD_NAME).my-release-elasticsearch-coordinating-only.default.svc.cluster.local"
            - name: ELASTICSEARCH_HEAP_SIZE
              value: "128m"
            - name: ELASTICSEARCH_IS_DEDICATED_NODE
              value: "yes"
            - name: ELASTICSEARCH_NODE_TYPE
              value: "coordinating"
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
          livenessProbe:
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          readinessProbe:
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          resources:
            limits: {}
            requests:
              cpu: 25m
              memory: 256Mi
          volumeMounts:
            - name: data
              mountPath: /bitnami/elasticsearch/data
      volumes:
        - name: "data"
          emptyDir: {}
---
# Source: zipkin/charts/elasticsearch/templates/data-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-elasticsearch-data
  labels:
    app.kubernetes.io/name: elasticsearch
    helm.sh/chart: elasticsearch-17.9.29
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: data
    ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
    app: data
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: data
  podManagementPolicy: Parallel
  replicas: 2
  serviceName: my-release-elasticsearch-data
  template:
    metadata:
      labels:
        app.kubernetes.io/name: elasticsearch
        helm.sh/chart: elasticsearch-17.9.29
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: data
        ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
        app: data
      annotations:
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      serviceAccountName: default
      securityContext:
        fsGroup: 1001
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/bitnami-shell:10-debian-10-r403
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
          resources:
            limits: {}
            requests: {}
      containers:
        - name: elasticsearch
          image: docker.io/bitnami/elasticsearch:7.17.3-debian-10-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: BITNAMI_DEBUG
              value: "false"
            - name: ELASTICSEARCH_CLUSTER_NAME
              value: "elastic"
            - name: ELASTICSEARCH_CLUSTER_HOSTS
              value: "my-release-elasticsearch-master.default.svc.cluster.local,my-release-elasticsearch-coordinating-only.default.svc.cluster.local,my-release-elasticsearch-data.default.svc.cluster.local,"
            - name: ELASTICSEARCH_TOTAL_NODES
              value: "5"
            - name: ELASTICSEARCH_HEAP_SIZE
              value: "1024m"
            - name: ELASTICSEARCH_IS_DEDICATED_NODE
              value: "yes"
            - name: ELASTICSEARCH_NODE_TYPE
              value: "data"
            - name: ELASTICSEARCH_ADVERTISED_HOSTNAME
              value: "$(MY_POD_NAME).my-release-elasticsearch-data.default.svc.cluster.local"
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
          livenessProbe:
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          readinessProbe:
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          resources:
            limits: {}
            requests:
              cpu: 25m
              memory: 2048Mi
          volumeMounts:
            - name: "data"
              mountPath: "/bitnami/elasticsearch/data"
      volumes:
        - name: "data"
          emptyDir: {}
---
# Source: zipkin/charts/elasticsearch/templates/master-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-release-elasticsearch-master
  labels:
    app.kubernetes.io/name: elasticsearch
    helm.sh/chart: elasticsearch-17.9.29
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
    ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
    app: master
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: elasticsearch
      app.kubernetes.io/instance: my-release
      app.kubernetes.io/component: master
  podManagementPolicy: Parallel
  replicas: 3
  serviceName: my-release-elasticsearch-master
  template:
    metadata:
      labels:
        app.kubernetes.io/name: elasticsearch
        helm.sh/chart: elasticsearch-17.9.29
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: master
        ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
        app: master
      annotations:
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          
        nodeAffinity:
          
      serviceAccountName: default
      securityContext:
        fsGroup: 1001
      initContainers:
        ## Image that performs the sysctl operation to modify Kernel settings (needed sometimes to avoid boot errors)
        - name: sysctl
          image: docker.io/bitnami/bitnami-shell:10-debian-10-r403
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              CURRENT=`sysctl -n vm.max_map_count`;
              DESIRED="262144";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w vm.max_map_count=262144;
              fi;
              CURRENT=`sysctl -n fs.file-max`;
              DESIRED="65536";
              if [ "$DESIRED" -gt "$CURRENT" ]; then
                  sysctl -w fs.file-max=65536;
              fi;
          securityContext:
            privileged: true
          resources:
            limits: {}
            requests: {}
      containers:
        - name: elasticsearch
          image: docker.io/bitnami/elasticsearch:7.17.3-debian-10-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: BITNAMI_DEBUG
              value: "false"
            - name: ELASTICSEARCH_CLUSTER_NAME
              value: "elastic"
            - name: ELASTICSEARCH_CLUSTER_HOSTS
              value: "my-release-elasticsearch-master.default.svc.cluster.local,my-release-elasticsearch-coordinating-only.default.svc.cluster.local,my-release-elasticsearch-data.default.svc.cluster.local,"
            - name: ELASTICSEARCH_TOTAL_NODES
              value: "5"
            - name: ELASTICSEARCH_CLUSTER_MASTER_HOSTS
              value: my-release-elasticsearch-master-0 my-release-elasticsearch-master-1 my-release-elasticsearch-master-2 
            - name: ELASTICSEARCH_MINIMUM_MASTER_NODES
              value: "2"
            - name: ELASTICSEARCH_ADVERTISED_HOSTNAME
              value: "$(MY_POD_NAME).my-release-elasticsearch-master.default.svc.cluster.local"
            - name: ELASTICSEARCH_HEAP_SIZE
              value: "128m"
            - name: ELASTICSEARCH_IS_DEDICATED_NODE
              value: "yes"
            - name: ELASTICSEARCH_NODE_TYPE
              value: "master"
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
          livenessProbe:
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          readinessProbe:
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - /opt/bitnami/scripts/elasticsearch/healthcheck.sh
          resources:
            limits: {}
            requests:
              cpu: 25m
              memory: 256Mi
          volumeMounts:
            - name: data
              mountPath: /bitnami/elasticsearch/data
      volumes:
        - name: "data"
          emptyDir: {}
---
# Source: zipkin/templates/cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: my-release-zipkin-dependencies
  namespace: default
  labels:
    app.kubernetes.io/name: zipkin
    helm.sh/chart: zipkin-2.1.4
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/managed-by: Helm
spec:
  schedule: "*/10 * * * *"
  failedJobsHistoryLimit: 5
  successfulJobsHistoryLimit: 5
  jobTemplate:
    metadata:
      labels:
        app.kubernetes.io/name: zipkin
        helm.sh/chart: zipkin-2.1.4
        app.kubernetes.io/instance: my-release
        app.kubernetes.io/managed-by: Helm
        cronjob-name: my-release-zipkin-dependencies
    spec:
      template:
        metadata:
          labels:
            app.kubernetes.io/name: zipkin
            helm.sh/chart: zipkin-2.1.4
            app.kubernetes.io/instance: my-release
            app.kubernetes.io/managed-by: Helm
            cronjob-name: my-release-zipkin-dependencies
        spec:          
          restartPolicy: Never
          containers:
          - name: my-release-zipkin-dependencies
            env:
              - name: STORAGE_TYPE
                value: elasticsearch
              - name : ES_HOSTS
                value: my-release-elasticsearch-coordinating-only:9200
            envFrom:
            imagePullPolicy: IfNotPresent
            image: openzipkin/zipkin-dependencies:2.6.4
