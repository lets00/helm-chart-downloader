---
# Source: gke-node-termination-handler/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-release-gke-node-termination-handler
  labels:
    app.kubernetes.io/name: gke-node-termination-handler
    helm.sh/chart: gke-node-termination-handler-1.2.7
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: gke-node-termination-handler/templates/rbac.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-release-gke-node-termination-handler
  labels:
    app.kubernetes.io/name: gke-node-termination-handler
    helm.sh/chart: gke-node-termination-handler-1.2.7
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
rules:
  # Allow Node Termination Handler to get and update nodes (for posting taints).
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "update"]
  # Allow Node Termination Handler to create events
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create"]
  # Allow Node Termination Handler to list and delete pods (for draining nodes)
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["list", "delete", "get"]
---
# Source: gke-node-termination-handler/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-release-gke-node-termination-handler
  labels:
    app.kubernetes.io/name: gke-node-termination-handler
    helm.sh/chart: gke-node-termination-handler-1.2.7
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-release-gke-node-termination-handler
subjects:
- kind: ServiceAccount
  name: my-release-gke-node-termination-handler
  namespace: default
---
# Source: gke-node-termination-handler/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: my-release-gke-node-termination-handler
  labels:
    app.kubernetes.io/name: gke-node-termination-handler
    helm.sh/chart: gke-node-termination-handler-1.2.7
    app.kubernetes.io/instance: my-release
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      name: my-release-gke-node-termination-handler
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        name: my-release-gke-node-termination-handler
    spec:
      # Necessary to hit the node's metadata server when using Workload Identity
      hostNetwork: true
      # Necessary to reboot node
      hostPID: true
      serviceAccountName: my-release-gke-node-termination-handler
      affinity:
        nodeAffinity:
         # Restrict to GPU nodes or preemptible nodes
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: cloud.google.com/gke-accelerator
                operator: Exists
            - matchExpressions:
              - key: cloud.google.com/gke-preemptible
                operator: Exists
      containers:
      - image: "k8s.gcr.io/gke-node-termination-handler@sha256:aca12d17b222dfed755e28a44d92721e477915fb73211d0a0f8925a1fa847cca"
        imagePullPolicy: Always
        name: gke-node-termination-handler
        command: ["./node-termination-handler"]
        args:
            - -v=10
            - --logtostderr
            - --exclude-pods=$(POD_NAME):$(POD_NAMESPACE)
            - --taint=cloud.google.com/impending-node-termination::NoSchedule
        securityContext:
          capabilities:
            # Necessary to reboot node
            add: ["SYS_BOOT"]
        env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: SLACK_WEBHOOK_URL
            value: ""
        resources:
            limits:
              cpu: 150m
              memory: 30Mi
            requests:
              cpu: 150m
              memory: 30Mi
      tolerations:
      # Run regardless of any existing taints.
      - effect: NoSchedule
        operator: Exists
      - effect: NoExecute
        operator: Exists
